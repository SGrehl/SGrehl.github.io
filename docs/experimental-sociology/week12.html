<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2025-06-20">

<title>Experimental Sociology - Week 12 – ES &amp; CSS</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-2fa0555fe88427c29efa1b60aaf9e62d.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-024b15207476f2674d9c8aca10390aa5.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script src="../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>

      .quarto-title-block .quarto-title-banner {
        background: #5791b5;
      }
</style>
<link href="../site_libs/htmltools-fill-0.5.8.1/fill.css" rel="stylesheet">

<script src="../site_libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>

<script src="../site_libs/plotly-binding-4.10.4/plotly.js"></script>

<script src="../site_libs/typedarray-0.1/typedarray.min.js"></script>

<script src="../site_libs/jquery-3.5.1/jquery.min.js"></script>

<link href="../site_libs/crosstalk-1.2.1/css/crosstalk.min.css" rel="stylesheet">

<script src="../site_libs/crosstalk-1.2.1/js/crosstalk.min.js"></script>

<link href="../site_libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css" rel="stylesheet">

<script src="../site_libs/plotly-main-2.11.1/plotly-latest.min.js"></script>

<script type="text/javascript" src="../js/week-control.js"></script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">ES &amp; CSS</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-general-information" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">General Information</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-general-information">    
        <li>
    <a class="dropdown-item" href="../general-information/exam.html">
 <span class="dropdown-text">Course Assessment</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../general-information/sc.html">
 <span class="dropdown-text">Scientific Computing</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../general-information/data.html">
 <span class="dropdown-text">Data Sources</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../general-information/ai_usage.html">
 <span class="dropdown-text">AI-Usage</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../general-information/anti_dis.html">
 <span class="dropdown-text">Anti-Discrimination Policy</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-experimental-sociology" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Experimental Sociology</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-experimental-sociology">    
        <li>
    <a class="dropdown-item" href="../experimental-sociology/es_overview.html">
 <span class="dropdown-text">Course Overview</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../experimental-sociology/week01.html">
 <span class="dropdown-text">Week 01</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../experimental-sociology/week02.html">
 <span class="dropdown-text">Week 02</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../experimental-sociology/week03.html">
 <span class="dropdown-text">Week 03</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../experimental-sociology/week04.html">
 <span class="dropdown-text">Week 04</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../experimental-sociology/week05.html">
 <span class="dropdown-text">Week 05</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../experimental-sociology/week06.html">
 <span class="dropdown-text">Week 06</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../experimental-sociology/week07.html">
 <span class="dropdown-text">Week 07</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../experimental-sociology/week08.html">
 <span class="dropdown-text">Week 08</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../experimental-sociology/week09.html">
 <span class="dropdown-text">Week 09</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../experimental-sociology/week10.html">
 <span class="dropdown-text">Week 10</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../experimental-sociology/week11.html">
 <span class="dropdown-text">Week 11</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../experimental-sociology/week12.html">
 <span class="dropdown-text">Week 12</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../experimental-sociology/week13.html">
 <span class="dropdown-text">Week 13</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../experimental-sociology/week14.html">
 <span class="dropdown-text">Week 14</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-computational-social-sciences" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Computational Social Sciences</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-computational-social-sciences">    
        <li>
    <a class="dropdown-item" href="../computational-social-sciences/css_overview.html">
 <span class="dropdown-text">Course Overview</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../computational-social-sciences/week01.html">
 <span class="dropdown-text">Week 01</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../computational-social-sciences/week02.html">
 <span class="dropdown-text">Week 02</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../computational-social-sciences/week03.html">
 <span class="dropdown-text">Week 03</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../computational-social-sciences/week04.html">
 <span class="dropdown-text">Week 04</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../computational-social-sciences/week05.html">
 <span class="dropdown-text">Week 05</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../computational-social-sciences/week06.html">
 <span class="dropdown-text">Week 06</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../computational-social-sciences/week07.html">
 <span class="dropdown-text">Week 07</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../computational-social-sciences/week08.html">
 <span class="dropdown-text">Week 08</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../computational-social-sciences/week09.html">
 <span class="dropdown-text">Week 09</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../computational-social-sciences/week10.html">
 <span class="dropdown-text">Week 10</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../computational-social-sciences/week11.html">
 <span class="dropdown-text">Week 11</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../computational-social-sciences/week12.html">
 <span class="dropdown-text">Week 12</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../computational-social-sciences/week13.html">
 <span class="dropdown-text">Week 13</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../computational-social-sciences/week14.html">
 <span class="dropdown-text">Week 14</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-page-right">
      <div class="quarto-title-block"><div><h1 class="title">Experimental Sociology - Week 12</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
            <p class="subtitle lead">Power Analysis</p>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta column-page-right">

      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">2025-06-20</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Contents</h2>
   
  <ul>
  <li><a href="#learning-goals" id="toc-learning-goals" class="nav-link active" data-scroll-target="#learning-goals">Learning Goals</a></li>
  <li><a href="#statistical-power" id="toc-statistical-power" class="nav-link" data-scroll-target="#statistical-power">Statistical Power</a>
  <ul class="collapse">
  <li><a href="#power-and-specificity" id="toc-power-and-specificity" class="nav-link" data-scroll-target="#power-and-specificity">Power and Specificity</a></li>
  <li><a href="#four-core-elements-of-statistical-power" id="toc-four-core-elements-of-statistical-power" class="nav-link" data-scroll-target="#four-core-elements-of-statistical-power">Four Core Elements of Statistical Power</a>
  <ul class="collapse">
  <li><a href="#time-to-play-and-learn" id="toc-time-to-play-and-learn" class="nav-link" data-scroll-target="#time-to-play-and-learn">Time To Play (and Learn!)</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#conducting-a-power-analysis" id="toc-conducting-a-power-analysis" class="nav-link" data-scroll-target="#conducting-a-power-analysis">Conducting a Power Analysis</a>
  <ul class="collapse">
  <li><a href="#the-analytical-way" id="toc-the-analytical-way" class="nav-link" data-scroll-target="#the-analytical-way">The Analytical Way</a>
  <ul class="collapse">
  <li><a href="#trusting-your-power-analysis" id="toc-trusting-your-power-analysis" class="nav-link" data-scroll-target="#trusting-your-power-analysis">Trusting Your Power Analysis</a></li>
  </ul></li>
  <li><a href="#simulation-a-practical-alternative-to-formula-based-power-analysis" id="toc-simulation-a-practical-alternative-to-formula-based-power-analysis" class="nav-link" data-scroll-target="#simulation-a-practical-alternative-to-formula-based-power-analysis">Simulation: A Practical Alternative to Formula-Based Power Analysis</a></li>
  <li><a href="#implementation-in-r" id="toc-implementation-in-r" class="nav-link" data-scroll-target="#implementation-in-r">Implementation in R</a></li>
  <li><a href="#why-use-unequal-sample-sizes" id="toc-why-use-unequal-sample-sizes" class="nav-link" data-scroll-target="#why-use-unequal-sample-sizes">Why Use Unequal Sample Sizes?</a>
  <ul class="collapse">
  <li><a href="#cost-constraints" id="toc-cost-constraints" class="nav-link" data-scroll-target="#cost-constraints">1. Cost Constraints</a></li>
  <li><a href="#logistical-or-external-constraints" id="toc-logistical-or-external-constraints" class="nav-link" data-scroll-target="#logistical-or-external-constraints">2. Logistical or External Constraints</a></li>
  <li><a href="#adaptive-designs-and-reweighting" id="toc-adaptive-designs-and-reweighting" class="nav-link" data-scroll-target="#adaptive-designs-and-reweighting">3. Adaptive Designs and Reweighting</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#increasing-power-further" id="toc-increasing-power-further" class="nav-link" data-scroll-target="#increasing-power-further">Increasing Power Further</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">🧩 Conclusion</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block column-page-right" id="quarto-document-content">





<p>Last week, we focused on calibration, allowing us to fine-tune our model parameters to closely match empirical data. With a calibrated model in hand, we can now run experiments in silico-simulating experimental conditions in a virtual environment. This step enables us to explore key design questions, refine our experimental setup, and improve the planning of real-world studies.</p>
<p>Consider the question of how people’s opinions are influenced by others. More specifically, we are interested in how different network topologies affect polarization within a population.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> We assume that the influence of a neutral source differs from the influence of someone with shared partisanship, and also from someone with opposing partisanship. This sets the stage for a in silicio experiment. <a href="#fig-network-conditions" class="quarto-xref">Figure&nbsp;1</a> shows four different experimental treatments that participants might encounter when learning about the opinions of others:</p>
<div id="fig-network-conditions" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-network-conditions-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/clipboard-2383815932.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Figure&nbsp;1: Schematic depiction of the different network topologies as seen from the participant’s perspective (red nodes). White nodes have a similar partisanship, black nodes have a dissimilar partisanship. The partisanship of gray nodes is not revealed (The total network (not shown) has a size of ten people)."><img src="images/clipboard-2383815932.png" class="img-fluid figure-img" width="704"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-network-conditions-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Schematic depiction of the different network topologies as seen from the participant’s perspective (red nodes). White nodes have a similar partisanship, black nodes have a dissimilar partisanship. The partisanship of gray nodes is not revealed (The total network (not shown) has a size of ten people).
</figcaption>
</figure>
</div>
<p>Each treatment reflects a different network topology a certain agent (ego, the red circle) is a part of. The experiment should proceeds as follows: first, participants’ initial opinions are recorded individually. Then, they are informed about the opinions of their neighbors, after which their opinions are measured again. In the first (<em>neutral</em>) condition, ego learns only the opinions of four others, without knowing their partisanship. In the other three conditions, ego also learns their neighbors’ party preferences—either all similar (<em>partisan</em>), all opposing (<em>antipartisan</em>), or a balanced mix (<em>mixed</em>).</p>
<p>We assume that neutral influence (<span class="math inline">\(\mu\)</span>) is weaker than influence from like-minded individuals (<span class="math inline">\(\mu_P\)</span>), while influence from those with opposing partisanship (<span class="math inline">\(\mu_A\)</span>) is weaker still—or even negative. In short, we expect <span class="math inline">\(\mu_A &lt; \mu &lt; \mu_P\)</span>. Drawing on empirical findings from previous studies, we use calibrated values for these parameters (<code>calibrated_model</code>) to run our experiment in silico:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>simulation  <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">model =</span> <span class="st">"calibrated_model"</span>,</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">replications =</span> <span class="dv">2</span>,</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">tbl_parameter =</span> <span class="fu">expand.grid</span>(</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">network =</span> <span class="fu">c</span>(<span class="st">"neutral"</span>, <span class="st">"partisan"</span>, <span class="st">"antipartisan"</span>, <span class="st">"mixed"</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">master_seed  =</span> <span class="dv">42</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">run_simulation</span>(simulation)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>To analyze the simulation output, we compute polarization within each simulated world. For this, we calculate the average absolute opinion difference between the two partisan groups. The use of absolute differences reflects our focus on the magnitude of disagreement, not which group supports which view.</p>
<div class="cell">
<details class="code-fold">
<summary>Show R Code (calc_polarization function)</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(glue)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>calc_polarization <span class="ot">&lt;-</span> <span class="cf">function</span>(</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>  results,</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">table  =</span> <span class="st">"final"</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>) {</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (table <span class="sc">==</span> <span class="st">"final"</span>) {</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    df <span class="ot">&lt;-</span> results<span class="sc">$</span>df_final_worlds</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>  } <span class="cf">else</span> <span class="cf">if</span> (table <span class="sc">==</span> <span class="st">"init"</span>) {</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    df <span class="ot">&lt;-</span> results<span class="sc">$</span>df_init_worlds</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Identify the columns defining each "world"</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>  start <span class="ot">&lt;-</span> <span class="fu">which</span>(<span class="fu">names</span>(df) <span class="sc">==</span> <span class="st">"replications"</span>) <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>  world_cols <span class="ot">&lt;-</span> <span class="fu">names</span>(df)[start<span class="sc">:</span><span class="fu">length</span>(<span class="fu">names</span>(df))]</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>  n_opinions <span class="ot">&lt;-</span> <span class="fu">length</span>(df<span class="sc">$</span>opinions[[<span class="dv">1</span>]])</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>  <span class="co"># 4) extract each position and compute diffs</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="fu">seq_len</span>(n_opinions)) {</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># pull the i-th element out of each list-column</span></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>    df[[<span class="fu">paste0</span>(<span class="st">"opinion_"</span>,  i)]] <span class="ot">&lt;-</span> <span class="fu">map_dbl</span>(df<span class="sc">$</span>opinions,       <span class="sc">~</span> .x[i])</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Compute the absolute difference in average opinions by groups</span></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>  result_list <span class="ot">&lt;-</span> <span class="fu">vector</span>(<span class="st">"list"</span>, <span class="at">length =</span> n_opinions)</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Compute the absolute difference in average opinions by groups</span></span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="fu">seq_len</span>(n_opinions)) {</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>    opinion_col <span class="ot">&lt;-</span> <span class="fu">paste0</span>(<span class="st">"opinion_"</span>, i)</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>    abs_diff_col <span class="ot">&lt;-</span> <span class="fu">glue</span>(<span class="st">"abs_diff_opinion_{i}"</span>)</span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>    result_list[[i]] <span class="ot">&lt;-</span> df <span class="sc">|&gt;</span></span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>      <span class="fu">group_by</span>(rep, <span class="fu">across</span>(<span class="fu">all_of</span>(world_cols)), partisanship) <span class="sc">|&gt;</span></span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>      <span class="fu">summarize</span>(<span class="at">avg_opinion =</span> <span class="fu">mean</span>(.data[[opinion_col]]), <span class="at">.groups =</span> <span class="st">"drop"</span>) <span class="sc">|&gt;</span></span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>      <span class="fu">pivot_wider</span>(<span class="at">names_from =</span> partisanship, </span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>                  <span class="at">values_from =</span> avg_opinion, </span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>                  <span class="at">names_prefix =</span> <span class="st">"opinion_"</span>) <span class="sc">|&gt;</span> </span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>      <span class="fu">mutate</span>(<span class="sc">!!</span><span class="at">abs_diff_col :=</span> <span class="fu">abs</span>(opinion_0 <span class="sc">-</span> opinion_1)) <span class="sc">|&gt;</span> </span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>      dplyr<span class="sc">::</span><span class="fu">select</span>(<span class="sc">-</span>opinion_0, <span class="sc">-</span>opinion_1)</span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Combine all opinion positions into one dataframe</span></span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a>  final_results <span class="ot">&lt;-</span> <span class="fu">bind_rows</span>(result_list)</span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-46"><a href="#cb2-46" aria-hidden="true" tabindex="-1"></a>  final_results</span>
<span id="cb2-47"><a href="#cb2-47" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Now we can use this to see how the different network topologies affect polarization:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>df_polarization <span class="ot">&lt;-</span> <span class="fu">calc_polarization</span>(results)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co"># show average differences between participants in the worlds</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>diffs <span class="ot">&lt;-</span> df_polarization <span class="sc">|&gt;</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(network) <span class="sc">|&gt;</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">abs_diff_mean =</span> <span class="fu">mean</span>(abs_diff_opinion_1)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>diffs</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 4 × 2
  network      abs_diff_mean
  &lt;fct&gt;                &lt;dbl&gt;
1 neutral             0.0870
2 partisan            0.124 
3 antipartisan        0.168 
4 mixed               0.149 </code></pre>
</div>
</div>
<p>The output reveals that average polarization is lowest in the <em>neutral</em> condition and highest in the <em>antipartisan</em> condition. Just one round of interaction is enough to increase the polarization by over 8%-points with a change from <em>neutral</em> to <em>antipartisan</em> condition.</p>
<p>We can also assess the effect size of these differences (using the library <code>effsize</code>):</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(effsize)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fu">cohen.d</span>(</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">formula =</span> abs_diff_opinion_1 <span class="sc">~</span> network,</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">data    =</span> df_polarization <span class="sc">|&gt;</span> <span class="fu">filter</span>(network <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">"neutral"</span>, <span class="st">"antipartisan"</span>)) <span class="sc">|&gt;</span> </span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">droplevels</span>(),</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">pooled  =</span> <span class="cn">TRUE</span>,</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">hedges.correction =</span> <span class="cn">FALSE</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>d</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Cohen's d

d estimate: -0.8140591 (large)
95 percent confidence interval:
    lower     upper 
-5.291375  3.663257 </code></pre>
</div>
</div>
<p>The result suggests a medium-to-large effect. But is that enough to justify a real-world experiment based on these findings? While the simulated effects are promising, we need to know whether such differences would be statistically significant with real experimental data. A common approach is to run the same statistical test we would run later in the real experiment to test whether polarization is different between treatments. Lets assume we are content with a simple t-test. Let us use this test to compare now the effect between the <em>neutral</em> and the <em>antipartisan</em> condition:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>ttest <span class="ot">&lt;-</span> df_polarization <span class="sc">|&gt;</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(network <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">"neutral"</span>, <span class="st">"antipartisan"</span>)) <span class="sc">|&gt;</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">t.test</span>(abs_diff_opinion_1 <span class="sc">~</span> network, <span class="at">data =</span> _)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>ttest</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
    Welch Two Sample t-test

data:  abs_diff_opinion_1 by network
t = -0.81406, df = 1.4419, p-value = 0.5281
alternative hypothesis: true difference in means between group neutral and group antipartisan is not equal to 0
95 percent confidence interval:
 -0.7159995  0.5536910
sample estimates:
     mean in group neutral mean in group antipartisan 
                 0.0869696                  0.1681238 </code></pre>
</div>
</div>
<p>Yet, the difference between the two treatments is not statistically significant (<span class="math inline">\(p &lt; 0.528\)</span>)—even though the effect size is considerable. Why? Because we only have two worlds per condition. Remember: polarization is a property of the entire simulated world, not of individuals. So even if each world contains many agents, our actual sample size for the statistical test is just two worlds per treatment.</p>
<p>Clearly, this sample size is far too small to detect substantial effects with confidence. Had we proceeded with a real-world experiment based on such limited data, we might have wasted significant resources. To prevent this, we turn to <strong>power analysis</strong>. Power analysis allows us to estimate how many simulated worlds (or real-world participants) are needed to detect effects of a given size with a high probability. This ensures that the experiments we design are not only theoretically sound but also practically effective.</p>
<p>At the same time, as you may already know from earlier statistics courses, increasing the sample size sufficiently will always lead to statistical significance, regardless of effect size. Therefore, we aim for a sample size that is just sufficient to detect the effect sizes we believe to be realistic—while remaining insensitive to much smaller, potentially spurious effects. In other words, power analysis helps us find the minimum number of worlds (or more generally sample size) required to robustly detect meaningful differences, without overcommitting resources or overfitting to noise.</p>
<section id="learning-goals" class="level2">
<h2 class="anchored" data-anchor-id="learning-goals">Learning Goals</h2>
<ol type="1">
<li>Define and interpret statistical power.</li>
<li>Identify the main components affecting experimental power.</li>
<li>Calculate power using both analytic formulas and simulation methods.</li>
<li>Conduct sensitivity analyses to assess how robust your power calculations are to assumptions.</li>
</ol>
</section>
<section id="statistical-power" class="level1">
<h1>Statistical Power</h1>
<p>Statistical power (henceforth simply power) is the probability that an experiment correctly <strong>identifies a true effect</strong>—it’s our ability to detect a meaningful signal amidst the noise. In any experimental setting, the <strong>signal</strong> we seek is the actual impact of a treatment. This could be:</p>
<ul>
<li>Does educational intervention increase income levels?</li>
<li>Do vaccination campaigns reduce disease incidence?</li>
<li>Which network topologies affect partisan polarization the most?</li>
</ul>
<p>The <strong>noise</strong> refers to the natural variability or randomness in data, caused by many unpredictable factors that are difficult—or even impossible—to measure or control for statistically. It’s typically quantified as the standard deviation of outcomes. Consider the following examples:</p>
<ul>
<li>If your outcome is the prevalence of a rare disease, daily fluctuations are usually minimal—thus, noise is low. Even a modest decrease (e.g., 1 percentage point) in disease rates could be detectable.</li>
<li>Conversely, measuring income as an outcome is inherently noisier, as individual incomes can differ greatly. A modest income increase of 1% might easily go unnoticed due to substantial background noise.</li>
</ul>
<p>Adequate power ensures that a true effect—if it exists—won’t be masked by randomness.</p>
<section id="power-and-specificity" class="level2">
<h2 class="anchored" data-anchor-id="power-and-specificity">Power and Specificity</h2>
<p>When planning an experiment, two core statistical concepts must be carefully balanced: <strong>power</strong> and <strong>specificity</strong> (see <a href="#tbl-sp" class="quarto-xref">Table&nbsp;1</a>). Understanding how they interact is crucial for designing experiments that are both scientifically rigorous and resource-efficient.</p>
<p><strong>Specificity</strong> refers to the probability of correctly retaining the null hypothesis when it is actually true. In other words, it is the ability of a test to avoid false positives. The <strong>significance level</strong> <span class="math inline">\(\alpha\)</span> defines how willing we are to risk a <strong>Type I error</strong>—rejecting the null hypothesis <span class="math inline">\(H_0\)</span> when it is actually true. This is often set at 0.05, meaning we accept a 5% chance of a false positive. Accordingly, the <strong>specificity</strong> of such a test is <span class="math inline">\(1 - \alpha = 0.95\)</span>.</p>
<p>On the other hand, <strong>statistical power</strong>—denoted as <span class="math inline">\(1 - \beta\)</span>—is the probability of correctly detecting a true effect. It represents the ability to avoid a <strong>Type II error</strong> (failing to reject <span class="math inline">\(H_0\)</span> when it is false). The value <span class="math inline">\(\beta\)</span> quantifies the probability of making such an error. Power is conventionally set at 80%, meaning we aim for <span class="math inline">\(1 - \beta = 0.8\)</span>, or in other words, we want to correctly detect true effects in 4 out of 5 experiments.</p>
<p>Balancing power and specificity is essential: increasing one often comes at the cost of the other. Power analysis helps us navigate this trade-off, ensuring that we choose a sample size large enough to detect meaningful effects, without inflating the risk of false positives.</p>
<div id="tbl-sp" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-sp-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: Decision outcomes depending on test result and reality
</figcaption>
<div aria-describedby="tbl-sp-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 24%">
<col style="width: 24%">
<col style="width: 26%">
<col style="width: 24%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;"></th>
<th style="text-align: left;"><span class="math inline">\(H_0\)</span> is true</th>
<th style="text-align: left;"><span class="math inline">\(H_1\)</span> is true</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>Test decision…</strong></td>
<td style="text-align: left;">… in favor of <span class="math inline">\(H_0\)</span></td>
<td style="text-align: left;">✅ Correct decision (Specificity) <br> Probability: 1 − α</td>
<td style="text-align: left;">❌ <strong>Type II error</strong> <br> Probability: β</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;">… in favor of <span class="math inline">\(H_1\)</span></td>
<td style="text-align: left;">❌ <strong>Type I error</strong> <br> Probability: α</td>
<td style="text-align: left;">✅ Correct decision (Power) <br> Probability: 1 − β</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
<section id="four-core-elements-of-statistical-power" class="level2">
<h2 class="anchored" data-anchor-id="four-core-elements-of-statistical-power">Four Core Elements of Statistical Power</h2>
<p>Four primary factors shape an experiment’s power:</p>
<ol type="1">
<li><p><strong>The test itself and the statistical significance criterion</strong> The type of statistical test used—and the threshold set for statistical significance—directly influences power. Some tests are inherently more sensitive than others, depending on the data and research design. In addition, the choice of <span class="math inline">\(\alpha\)</span> (commonly set at 0.05) defines the strictness of evidence required to reject the null hypothesis. A lower <span class="math inline">\(\alpha\)</span> (e.g., 0.01) reduces the chance of false positives but also makes it harder to detect true effects, thereby reducing power. Conversely, increasing <span class="math inline">\(\alpha\)</span> boosts power but raises the risk of false positives.</p></li>
<li><p><strong>Strength of Treatment</strong><br>
Stronger treatments are easier to detect and therefore increase statistical power. For example, giving each participant a large sum of money is more likely to produce a measurable effect than giving only a small sum. However, in practice, researchers often face constraints—whether due to limited resources or limited control over the intervention—especially when evaluating existing programs or policies.</p></li>
<li><p><strong>Background Noise (Variability</strong>)<br>
The more variability there is in outcomes, the harder it is to detect a true effect. Selecting outcome measures with lower variability can help improve power. In many cases, however, variability is inherent and difficult to reduce—especially when measuring complex behaviors like income or attitudes. This is precisely one of the reasons researchers turn to lab experiments: to create controlled environments that minimize noise. By standardizing conditions across participants, lab settings help keep variability low, making it easier to isolate and detect the effect of interest.</p></li>
<li><p><strong>Experimental Design</strong><br>
This is (often) the most direct lever researchers have to influence power. Power analysis often focuses on <strong>sample size</strong>—larger samples reduce uncertainty and increase power. But good design goes beyond just size. Consider:</p>
<ul>
<li>How units are randomized (individually or in clusters),</li>
<li>Whether key covariates are measured and controlled for,</li>
<li>How many treatment groups are included and how they’re structured.</li>
</ul></li>
</ol>
<section id="time-to-play-and-learn" class="level3">
<h3 class="anchored" data-anchor-id="time-to-play-and-learn">Time To Play (and Learn!)</h3>
<p>In the interactive graph below, you can explore how the key parameters of hypothesis testing—significance criterion <span class="math inline">\(\alpha\)</span>, difference in mean <span class="math inline">\(\mu_1\)</span>, and standard deviation <span class="math inline">\(\sigma\)</span>—interact to shape the probabilities of different outcomes.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> By adjusting the sliders, observe how the rates of <strong>Type I errors</strong> (false positives) and <strong>Type II errors</strong> (false negatives) change.</p>
<ul>
<li>The <strong>blue shaded areas</strong> represent <strong>Type I errors</strong>: regions where we incorrectly reject the null hypothesis (<span class="math inline">\(H_0\)</span> is true, but we reject it).</li>
<li>The <strong>red shaded area</strong> represents a <strong>Type II error</strong>: failing to reject the null hypothesis when the alternative is actually true.</li>
<li>The remaining areas under the curves represent <strong>correct decisions</strong>: either correctly retaining the null or correctly detecting a true effect.</li>
</ul>
<p>In an ideal scenario, we aim to minimize both the blue and red areas—reducing the likelihood of false discoveries <em>and</em> missed effects. Try adjusting the parameters to see how you can shrink both error regions simultaneously!</p>
<script src="https://cdn.plot.ly/plotly-3.0.1.min.js" charset="utf-8"></script>
<script src="js/alpha_beta.js" charset="utf-8"></script>
<div class="simulation">
<div class="results">
<div id="power-plot" style="width:100%;height:500px;">

</div>
</div>
<div class="settings">
<p>
<strong>Significance criterion <span class="math inline">\(\alpha\)</span>:</strong> <label for="a_value_v" id="a_value_label"></label><br> <input type="range" id="a_value" min="0.01" max="0.2" value="0.05" step="0.01">
</p>
<p>
<strong>Difference in mean <span class="math inline">\(\mu_1\)</span>:</strong> <label for="d_value_v" id="d_value_label"></label><br> <input type="range" id="d_value" min="0.1" max="3" value="2" step="0.1">
</p>
<p>
<strong>Standard Deviation <span class="math inline">\(\sigma\)</span>:</strong> <label for="sd_value_v" id="sd_value_label"></label><br> <input type="range" id="sd_value" min="0.1" max="3" value="1" step="0.1">
</p>
</div>
</div>
<p>As you will notice, all three parameters—significance criterion <span class="math inline">\(\alpha\)</span>, difference in mean <span class="math inline">\(\mu_1\)</span>, and standard deviation <span class="math inline">\(\sigma\)</span>—impact the probability of a Type II error (<span class="math inline">\(\beta\)</span>). However, they are not equally advisable to manipulate from a scientific perspective.</p>
<p>While increasing the significance criterion <span class="math inline">\(\alpha\)</span> can improve power by reducing <span class="math inline">\(\beta\)</span>, doing so comes at the cost of raising the false positive rate. This compromises the integrity of your results and increases the risk of contributing to irreproducible findings. Good scientific practice discourages simply relaxing <span class="math inline">\(\alpha\)</span> to gain statistical significance.</p>
<p>Instead, maintaining a conventional threshold (e.g., <span class="math inline">\(\alpha = 0.05\)</span>) ensures that evidence required to reject the null hypothesis remains stringent. This protects the credibility of statistical inference and helps prevent the overstatement of weak or spurious effects—one of the central concerns in the current replication crisis across many disciplines.</p>
<p>Therefore, we should seek to influence <span class="math inline">\(\beta\)</span> by adjusting parameters that improve our experimental design <strong>without compromising statistical integrity</strong>—namely, increasing effect size (e.g., through better treatment design), reducing variability (e.g., by improving measurement precision), or increasing sample size (e.g., adding more participants or simulation runs).</p>
</section>
</section>
</section>
<section id="conducting-a-power-analysis" class="level1">
<h1>Conducting a Power Analysis</h1>
<p>In the previous section, we explored several key design choices—such as sample size, randomization strategy, and control of covariates—that can greatly influence an experiment’s statistical power. To make informed design decisions, however, we must first understand how to <strong>quantify</strong> power. This is where power analysis comes in.</p>
<p>There are two primary approaches to conducting a power analysis:</p>
<ol type="1">
<li><strong>Analytical methods</strong>, which use mathematical formulas derived from statistical theory to estimate power.</li>
<li><strong>Simulation-based methods</strong>, which involve generating synthetic datasets under specified assumptions and repeatedly testing them to observe how often a statistically significant result occurs.</li>
</ol>
<p>Each approach has its advantages. Analytical formulas are fast, interpretable, and useful for standard designs—but they depend on idealized assumptions (e.g., normality, equal variances). Simulation, by contrast, is computationally more intensive but highly flexible, making it better suited for complex or customized scenarios.</p>
<p>In the sections that follow, we will explore both methods in detail and discuss how to apply them to real experimental planning.</p>
<section id="the-analytical-way" class="level2">
<h2 class="anchored" data-anchor-id="the-analytical-way">The Analytical Way</h2>
<p>There are many formulas for calculating statistical power, each tailored to a specific type of test (e.g., t-tests, ANOVA, regression). To keep things simple, we’ll focus on the classical two-sample, two-sided t-test, which compares the means of two independent groups.</p>
<p>For this case, the power (<span class="math inline">\(1 - \beta\)</span>) can be approximated using the following formula:</p>
<p><span class="math display">\[
1-\beta \approx 1 - \Phi\left( \Phi^{-1} \left(1-\frac{\alpha}{2}\right) - \frac{|\mu_t-\mu_c|\sqrt{N}}{2\sigma} \right)
\]</span></p>
<p>Here’s what these symbols mean:</p>
<ul>
<li><span class="math inline">\(\beta\)</span>: Probability of making a Type II error.</li>
<li><span class="math inline">\(\Phi\)</span>: Cumulative distribution function (CDF) for the normal distribution.</li>
<li><span class="math inline">\(\Phi^{-1}\)</span>: The inverse normal distribution function.</li>
<li><span class="math inline">\(\mu_t\)</span>: Mean outcome of the treatment group.</li>
<li><span class="math inline">\(\mu_c\)</span>: Mean outcome of the control group.</li>
<li><span class="math inline">\(\sigma\)</span>: Standard deviation (noise) of outcomes, assumed equal across groups.</li>
<li><span class="math inline">\(\alpha\)</span>: Significance level (commonly set at 0.05).</li>
<li><span class="math inline">\(N\)</span>: Total sample size.</li>
</ul>
<p>Note that this approximation becomes more accurate as <span class="math inline">\(N\)</span> increases, because under the alternative hypothesis (<span class="math inline">\(H_1\)</span>), the Student’s t-distribution converges to the standard normal distribution.</p>
<p>Let’s apply this formula to estimate the power of our experiment with <span class="math inline">\(N = 4\)</span> (2 simulated worlds per condition):</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>power_calculator <span class="ot">&lt;-</span> <span class="cf">function</span>(mu_t, mu_c, sigma, <span class="at">alpha=</span><span class="fl">0.05</span>, N, <span class="at">two.sided =</span> <span class="cn">TRUE</span>){ </span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (<span class="sc">!</span>two.sided) alpha <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">*</span> alpha</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>  inside <span class="ot">&lt;-</span> <span class="fu">qnorm</span>(<span class="dv">1</span> <span class="sc">-</span> alpha<span class="sc">/</span><span class="dv">2</span>) <span class="sc">-</span> <span class="fu">abs</span>(mu_t <span class="sc">-</span> mu_c) <span class="sc">*</span> <span class="fu">sqrt</span>(N) <span class="sc">/</span> (<span class="dv">2</span> <span class="sc">*</span> sigma)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>  <span class="dv">1</span> <span class="sc">-</span> <span class="fu">pnorm</span>(inside)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>} </span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate the sd's for our two experimental conditions</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> df_polarization <span class="sc">|&gt;</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(network <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">"neutral"</span>, <span class="st">"antipartisan"</span>)) <span class="sc">|&gt;</span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pull</span>(abs_diff_opinion_1) <span class="sc">|&gt;</span> </span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sd</span>()</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a><span class="co"># in diffs[1,2] and diffs[3,2] the values for neutral and antipartisan are stored! </span></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a><span class="fu">power_calculator</span>(</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu_t  =</span> diffs[<span class="dv">1</span>,<span class="dv">2</span>] <span class="sc">|&gt;</span> <span class="fu">pull</span>(),</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu_c  =</span> diffs[<span class="dv">3</span>,<span class="dv">2</span>] <span class="sc">|&gt;</span> <span class="fu">pull</span>(),</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>  <span class="at">sigma =</span> sigma,</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="fl">0.05</span>,</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>  <span class="at">N =</span> <span class="dv">4</span></span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.1365657</code></pre>
</div>
</div>
<p>We see that with <span class="math inline">\(N = 4\)</span>, we can only expect about 13.7% power—meaning that in roughly 86% of similar experiments, we would fail to detect a real effect, despite a substantial difference between groups.</p>
<p>How many observations do we need? For a quick approximation, we can use Lehr’s rule of thumb <span class="citation" data-cites="lehr1992">(<a href="#ref-lehr1992" role="doc-biblioref">1992</a>)</span>, which estimates sample size for an 80% powered, two-sided t-test at <span class="math inline">\(\alpha = 0.05\)</span> as:</p>
<p><span class="math display">\[
n \approx 16 \cdot \frac{\sigma^2}{(\mu_c-\mu_t)^2}
\]</span> In this formula, <span class="math inline">\(n\)</span> represents the required sample size <strong>per group</strong>. Since we are comparing two groups, the total sample size is <span class="math inline">\(N = 2 \cdot n\)</span>. Let’s apply this rule in R:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>approx_n <span class="ot">&lt;-</span> <span class="cf">function</span>(</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    mu_t,</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>    mu_c, </span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>    sigma</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>){ </span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a> <span class="dv">16</span> <span class="sc">*</span> (sigma<span class="sc">^</span><span class="dv">2</span> <span class="sc">/</span> (mu_t <span class="sc">-</span> mu_c)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>} </span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a><span class="fu">approx_n</span>(</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu_t =</span> <span class="fl">0.1681238</span>,</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu_c =</span> <span class="fl">0.0869696</span>,</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">sigma =</span> sigma</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 21.4293</code></pre>
</div>
</div>
<p>This yields an estimated <span class="math inline">\(n \geq 22\)</span> to achieve 80% power. This means in the end we must sample 44 worlds at least.</p>
<p>While this is helpful for a rough estimate, it’s not advisable to rely solely on such approximations. To improve accuracy, we can use the <code>WebPower</code> package, which offers more precise calculations and supports a range of designs, including unequal group sizes, paired samples, and more.</p>
<p>Let’s use <code>WebPower</code> to plot how power increases with <span class="math inline">\(N\)</span>, using the previously calculated effect size as an anchor.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co">#install.packages("WebPower")</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(WebPower)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="co"># we calculated the d earlyer with cohens.d</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>res <span class="ot">&lt;-</span> <span class="fu">wp.t</span>(<span class="at">n1=</span><span class="fu">seq</span>(<span class="dv">20</span>, <span class="dv">30</span>, <span class="at">by=</span><span class="dv">1</span>), <span class="at">d=</span>d<span class="sc">$</span>estimate, <span class="at">type=</span><span class="st">"two.sample"</span>, <span class="at">alternative=</span><span class="st">"two.sided"</span>)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(res)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> <span class="fl">0.8</span>, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">"red"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-N-power" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-N-power-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="week12_files/figure-html/fig-N-power-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Figure&nbsp;2: The power in our experiment depending on n.&nbsp;The total N is twice this size."><img src="week12_files/figure-html/fig-N-power-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="672"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-N-power-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: The power in our experiment depending on n.&nbsp;The total N is twice this size.
</figcaption>
</figure>
</div>
</div>
</div>
<p>We observe that while Lehr’s rule suggests <span class="math inline">\(n = 22\)</span>, a more precise estimate shows we would actually need at least <span class="math inline">\(n = 25\)</span> to achieve 80% power in our experiment.</p>
<section id="trusting-your-power-analysis" class="level3">
<h3 class="anchored" data-anchor-id="trusting-your-power-analysis">Trusting Your Power Analysis</h3>
<p>Power analyses inherently rely on uncertain assumptions. Critics might point out this circular reasoning: you use guesses about effect size and variability to determine how likely you are to detect effects.</p>
<p>However, power analysis is a powerful tool precisely because it reveals sensitivity to these assumptions. You can easily explore how your conclusions change with variations in assumed effect size, sample size, and noise.</p>
<p>For instance, vary the sample size (<span class="math inline">\(N\)</span>) to observe how power changes:</p>
<ul>
<li>Larger samples increase power.</li>
<li>Smaller effect sizes or higher variability reduce power.</li>
</ul>
<p>Conducting sensitivity analyses this way helps you make informed, transparent decisions about experimental design.</p>
<p>It’s also worth noting that our current estimates rely on just a few simulations (e.g., <span class="math inline">\(N = 4\)</span> total worlds for comparing <em>neutral</em> vs.&nbsp;<em>antipartisan</em> conditions). This low number limits the reliability of our estimates. To obtain more trustworthy results, we should next turn to simulation-based power estimation—directly measuring how often our experiment would succeed, given our current assumptions.</p>
</section>
</section>
<section id="simulation-a-practical-alternative-to-formula-based-power-analysis" class="level2">
<h2 class="anchored" data-anchor-id="simulation-a-practical-alternative-to-formula-based-power-analysis">Simulation: A Practical Alternative to Formula-Based Power Analysis</h2>
<p>Traditional formulas offer quick insights, but modern computational methods—such as simulations—can provide richer, more flexible analysis.</p>
<p>Simulation involves:</p>
<ul>
<li>Repeatedly generating hypothetical datasets based on your assumptions.</li>
<li>Conducting statistical tests on these simulated datasets.</li>
<li>Calculating the proportion of simulated experiments detecting significant effects.</li>
</ul>
<p>This approach makes fewer assumptions and lets you explore complex scenarios realistically, especially useful for advanced or novel experimental designs.</p>
<p>Simulations thus enhance your understanding of an experiment’s robustness and strengthen the validity of your experimental findings.</p>
</section>
<section id="implementation-in-r" class="level2">
<h2 class="anchored" data-anchor-id="implementation-in-r">Implementation in R</h2>
<p>Under normal circumstances—when we’re interested in individual-level outcomes—our <code>run_simulation()</code> function would suffice for estimating the required <span class="math inline">\(N\)</span>. We could vary <span class="math inline">\(N\)</span> directly in <code>tbl_parameter</code> and track when the treatment becomes significant in more than 80% of the replications.</p>
<p>However, in our case, we’re interested in a <strong>property of the world</strong> itself (i.e., polarization), not in individual behavior. In this context, the <code>replications</code> used in <code>run_simulation()</code> actually correspond to the number of <strong>independent worlds</strong> (or experimental sessions) we simulate per treatment.</p>
<p>A clean and robust solution would be to write a <code>run_meta_simulation()</code> function that wraps around <code>run_simulation()</code> and handles repeated simulation for each sample size, collecting p-values across runs. However, such an implementation is complex. Instead, we’ll take a shortcut and slightly modify how we use our existing <code>run_simulation()</code>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>replications <span class="ot">=</span> <span class="dv">100</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>worlds_per_treatment_max <span class="ot">=</span> <span class="dv">40</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>simulation  <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">model =</span> <span class="st">"calibrated_model"</span>,</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">replications =</span> worlds_per_treatment_max <span class="sc">*</span> replications,</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">tbl_parameter =</span> <span class="fu">expand.grid</span>(</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">network =</span> <span class="fu">c</span>(<span class="st">"neutral"</span>, <span class="st">"antipartisan"</span>)</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">master_seed  =</span> <span class="dv">42</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here we define 100 replications and 40 as the maximum number of worlds per treatment we want to simulate.</p>
<p>Now we run this simulation:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>meta_results <span class="ot">&lt;-</span> <span class="fu">run_simulation</span>(simulation)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The idea is as follows: replication 1 to 100 corresponds to the first world, 101 to 200 to the second world, and so on. If we want to compare, for example, 10 <em>neutral</em> worlds with 5 <em>antipartisan</em> worlds, we can take replications 1, 101, 201, …, 901 and compare those to the corresponding replications for the other condition.</p>
<p>To automate this, we write a function that calculates power by looping over replications, collecting p-values, and computing the share of tests that fall below our <span class="math inline">\(\alpha\)</span> threshold:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>get_power_from_simulation <span class="ot">&lt;-</span> <span class="cf">function</span>(</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>  df,</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>  n_1, </span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>  n_2, </span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>  by_var,    <span class="co"># unquoted column name, e.g. network</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>  by_val1,   <span class="co"># value of by_var for group 1, e.g. "neutral"</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>  by_val2,   <span class="co"># value of by_var for group 2, e.g. "antipartisan"</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>  replications</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>){</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>  by_var <span class="ot">&lt;-</span> <span class="fu">enquo</span>(by_var)</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Pre‐filter the two condition sets once:</span></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>  df_by <span class="ot">&lt;-</span> df <span class="sc">|&gt;</span> <span class="fu">filter</span>((<span class="sc">!!</span>by_var) <span class="sc">==</span> by_val1 <span class="sc">|</span>(<span class="sc">!!</span>by_var) <span class="sc">==</span> by_val2)</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>  rejections <span class="ot">&lt;-</span> <span class="fu">vapply</span>( <span class="fu">seq_len</span>(replications),  <span class="at">FUN.VALUE =</span> <span class="fu">logical</span>(<span class="dv">1</span>), <span class="cf">function</span>(i) </span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>      idx1 <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> i, <span class="at">by =</span> replications, <span class="at">length.out =</span> n_1)</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>      idx2 <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> i, <span class="at">by =</span> replications, <span class="at">length.out =</span> n_2)</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>      df_sel <span class="ot">&lt;-</span> df_by <span class="sc">|&gt;</span> </span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>        <span class="fu">filter</span>(</span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>          ((<span class="sc">!!</span>by_var) <span class="sc">==</span> by_val1 <span class="sc">|</span> rep <span class="sc">%in%</span> idx1) <span class="sc">&amp;</span></span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>          ((<span class="sc">!!</span>by_var) <span class="sc">==</span> by_val2 <span class="sc">|</span> rep <span class="sc">%in%</span> idx2)</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>      <span class="fu">run_test</span>(df_sel)</span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a>  <span class="co"># proportion of rejections = estimated power</span></span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mean</span>(rejections)</span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a>run_test <span class="ot">&lt;-</span> <span class="cf">function</span>(df){</span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a>  <span class="fu">t.test</span>(abs_diff_opinion_1 <span class="sc">~</span> network, <span class="at">data =</span> df, <span class="at">alternative =</span> <span class="st">"two.sided"</span>)<span class="sc">$</span>p.value <span class="sc">&lt;</span> <span class="fl">0.05</span></span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Note that we defined a small helper function, <code>run_test()</code>, which performs a <span class="math inline">\(t\)</span>-test. By isolating the test logic in its own function, we make it easy to later substitute alternative statistical tests—simply by modifying this subfunction—without needing to change the surrounding analysis pipeline.</p>
<p>We can now apply this function to estimate power for 10 <em>neutral</em> and 5 <em>antipartisan</em> worlds:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>df_polarization <span class="ot">&lt;-</span> <span class="fu">calc_polarization</span>(meta_results)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="fu">get_power_from_simulation</span>(</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">df         =</span> df_polarization,</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">n_1        =</span> <span class="dv">10</span>,</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">n_2        =</span> <span class="dv">5</span>,</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">by_var     =</span> network,</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">by_val1    =</span> <span class="st">"neutral"</span>,</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">by_val2    =</span> <span class="st">"antipartisan"</span>,</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">replications =</span> <span class="dv">100</span></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.23</code></pre>
</div>
</div>
<p>Not surprisingly, power is still low—around 23%. But now, let’s systematically explore how power increases as we raise the number of worlds per treatment:</p>
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Show R Code (Power plot)</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>sample_size <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">10</span>, <span class="dv">30</span>, <span class="at">by =</span> <span class="dv">1</span>)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">sample_size =</span> sample_size) <span class="sc">|&gt;</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">power =</span> <span class="fu">map_dbl</span>(sample_size, <span class="sc">~</span> </span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>      <span class="fu">get_power_from_simulation</span>(</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>        <span class="at">df           =</span> df_polarization,</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>        <span class="at">n_1          =</span> .x,</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>        <span class="at">n_2          =</span> .x,</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>        <span class="at">by_var       =</span> network,</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>        <span class="at">by_val1      =</span> <span class="st">"neutral"</span>,</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>        <span class="at">by_val2      =</span> <span class="st">"antipartisan"</span>,</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>        <span class="at">replications =</span> <span class="dv">100</span></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>      )</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(plotly)</span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_ly</span>(df, </span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>        <span class="at">x =</span> <span class="sc">~</span>sample_size, </span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>        <span class="at">y =</span> <span class="sc">~</span>power, </span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>        <span class="at">type =</span> <span class="st">'scatter'</span>, </span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a>        <span class="at">name =</span> <span class="st">'Power by n'</span>,</span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a>        <span class="at">mode =</span> <span class="st">'lines+markers'</span>,</span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a>        <span class="at">hoverinfo =</span> <span class="st">'text'</span>,</span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a>        <span class="at">text =</span> <span class="sc">~</span><span class="fu">paste0</span>(<span class="st">'N = '</span>, sample_size, <span class="st">'&lt;br&gt;Power = '</span>, <span class="fu">round</span>(power, <span class="dv">2</span>))</span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_lines</span>(<span class="at">x =</span> <span class="sc">~</span>sample_size, </span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a>            <span class="at">y =</span> <span class="fu">rep</span>(<span class="fl">0.8</span>, <span class="fu">nrow</span>(df)), </span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a>            <span class="at">line =</span> <span class="fu">list</span>(<span class="at">dash =</span> <span class="st">'dash'</span>, <span class="at">color =</span> <span class="st">'red'</span>),</span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a>            <span class="at">name =</span> <span class="st">'80% Power'</span>) <span class="sc">%&gt;%</span></span>
<span id="cb19-33"><a href="#cb19-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layout</span>(</span>
<span id="cb19-34"><a href="#cb19-34" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">'Power vs. Sample Size'</span>,</span>
<span id="cb19-35"><a href="#cb19-35" aria-hidden="true" tabindex="-1"></a>    <span class="at">xaxis =</span> <span class="fu">list</span>(<span class="at">title =</span> <span class="st">'Sample Size (N)'</span>),</span>
<span id="cb19-36"><a href="#cb19-36" aria-hidden="true" tabindex="-1"></a>    <span class="at">yaxis =</span> <span class="fu">list</span>(<span class="at">title =</span> <span class="st">'Power'</span>),</span>
<span id="cb19-37"><a href="#cb19-37" aria-hidden="true" tabindex="-1"></a>    <span class="at">showlegend =</span> <span class="cn">TRUE</span></span>
<span id="cb19-38"><a href="#cb19-38" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="fig-N-power2" class="cell-output-display quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-N-power2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="plotly html-widget html-fill-item" id="htmlwidget-7cf3f5005b32e5b9708a" style="width:100%;height:464px;"></div>
<script type="application/json" data-for="htmlwidget-7cf3f5005b32e5b9708a">{"x":{"visdat":{"39a014ac68c3":["function () ","plotlyVisDat"]},"cur_data":"39a014ac68c3","attrs":{"39a014ac68c3":{"x":{},"y":{},"mode":"lines+markers","hoverinfo":"text","text":{},"name":"Power by n","alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter"},"39a014ac68c3.1":{"x":{},"y":[0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004],"mode":"lines","hoverinfo":"text","text":{},"name":"80% Power","alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter","line":{"dash":"dash","color":"red"},"inherit":true}},"layout":{"margin":{"b":40,"l":60,"t":25,"r":10},"title":"Power vs. Sample Size","xaxis":{"domain":[0,1],"automargin":true,"title":"Sample Size (N)"},"yaxis":{"domain":[0,1],"automargin":true,"title":"Power"},"showlegend":true,"hovermode":"closest"},"source":"A","config":{"modeBarButtonsToAdd":["hoverclosest","hovercompare"],"showSendToCloud":false},"data":[{"x":[10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30],"y":[0.20999999999999999,0.26000000000000001,0.32000000000000001,0.40999999999999998,0.51000000000000001,0.59999999999999998,0.68999999999999995,0.71999999999999997,0.78000000000000003,0.87,0.92000000000000004,0.94999999999999996,0.96999999999999997,0.97999999999999998,0.97999999999999998,0.97999999999999998,0.98999999999999999,1,1,1,1],"mode":"lines+markers","hoverinfo":["text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text"],"text":["N = 10<br>Power = 0.21","N = 11<br>Power = 0.26","N = 12<br>Power = 0.32","N = 13<br>Power = 0.41","N = 14<br>Power = 0.51","N = 15<br>Power = 0.6","N = 16<br>Power = 0.69","N = 17<br>Power = 0.72","N = 18<br>Power = 0.78","N = 19<br>Power = 0.87","N = 20<br>Power = 0.92","N = 21<br>Power = 0.95","N = 22<br>Power = 0.97","N = 23<br>Power = 0.98","N = 24<br>Power = 0.98","N = 25<br>Power = 0.98","N = 26<br>Power = 0.99","N = 27<br>Power = 1","N = 28<br>Power = 1","N = 29<br>Power = 1","N = 30<br>Power = 1"],"name":"Power by n","type":"scatter","marker":{"color":"rgba(31,119,180,1)","line":{"color":"rgba(31,119,180,1)"}},"error_y":{"color":"rgba(31,119,180,1)"},"error_x":{"color":"rgba(31,119,180,1)"},"line":{"color":"rgba(31,119,180,1)"},"xaxis":"x","yaxis":"y","frame":null},{"x":[10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30],"y":[0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004],"mode":"lines","hoverinfo":["text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text"],"text":["N = 10<br>Power = 0.21","N = 11<br>Power = 0.26","N = 12<br>Power = 0.32","N = 13<br>Power = 0.41","N = 14<br>Power = 0.51","N = 15<br>Power = 0.6","N = 16<br>Power = 0.69","N = 17<br>Power = 0.72","N = 18<br>Power = 0.78","N = 19<br>Power = 0.87","N = 20<br>Power = 0.92","N = 21<br>Power = 0.95","N = 22<br>Power = 0.97","N = 23<br>Power = 0.98","N = 24<br>Power = 0.98","N = 25<br>Power = 0.98","N = 26<br>Power = 0.99","N = 27<br>Power = 1","N = 28<br>Power = 1","N = 29<br>Power = 1","N = 30<br>Power = 1"],"name":"80% Power","type":"scatter","line":{"color":"red","dash":"dash"},"marker":{"color":"rgba(255,127,14,1)","line":{"color":"rgba(255,127,14,1)"}},"error_y":{"color":"rgba(255,127,14,1)"},"error_x":{"color":"rgba(255,127,14,1)"},"xaxis":"x","yaxis":"y","frame":null}],"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.20000000000000001,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-N-power2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: The power in our experiment depending on n (simulation results).
</figcaption>
</figure>
</div>
</div>
<p>We observe that even with a symmetric sample size of 19 worlds per condition or an <span class="math inline">\(N=38\)</span>, we achieve over 80% power. This is a bit lower than our earlier approximation using analytical methods—likely because our original estimate was based on only 4 observations to calculate <span class="math inline">\(\sigma\)</span>, introducing higher variability.</p>
<p>We can inspect the effect size again for the the complete run (all 8000 worlds):</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cohen.d</span>(</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">formula =</span> abs_diff_opinion_1 <span class="sc">~</span> network,</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">data    =</span> df_polarization <span class="sc">|&gt;</span> <span class="fu">filter</span>(network <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">"neutral"</span>, <span class="st">"antipartisan"</span>)) <span class="sc">|&gt;</span> </span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">droplevels</span>(),</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">pooled  =</span> <span class="cn">TRUE</span>,</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">hedges.correction =</span> <span class="cn">FALSE</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Cohen's d

d estimate: -0.7979546 (medium)
95 percent confidence interval:
     lower      upper 
-0.8434983 -0.7524109 </code></pre>
</div>
</div>
<p>We see that this is not far off what we initially estimated.</p>
<p>This simulation-based approach gives us a robust, assumption-light estimate of the power under realistic experimental conditions. It’s particularly valuable when classical formulas are too simplistic for the design at hand.</p>
</section>
<section id="why-use-unequal-sample-sizes" class="level2">
<h2 class="anchored" data-anchor-id="why-use-unequal-sample-sizes">Why Use Unequal Sample Sizes?</h2>
<p>Throughout this chapter, we have primarily assumed equal sample sizes for treatment and control groups (i.e., <span class="math inline">\(n_0 = n_1\)</span>). This design is indeed statistically optimal: comparing 10 vs.&nbsp;10 yields more power than, for example, 19 vs.&nbsp;1. In general, power is maximized when group sizes are balanced, assuming all else is equal.</p>
<p>However, there are several situations in which using <strong>unequal sample sizes</strong> is not only acceptable, but actually advisable.</p>
<section id="cost-constraints" class="level3">
<h3 class="anchored" data-anchor-id="cost-constraints">1. Cost Constraints</h3>
<p>In some experiments, one treatment group may be significantly more expensive to implement than the other. For example, if administering the treatment requires costly resources—say, specialist time, hardware, or financial incentives—while the control group involves only basic measurement, then a balanced design may be impractical.</p>
<p>Instead of running a 10 vs.&nbsp;10 trial, you might run 15 vs.&nbsp;8. Although this introduces some statistical inefficiency, it may still be preferable if it leads to lower overall cost. The trade-off here is between statistical power and budget efficiency: slightly reduced power may be acceptable if it enables more feasible execution.</p>
</section>
<section id="logistical-or-external-constraints" class="level3">
<h3 class="anchored" data-anchor-id="logistical-or-external-constraints">2. Logistical or External Constraints</h3>
<p>Sometimes, sample sizes in one group are fixed by circumstances beyond the researcher’s control. For example:</p>
<ul>
<li>You may only have access to a limited number of treated units (e.g., policy participants, rare populations, or invited experts).</li>
<li>The treatment group could be capped due to institutional or ethical limits.</li>
<li>Recruitment channels might produce uneven inflows into treatment and control.</li>
</ul>
<p>In such cases, the sample size for one group is fixed, and the researcher must calculate the <strong>required sample size for the other group</strong> to achieve the desired power.</p>
</section>
<section id="adaptive-designs-and-reweighting" class="level3">
<h3 class="anchored" data-anchor-id="adaptive-designs-and-reweighting">3. Adaptive Designs and Reweighting</h3>
<p>Unequal sample sizes may also emerge as a result of <strong>adaptive experimental designs</strong>, where assignment probabilities shift over time (e.g., in multi-armed bandits). Or, they may reflect <strong>intentional oversampling</strong> of one group to ensure adequate representation or variance for subgroup analysis.</p>
<p>Statistical techniques such as weighted regression or generalized estimating equations can help correct for imbalances, especially in observational or quasi-experimental contexts.</p>
<p>In summary, while equal sample sizes provide maximum statistical efficiency, real-world considerations—such as cost, availability, and ethics—can justify unequal designs. In such cases, power analysis becomes especially important to determine how best to allocate limited resources while still preserving the ability to detect meaningful effects.</p>
</section>
</section>
</section>
<section id="increasing-power-further" class="level1">
<h1>Increasing Power Further</h1>
<p>Until now, we have primarily focused on increasing power by adjusting <strong>sample size</strong>—arguably the most straightforward and commonly used approach. However, as previously discussed, sample size is not the only lever available to researchers. Another highly effective strategy is to use the <strong>most efficient test statistic</strong> for the research question and data structure at hand.</p>
<p>But what exactly does that mean? To understand this, let’s reconsider the structure of our experiment:</p>
<p><span class="math display">\[
R \longrightarrow T_0 \longrightarrow Y_0 \newline
R \longrightarrow T_1 \longrightarrow Y_1
\]</span> In this setup, participants are randomized (<span class="math inline">\(R\)</span>) into either a control group (<span class="math inline">\(T_0\)</span>, <em>neutral</em>) or a treatment group (<span class="math inline">\(T_1\)</span>, <em>antipartisan</em>), and we then measure the outcome—average partisan difference in opinions—after the treatment.</p>
<p>However, our actual experimental design contains more information:</p>
<p><span class="math display">\[
R \longrightarrow Y_0^{t_0} \longrightarrow T_0 \longrightarrow Y_0^{t_1} \newline
R \longrightarrow Y_1^{t_0} \longrightarrow T_1 \longrightarrow Y_1^{t_1}
\]</span> That is, we also collect an initial measurement of opinions <strong>before</strong> treatment assignment, allowing us to observe polarization at baseline (<span class="math inline">\(Y^{t_0}\)</span>), in addition to the post-treatment outcome (<span class="math inline">\(Y^{t_1}\)</span>).</p>
<p>This pre-treatment measurement allows for a more precise analysis. Instead of relying solely on a simple <span class="math inline">\(t\)</span>-test comparing post-treatment outcomes, we can now use a regression model that adjusts for baseline polarization. This approach not only increases statistical power but also helps account for initial differences between groups.</p>
<p>Fortunately, our <code>calc_polarization()</code> function supports this by allowing us to extract both final and initial polarization measures:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>df_polarization <span class="ot">&lt;-</span> <span class="fu">calc_polarization</span>(meta_results) <span class="sc">|&gt;</span> <span class="co"># get final polarization</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_cols</span>(</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">calc_polarization</span>(meta_results, <span class="at">table =</span> <span class="st">"init"</span>) <span class="sc">|&gt;</span> <span class="co"># get inital polarization</span></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>      <span class="fu">rename</span>(<span class="at">abs_diff_opinion_1_init =</span> abs_diff_opinion_1) <span class="sc">|&gt;</span> </span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>      dplyr<span class="sc">::</span><span class="fu">select</span>(abs_diff_opinion_1_init)</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Next, we redefine our <code>run_test()</code> function to include <code>abs_diff_opinion_1_init</code> as a covariate in the regression:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>run_test <span class="ot">&lt;-</span> <span class="cf">function</span>(df){</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>    fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(abs_diff_opinion_1  <span class="sc">~</span> network <span class="sc">+</span> abs_diff_opinion_1_init,</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>              <span class="at">data =</span> df</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>              )</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>    coefs <span class="ot">&lt;-</span> <span class="fu">summary</span>(fit)<span class="sc">$</span>coefficients</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># coefficient name for group effect</span></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>    coef_name <span class="ot">&lt;-</span> <span class="st">"networkantipartisan"</span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>    p_val <span class="ot">&lt;-</span> coefs[coef_name, <span class="st">"Pr(&gt;|t|)"</span>]</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>    p_val <span class="sc">&lt;</span> <span class="fl">0.05</span> <span class="co"># alpha</span></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>With this updated model in place, we can now rerun our power analysis using regression instead of a <span class="math inline">\(t\)</span>-test:</p>
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Show R Code (Power plot)</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>sample_size <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">2</span>, <span class="dv">15</span>, <span class="at">by =</span> <span class="dv">1</span>)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">sample_size =</span> sample_size) <span class="sc">|&gt;</span></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">power =</span> <span class="fu">map_dbl</span>(sample_size, <span class="sc">~</span> </span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>      <span class="fu">get_power_from_simulation</span>(</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>        <span class="at">df           =</span> df_polarization,</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>        <span class="at">n_1          =</span> .x,</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>        <span class="at">n_2          =</span> .x,</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>        <span class="at">by_var       =</span> network,</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>        <span class="at">by_val1      =</span> <span class="st">"neutral"</span>,</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>        <span class="at">by_val2      =</span> <span class="st">"antipartisan"</span>,</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>        <span class="at">replications =</span> <span class="dv">100</span></span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>      )</span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(plotly)</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_ly</span>(df, </span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a>        <span class="at">x =</span> <span class="sc">~</span>sample_size, </span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a>        <span class="at">y =</span> <span class="sc">~</span>power, </span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a>        <span class="at">type =</span> <span class="st">'scatter'</span>, </span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a>        <span class="at">name =</span> <span class="st">'Power by n'</span>,</span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a>        <span class="at">mode =</span> <span class="st">'lines+markers'</span>,</span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a>        <span class="at">hoverinfo =</span> <span class="st">'text'</span>,</span>
<span id="cb24-28"><a href="#cb24-28" aria-hidden="true" tabindex="-1"></a>        <span class="at">text =</span> <span class="sc">~</span><span class="fu">paste0</span>(<span class="st">'N = '</span>, sample_size, <span class="st">'&lt;br&gt;Power = '</span>, <span class="fu">round</span>(power, <span class="dv">2</span>))</span>
<span id="cb24-29"><a href="#cb24-29" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb24-30"><a href="#cb24-30" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_lines</span>(<span class="at">x =</span> <span class="sc">~</span>sample_size, </span>
<span id="cb24-31"><a href="#cb24-31" aria-hidden="true" tabindex="-1"></a>            <span class="at">y =</span> <span class="fu">rep</span>(<span class="fl">0.8</span>, <span class="fu">nrow</span>(df)), </span>
<span id="cb24-32"><a href="#cb24-32" aria-hidden="true" tabindex="-1"></a>            <span class="at">line =</span> <span class="fu">list</span>(<span class="at">dash =</span> <span class="st">'dash'</span>, <span class="at">color =</span> <span class="st">'red'</span>),</span>
<span id="cb24-33"><a href="#cb24-33" aria-hidden="true" tabindex="-1"></a>            <span class="at">name =</span> <span class="st">'80% Power'</span>) <span class="sc">%&gt;%</span></span>
<span id="cb24-34"><a href="#cb24-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layout</span>(</span>
<span id="cb24-35"><a href="#cb24-35" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">'Power vs. Sample Size'</span>,</span>
<span id="cb24-36"><a href="#cb24-36" aria-hidden="true" tabindex="-1"></a>    <span class="at">xaxis =</span> <span class="fu">list</span>(<span class="at">title =</span> <span class="st">'Sample Size (N)'</span>),</span>
<span id="cb24-37"><a href="#cb24-37" aria-hidden="true" tabindex="-1"></a>    <span class="at">yaxis =</span> <span class="fu">list</span>(<span class="at">title =</span> <span class="st">'Power'</span>),</span>
<span id="cb24-38"><a href="#cb24-38" aria-hidden="true" tabindex="-1"></a>    <span class="at">showlegend =</span> <span class="cn">TRUE</span></span>
<span id="cb24-39"><a href="#cb24-39" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="fig-N-power3" class="cell-output-display quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-N-power3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="plotly html-widget html-fill-item" id="htmlwidget-26cea16572b968fc750b" style="width:100%;height:464px;"></div>
<script type="application/json" data-for="htmlwidget-26cea16572b968fc750b">{"x":{"visdat":{"39a0232428c7":["function () ","plotlyVisDat"]},"cur_data":"39a0232428c7","attrs":{"39a0232428c7":{"x":{},"y":{},"mode":"lines+markers","hoverinfo":"text","text":{},"name":"Power by n","alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter"},"39a0232428c7.1":{"x":{},"y":[0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004],"mode":"lines","hoverinfo":"text","text":{},"name":"80% Power","alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter","line":{"dash":"dash","color":"red"},"inherit":true}},"layout":{"margin":{"b":40,"l":60,"t":25,"r":10},"title":"Power vs. Sample Size","xaxis":{"domain":[0,1],"automargin":true,"title":"Sample Size (N)"},"yaxis":{"domain":[0,1],"automargin":true,"title":"Power"},"showlegend":true,"hovermode":"closest"},"source":"A","config":{"modeBarButtonsToAdd":["hoverclosest","hovercompare"],"showSendToCloud":false},"data":[{"x":[2,3,4,5,6,7,8,9,10,11,12,13,14,15],"y":[0.14000000000000001,0.5,0.87,0.98999999999999999,1,1,1,1,1,1,1,1,1,1],"mode":"lines+markers","hoverinfo":["text","text","text","text","text","text","text","text","text","text","text","text","text","text"],"text":["N = 2<br>Power = 0.14","N = 3<br>Power = 0.5","N = 4<br>Power = 0.87","N = 5<br>Power = 0.99","N = 6<br>Power = 1","N = 7<br>Power = 1","N = 8<br>Power = 1","N = 9<br>Power = 1","N = 10<br>Power = 1","N = 11<br>Power = 1","N = 12<br>Power = 1","N = 13<br>Power = 1","N = 14<br>Power = 1","N = 15<br>Power = 1"],"name":"Power by n","type":"scatter","marker":{"color":"rgba(31,119,180,1)","line":{"color":"rgba(31,119,180,1)"}},"error_y":{"color":"rgba(31,119,180,1)"},"error_x":{"color":"rgba(31,119,180,1)"},"line":{"color":"rgba(31,119,180,1)"},"xaxis":"x","yaxis":"y","frame":null},{"x":[2,3,4,5,6,7,8,9,10,11,12,13,14,15],"y":[0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004],"mode":"lines","hoverinfo":["text","text","text","text","text","text","text","text","text","text","text","text","text","text"],"text":["N = 2<br>Power = 0.14","N = 3<br>Power = 0.5","N = 4<br>Power = 0.87","N = 5<br>Power = 0.99","N = 6<br>Power = 1","N = 7<br>Power = 1","N = 8<br>Power = 1","N = 9<br>Power = 1","N = 10<br>Power = 1","N = 11<br>Power = 1","N = 12<br>Power = 1","N = 13<br>Power = 1","N = 14<br>Power = 1","N = 15<br>Power = 1"],"name":"80% Power","type":"scatter","line":{"color":"red","dash":"dash"},"marker":{"color":"rgba(255,127,14,1)","line":{"color":"rgba(255,127,14,1)"}},"error_y":{"color":"rgba(255,127,14,1)"},"error_x":{"color":"rgba(255,127,14,1)"},"xaxis":"x","yaxis":"y","frame":null}],"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.20000000000000001,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-N-power3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: The power in our experiment depending on n (simulation results).
</figcaption>
</figure>
</div>
</div>
<p>As shown in the plot, adjusting for baseline polarization dramatically improves the power of our experiment. With this more sophisticated approach, a sample size of just <span class="math inline">\(n = 4\)</span> per group is already sufficient to surpass 80% power. At <span class="math inline">\(n = 5\)</span>, power approaches nearly 100%.</p>
<p>This is a <strong>significant improvement</strong> over our initial <span class="math inline">\(t\)</span>-test-only approach—and one that could save considerable time and resources. It underscores the value of leveraging all available data and using appropriate statistical models to maximize efficiency in experimental design.</p>
</section>
<section id="conclusion" class="level1">
<h1>🧩 Conclusion</h1>
<p>In this chapter, we explored how power analysis serves as a critical tool for designing effective and efficient experiments. We began by revisiting the statistical foundations—clarifying the trade-off between <strong>power</strong> (<span class="math inline">\(1 - \beta\)</span>) and <strong>specificity</strong> (<span class="math inline">\(1 - \alpha\)</span>)—and showed how low-powered studies can lead to ambiguous or misleading conclusions.</p>
<p>We then examined both <strong>analytical</strong> and <strong>simulation-based</strong> methods for calculating statistical power. While analytical formulas offer quick approximations, simulation-based approaches provide the flexibility needed for more complex or realistic experimental designs—especially in agent-based modeling contexts.</p>
<p>Using our own calibrated opinion dynamics model, we demonstrated how simulation can help estimate the number of “worlds” required to detect meaningful treatment effects. We also showed how controlling for pre-treatment measurements—such as initial polarization—can significantly increase statistical power, allowing us to draw stronger conclusions with fewer resources.</p>
<p>In practice, power analysis supports better planning, more transparent preregistration, and stronger scientific claims. Whether you’re preparing a grant proposal, designing a pilot, or running a full-scale experiment, power analysis ensures that your study is not only feasible but also meaningful.</p>
<p>Ultimately, power analysis is not just a technical requirement—it’s a safeguard for scientific integrity and a cornerstone of responsible research design.</p>


<!-- -->


</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-lehr1992" class="csl-entry" role="listitem">
Lehr, Robert. 1992. <span>“Sixteen S<span>-</span>Squared Over D<span>-</span>Squared: A Relation for Crude Sample Size Estimates.”</span> <em>Statistics in Medicine</em> 11 (8): 1099–1102. <a href="https://doi.org/10.1002/sim.4780110811">https://doi.org/10.1002/sim.4780110811</a>.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Note that polarization, unlike an opinion, is not an individual property. Instead, it reflects a collective feature of the system. In agent-based modeling terms, polarization is a property of an entire world, not of any one agent.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>In this interactive graph, <span class="math inline">\(\sigma\)</span> does not only represent standard deviation in the classical sense, but can also serve as a proxy for sample size. Increasing the sample size reduces uncertainty around the estimated mean, effectively shrinking the observed standard deviation due to the law of large numbers. In that sense, decreasing <span class="math inline">\(\sigma\)</span> here mimics the effect of increasing the number of observations.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section><section class="quarto-appendix-contents" id="quarto-copyright"><h2 class="anchored quarto-appendix-heading">Copyright</h2><div class="quarto-appendix-contents"><div>Copyright Sascha Grehl, 2025. All Rights Reserved</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb25" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="co">  title: "Experimental Sociology - Week 12"</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="co">  subtitle: "Power Analysis"</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a><span class="co">  date: "2025-06-20"</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(igraph)</span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a>Last week, we focused on calibration, allowing us to fine-tune our model parameters to closely match empirical data. With a calibrated model in hand, we can now run experiments in silico-simulating experimental conditions in a virtual environment. This step enables us to explore key design questions, refine our experimental setup, and improve the planning of real-world studies.</span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a>Consider the question of how people’s opinions are influenced by others. More specifically, we are interested in how different network topologies affect polarization within a population.<span class="ot">[^1]</span> We assume that the influence of a neutral source differs from the influence of someone with shared partisanship, and also from someone with opposing partisanship. This sets the stage for a in silicio experiment. @fig-network-conditions shows four different experimental treatments that participants might encounter when learning about the opinions of others:</span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a><span class="ot">[^1]: </span>Note that polarization, unlike an opinion, is not an individual property. Instead, it reflects a collective feature of the system. In agent-based modeling terms, polarization is a property of an entire world, not of any one agent.</span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a><span class="al">![Schematic depiction of the different network topologies as seen from the participant's perspective (red nodes). White nodes have a similar partisanship, black nodes have a dissimilar partisanship. The partisanship of gray nodes is not revealed (The total network (not shown) has a size of ten people).](images/clipboard-2383815932.png)</span>{#fig-network-conditions width="704"}</span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a>Each treatment reflects a different network topology a certain agent (ego, the red circle) is a part of. The experiment should proceeds as follows: first, participants’ initial opinions are recorded individually. Then, they are informed about the opinions of their neighbors, after which their opinions are measured again. In the first (*neutral*) condition, ego learns only the opinions of four others, without knowing their partisanship. In the other three conditions, ego also learns their neighbors' party preferences—either all similar (*partisan*), all opposing (*antipartisan*), or a balanced mix (*mixed*).</span>
<span id="cb25-24"><a href="#cb25-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-25"><a href="#cb25-25" aria-hidden="true" tabindex="-1"></a>We assume that neutral influence ($\mu$) is weaker than influence from like-minded individuals ($\mu_P$), while influence from those with opposing partisanship ($\mu_A$) is weaker still—or even negative. In short, we expect $\mu_A &lt; \mu &lt; \mu_P$. Drawing on empirical findings from previous studies, we use calibrated values for these parameters (<span class="in">`calibrated_model`</span>) to run our experiment in silico:</span>
<span id="cb25-26"><a href="#cb25-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-29"><a href="#cb25-29" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-30"><a href="#cb25-30" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb25-31"><a href="#cb25-31" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">read_rds</span>(<span class="st">"../data/abm-opinion3/week12_results.rds"</span>)</span>
<span id="cb25-32"><a href="#cb25-32" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-33"><a href="#cb25-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-36"><a href="#cb25-36" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-37"><a href="#cb25-37" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb25-38"><a href="#cb25-38" aria-hidden="true" tabindex="-1"></a>simulation  <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb25-39"><a href="#cb25-39" aria-hidden="true" tabindex="-1"></a>  <span class="at">model =</span> <span class="st">"calibrated_model"</span>,</span>
<span id="cb25-40"><a href="#cb25-40" aria-hidden="true" tabindex="-1"></a>  <span class="at">replications =</span> <span class="dv">2</span>,</span>
<span id="cb25-41"><a href="#cb25-41" aria-hidden="true" tabindex="-1"></a>  <span class="at">tbl_parameter =</span> <span class="fu">expand.grid</span>(</span>
<span id="cb25-42"><a href="#cb25-42" aria-hidden="true" tabindex="-1"></a>    <span class="at">network =</span> <span class="fu">c</span>(<span class="st">"neutral"</span>, <span class="st">"partisan"</span>, <span class="st">"antipartisan"</span>, <span class="st">"mixed"</span>)</span>
<span id="cb25-43"><a href="#cb25-43" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb25-44"><a href="#cb25-44" aria-hidden="true" tabindex="-1"></a>  <span class="at">master_seed  =</span> <span class="dv">42</span></span>
<span id="cb25-45"><a href="#cb25-45" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb25-46"><a href="#cb25-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-47"><a href="#cb25-47" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">run_simulation</span>(simulation)</span>
<span id="cb25-48"><a href="#cb25-48" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-49"><a href="#cb25-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-50"><a href="#cb25-50" aria-hidden="true" tabindex="-1"></a>To analyze the simulation output, we compute polarization within each simulated world. For this, we calculate the average absolute opinion difference between the two partisan groups. The use of absolute differences reflects our focus on the magnitude of disagreement, not which group supports which view.</span>
<span id="cb25-51"><a href="#cb25-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-54"><a href="#cb25-54" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-55"><a href="#cb25-55" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb25-56"><a href="#cb25-56" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: Show R Code (calc_polarization function)</span></span>
<span id="cb25-57"><a href="#cb25-57" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(glue)</span>
<span id="cb25-58"><a href="#cb25-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-59"><a href="#cb25-59" aria-hidden="true" tabindex="-1"></a>calc_polarization <span class="ot">&lt;-</span> <span class="cf">function</span>(</span>
<span id="cb25-60"><a href="#cb25-60" aria-hidden="true" tabindex="-1"></a>  results,</span>
<span id="cb25-61"><a href="#cb25-61" aria-hidden="true" tabindex="-1"></a>  <span class="at">table  =</span> <span class="st">"final"</span></span>
<span id="cb25-62"><a href="#cb25-62" aria-hidden="true" tabindex="-1"></a>) {</span>
<span id="cb25-63"><a href="#cb25-63" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (table <span class="sc">==</span> <span class="st">"final"</span>) {</span>
<span id="cb25-64"><a href="#cb25-64" aria-hidden="true" tabindex="-1"></a>    df <span class="ot">&lt;-</span> results<span class="sc">$</span>df_final_worlds</span>
<span id="cb25-65"><a href="#cb25-65" aria-hidden="true" tabindex="-1"></a>  } <span class="cf">else</span> <span class="cf">if</span> (table <span class="sc">==</span> <span class="st">"init"</span>) {</span>
<span id="cb25-66"><a href="#cb25-66" aria-hidden="true" tabindex="-1"></a>    df <span class="ot">&lt;-</span> results<span class="sc">$</span>df_init_worlds</span>
<span id="cb25-67"><a href="#cb25-67" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb25-68"><a href="#cb25-68" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb25-69"><a href="#cb25-69" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Identify the columns defining each "world"</span></span>
<span id="cb25-70"><a href="#cb25-70" aria-hidden="true" tabindex="-1"></a>  start <span class="ot">&lt;-</span> <span class="fu">which</span>(<span class="fu">names</span>(df) <span class="sc">==</span> <span class="st">"replications"</span>) <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb25-71"><a href="#cb25-71" aria-hidden="true" tabindex="-1"></a>  world_cols <span class="ot">&lt;-</span> <span class="fu">names</span>(df)[start<span class="sc">:</span><span class="fu">length</span>(<span class="fu">names</span>(df))]</span>
<span id="cb25-72"><a href="#cb25-72" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb25-73"><a href="#cb25-73" aria-hidden="true" tabindex="-1"></a>  n_opinions <span class="ot">&lt;-</span> <span class="fu">length</span>(df<span class="sc">$</span>opinions[[<span class="dv">1</span>]])</span>
<span id="cb25-74"><a href="#cb25-74" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb25-75"><a href="#cb25-75" aria-hidden="true" tabindex="-1"></a>  <span class="co"># 4) extract each position and compute diffs</span></span>
<span id="cb25-76"><a href="#cb25-76" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="fu">seq_len</span>(n_opinions)) {</span>
<span id="cb25-77"><a href="#cb25-77" aria-hidden="true" tabindex="-1"></a>    <span class="co"># pull the i-th element out of each list-column</span></span>
<span id="cb25-78"><a href="#cb25-78" aria-hidden="true" tabindex="-1"></a>    df[[<span class="fu">paste0</span>(<span class="st">"opinion_"</span>,  i)]] <span class="ot">&lt;-</span> <span class="fu">map_dbl</span>(df<span class="sc">$</span>opinions,       <span class="sc">~</span> .x[i])</span>
<span id="cb25-79"><a href="#cb25-79" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb25-80"><a href="#cb25-80" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb25-81"><a href="#cb25-81" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Compute the absolute difference in average opinions by groups</span></span>
<span id="cb25-82"><a href="#cb25-82" aria-hidden="true" tabindex="-1"></a>  result_list <span class="ot">&lt;-</span> <span class="fu">vector</span>(<span class="st">"list"</span>, <span class="at">length =</span> n_opinions)</span>
<span id="cb25-83"><a href="#cb25-83" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb25-84"><a href="#cb25-84" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Compute the absolute difference in average opinions by groups</span></span>
<span id="cb25-85"><a href="#cb25-85" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="fu">seq_len</span>(n_opinions)) {</span>
<span id="cb25-86"><a href="#cb25-86" aria-hidden="true" tabindex="-1"></a>    opinion_col <span class="ot">&lt;-</span> <span class="fu">paste0</span>(<span class="st">"opinion_"</span>, i)</span>
<span id="cb25-87"><a href="#cb25-87" aria-hidden="true" tabindex="-1"></a>    abs_diff_col <span class="ot">&lt;-</span> <span class="fu">glue</span>(<span class="st">"abs_diff_opinion_{i}"</span>)</span>
<span id="cb25-88"><a href="#cb25-88" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb25-89"><a href="#cb25-89" aria-hidden="true" tabindex="-1"></a>    result_list[[i]] <span class="ot">&lt;-</span> df <span class="sc">|&gt;</span></span>
<span id="cb25-90"><a href="#cb25-90" aria-hidden="true" tabindex="-1"></a>      <span class="fu">group_by</span>(rep, <span class="fu">across</span>(<span class="fu">all_of</span>(world_cols)), partisanship) <span class="sc">|&gt;</span></span>
<span id="cb25-91"><a href="#cb25-91" aria-hidden="true" tabindex="-1"></a>      <span class="fu">summarize</span>(<span class="at">avg_opinion =</span> <span class="fu">mean</span>(.data[[opinion_col]]), <span class="at">.groups =</span> <span class="st">"drop"</span>) <span class="sc">|&gt;</span></span>
<span id="cb25-92"><a href="#cb25-92" aria-hidden="true" tabindex="-1"></a>      <span class="fu">pivot_wider</span>(<span class="at">names_from =</span> partisanship, </span>
<span id="cb25-93"><a href="#cb25-93" aria-hidden="true" tabindex="-1"></a>                  <span class="at">values_from =</span> avg_opinion, </span>
<span id="cb25-94"><a href="#cb25-94" aria-hidden="true" tabindex="-1"></a>                  <span class="at">names_prefix =</span> <span class="st">"opinion_"</span>) <span class="sc">|&gt;</span> </span>
<span id="cb25-95"><a href="#cb25-95" aria-hidden="true" tabindex="-1"></a>      <span class="fu">mutate</span>(<span class="sc">!!</span><span class="at">abs_diff_col :=</span> <span class="fu">abs</span>(opinion_0 <span class="sc">-</span> opinion_1)) <span class="sc">|&gt;</span> </span>
<span id="cb25-96"><a href="#cb25-96" aria-hidden="true" tabindex="-1"></a>      dplyr<span class="sc">::</span><span class="fu">select</span>(<span class="sc">-</span>opinion_0, <span class="sc">-</span>opinion_1)</span>
<span id="cb25-97"><a href="#cb25-97" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb25-98"><a href="#cb25-98" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb25-99"><a href="#cb25-99" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Combine all opinion positions into one dataframe</span></span>
<span id="cb25-100"><a href="#cb25-100" aria-hidden="true" tabindex="-1"></a>  final_results <span class="ot">&lt;-</span> <span class="fu">bind_rows</span>(result_list)</span>
<span id="cb25-101"><a href="#cb25-101" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb25-102"><a href="#cb25-102" aria-hidden="true" tabindex="-1"></a>  final_results</span>
<span id="cb25-103"><a href="#cb25-103" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb25-104"><a href="#cb25-104" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-105"><a href="#cb25-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-106"><a href="#cb25-106" aria-hidden="true" tabindex="-1"></a>Now we can use this to see how the different network topologies affect polarization:</span>
<span id="cb25-107"><a href="#cb25-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-110"><a href="#cb25-110" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-111"><a href="#cb25-111" aria-hidden="true" tabindex="-1"></a>df_polarization <span class="ot">&lt;-</span> <span class="fu">calc_polarization</span>(results)</span>
<span id="cb25-112"><a href="#cb25-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-113"><a href="#cb25-113" aria-hidden="true" tabindex="-1"></a><span class="co"># show average differences between participants in the worlds</span></span>
<span id="cb25-114"><a href="#cb25-114" aria-hidden="true" tabindex="-1"></a>diffs <span class="ot">&lt;-</span> df_polarization <span class="sc">|&gt;</span></span>
<span id="cb25-115"><a href="#cb25-115" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(network) <span class="sc">|&gt;</span></span>
<span id="cb25-116"><a href="#cb25-116" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(</span>
<span id="cb25-117"><a href="#cb25-117" aria-hidden="true" tabindex="-1"></a>    <span class="at">abs_diff_mean =</span> <span class="fu">mean</span>(abs_diff_opinion_1)</span>
<span id="cb25-118"><a href="#cb25-118" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb25-119"><a href="#cb25-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-120"><a href="#cb25-120" aria-hidden="true" tabindex="-1"></a>diffs</span>
<span id="cb25-121"><a href="#cb25-121" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-122"><a href="#cb25-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-123"><a href="#cb25-123" aria-hidden="true" tabindex="-1"></a>The output reveals that average polarization is lowest in the *neutral* condition and highest in the *antipartisan* condition. Just one round of interaction is enough to increase the polarization by over 8%-points with a change from *neutral* to *antipartisan* condition.</span>
<span id="cb25-124"><a href="#cb25-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-125"><a href="#cb25-125" aria-hidden="true" tabindex="-1"></a>We can also assess the effect size of these differences (using the library <span class="in">`effsize`</span>):</span>
<span id="cb25-126"><a href="#cb25-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-129"><a href="#cb25-129" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-130"><a href="#cb25-130" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(effsize)</span>
<span id="cb25-131"><a href="#cb25-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-132"><a href="#cb25-132" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fu">cohen.d</span>(</span>
<span id="cb25-133"><a href="#cb25-133" aria-hidden="true" tabindex="-1"></a>  <span class="at">formula =</span> abs_diff_opinion_1 <span class="sc">~</span> network,</span>
<span id="cb25-134"><a href="#cb25-134" aria-hidden="true" tabindex="-1"></a>  <span class="at">data    =</span> df_polarization <span class="sc">|&gt;</span> <span class="fu">filter</span>(network <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">"neutral"</span>, <span class="st">"antipartisan"</span>)) <span class="sc">|&gt;</span> </span>
<span id="cb25-135"><a href="#cb25-135" aria-hidden="true" tabindex="-1"></a>    <span class="fu">droplevels</span>(),</span>
<span id="cb25-136"><a href="#cb25-136" aria-hidden="true" tabindex="-1"></a>  <span class="at">pooled  =</span> <span class="cn">TRUE</span>,</span>
<span id="cb25-137"><a href="#cb25-137" aria-hidden="true" tabindex="-1"></a>  <span class="at">hedges.correction =</span> <span class="cn">FALSE</span></span>
<span id="cb25-138"><a href="#cb25-138" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb25-139"><a href="#cb25-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-140"><a href="#cb25-140" aria-hidden="true" tabindex="-1"></a>d</span>
<span id="cb25-141"><a href="#cb25-141" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-142"><a href="#cb25-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-143"><a href="#cb25-143" aria-hidden="true" tabindex="-1"></a>The result suggests a medium-to-large effect. But is that enough to justify a real-world experiment based on these findings? While the simulated effects are promising, we need to know whether such differences would be statistically significant with real experimental data. A common approach is to run the same statistical test we would run later in the real experiment to test whether polarization is different between treatments. Lets assume we are content with a simple t-test. Let us use this test to compare now the effect between the *neutral* and the *antipartisan* condition:</span>
<span id="cb25-144"><a href="#cb25-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-147"><a href="#cb25-147" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-148"><a href="#cb25-148" aria-hidden="true" tabindex="-1"></a>ttest <span class="ot">&lt;-</span> df_polarization <span class="sc">|&gt;</span></span>
<span id="cb25-149"><a href="#cb25-149" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(network <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">"neutral"</span>, <span class="st">"antipartisan"</span>)) <span class="sc">|&gt;</span></span>
<span id="cb25-150"><a href="#cb25-150" aria-hidden="true" tabindex="-1"></a>  <span class="fu">t.test</span>(abs_diff_opinion_1 <span class="sc">~</span> network, <span class="at">data =</span> _)</span>
<span id="cb25-151"><a href="#cb25-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-152"><a href="#cb25-152" aria-hidden="true" tabindex="-1"></a>ttest</span>
<span id="cb25-153"><a href="#cb25-153" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-154"><a href="#cb25-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-155"><a href="#cb25-155" aria-hidden="true" tabindex="-1"></a>Yet, the difference between the two treatments is not statistically significant ($p &lt; <span class="in">`r round(ttest$p.value, 3)`</span>$)—even though the effect size is considerable. Why? Because we only have two worlds per condition. Remember: polarization is a property of the entire simulated world, not of individuals. So even if each world contains many agents, our actual sample size for the statistical test is just two worlds per treatment.</span>
<span id="cb25-156"><a href="#cb25-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-157"><a href="#cb25-157" aria-hidden="true" tabindex="-1"></a>Clearly, this sample size is far too small to detect substantial effects with confidence. Had we proceeded with a real-world experiment based on such limited data, we might have wasted significant resources. To prevent this, we turn to **power analysis**. Power analysis allows us to estimate how many simulated worlds (or real-world participants) are needed to detect effects of a given size with a high probability. This ensures that the experiments we design are not only theoretically sound but also practically effective.</span>
<span id="cb25-158"><a href="#cb25-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-159"><a href="#cb25-159" aria-hidden="true" tabindex="-1"></a>At the same time, as you may already know from earlier statistics courses, increasing the sample size sufficiently will always lead to statistical significance, regardless of effect size. Therefore, we aim for a sample size that is just sufficient to detect the effect sizes we believe to be realistic—while remaining insensitive to much smaller, potentially spurious effects. In other words, power analysis helps us find the minimum number of worlds (or more generally sample size) required to robustly detect meaningful differences, without overcommitting resources or overfitting to noise.</span>
<span id="cb25-160"><a href="#cb25-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-161"><a href="#cb25-161" aria-hidden="true" tabindex="-1"></a><span class="fu">## Learning Goals</span></span>
<span id="cb25-162"><a href="#cb25-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-163"><a href="#cb25-163" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>Define and interpret statistical power.</span>
<span id="cb25-164"><a href="#cb25-164" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>Identify the main components affecting experimental power.</span>
<span id="cb25-165"><a href="#cb25-165" aria-hidden="true" tabindex="-1"></a><span class="ss">3.  </span>Calculate power using both analytic formulas and simulation methods.</span>
<span id="cb25-166"><a href="#cb25-166" aria-hidden="true" tabindex="-1"></a><span class="ss">4.  </span>Conduct sensitivity analyses to assess how robust your power calculations are to assumptions.</span>
<span id="cb25-167"><a href="#cb25-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-168"><a href="#cb25-168" aria-hidden="true" tabindex="-1"></a><span class="fu"># Statistical Power</span></span>
<span id="cb25-169"><a href="#cb25-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-170"><a href="#cb25-170" aria-hidden="true" tabindex="-1"></a>Statistical power (henceforth simply power) is the probability that an experiment correctly **identifies a true effect**—it's our ability to detect a meaningful signal amidst the noise. In any experimental setting, the **signal** we seek is the actual impact of a treatment. This could be:</span>
<span id="cb25-171"><a href="#cb25-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-172"><a href="#cb25-172" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Does educational intervention increase income levels?</span>
<span id="cb25-173"><a href="#cb25-173" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Do vaccination campaigns reduce disease incidence?</span>
<span id="cb25-174"><a href="#cb25-174" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Which network topologies affect partisan polarization the most?</span>
<span id="cb25-175"><a href="#cb25-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-176"><a href="#cb25-176" aria-hidden="true" tabindex="-1"></a>The **noise** refers to the natural variability or randomness in data, caused by many unpredictable factors that are difficult—or even impossible—to measure or control for statistically. It’s typically quantified as the standard deviation of outcomes. Consider the following examples:</span>
<span id="cb25-177"><a href="#cb25-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-178"><a href="#cb25-178" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>If your outcome is the prevalence of a rare disease, daily fluctuations are usually minimal—thus, noise is low. Even a modest decrease (e.g., 1 percentage point) in disease rates could be detectable.</span>
<span id="cb25-179"><a href="#cb25-179" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Conversely, measuring income as an outcome is inherently noisier, as individual incomes can differ greatly. A modest income increase of 1% might easily go unnoticed due to substantial background noise.</span>
<span id="cb25-180"><a href="#cb25-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-181"><a href="#cb25-181" aria-hidden="true" tabindex="-1"></a>Adequate power ensures that a true effect—if it exists—won’t be masked by randomness.</span>
<span id="cb25-182"><a href="#cb25-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-183"><a href="#cb25-183" aria-hidden="true" tabindex="-1"></a><span class="fu">## Power and Specificity</span></span>
<span id="cb25-184"><a href="#cb25-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-185"><a href="#cb25-185" aria-hidden="true" tabindex="-1"></a>When planning an experiment, two core statistical concepts must be carefully balanced: **power** and **specificity** (see @tbl-sp). Understanding how they interact is crucial for designing experiments that are both scientifically rigorous and resource-efficient.</span>
<span id="cb25-186"><a href="#cb25-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-187"><a href="#cb25-187" aria-hidden="true" tabindex="-1"></a>**Specificity** refers to the probability of correctly retaining the null hypothesis when it is actually true. In other words, it is the ability of a test to avoid false positives. The **significance level** $\alpha$ defines how willing we are to risk a **Type I error**—rejecting the null hypothesis $H_0$ when it is actually true. This is often set at 0.05, meaning we accept a 5% chance of a false positive. Accordingly, the **specificity** of such a test is $1 - \alpha = 0.95$.</span>
<span id="cb25-188"><a href="#cb25-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-189"><a href="#cb25-189" aria-hidden="true" tabindex="-1"></a>On the other hand, **statistical power**—denoted as $1 - \beta$—is the probability of correctly detecting a true effect. It represents the ability to avoid a **Type II error** (failing to reject $H_0$ when it is false). The value $\beta$ quantifies the probability of making such an error. Power is conventionally set at 80%, meaning we aim for $1 - \beta = 0.8$, or in other words, we want to correctly detect true effects in 4 out of 5 experiments.</span>
<span id="cb25-190"><a href="#cb25-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-191"><a href="#cb25-191" aria-hidden="true" tabindex="-1"></a>Balancing power and specificity is essential: increasing one often comes at the cost of the other. Power analysis helps us navigate this trade-off, ensuring that we choose a sample size large enough to detect meaningful effects, without inflating the risk of false positives.</span>
<span id="cb25-192"><a href="#cb25-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-193"><a href="#cb25-193" aria-hidden="true" tabindex="-1"></a>|   |   | $H_0$ is true | $H_1$ is true |</span>
<span id="cb25-194"><a href="#cb25-194" aria-hidden="true" tabindex="-1"></a>|:-----------------|:-----------------|:------------------|:-----------------|</span>
<span id="cb25-195"><a href="#cb25-195" aria-hidden="true" tabindex="-1"></a>| **Test decision…** | … in favor of $H_0$ | ✅ Correct decision (Specificity) &lt;br&gt; Probability: 1 − α | ❌ **Type II error** &lt;br&gt; Probability: β |</span>
<span id="cb25-196"><a href="#cb25-196" aria-hidden="true" tabindex="-1"></a>|  | … in favor of $H_1$ | ❌ **Type I error** &lt;br&gt; Probability: α | ✅ Correct decision (Power) &lt;br&gt; Probability: 1 − β |</span>
<span id="cb25-197"><a href="#cb25-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-198"><a href="#cb25-198" aria-hidden="true" tabindex="-1"></a>: Decision outcomes depending on test result and reality {#tbl-sp}</span>
<span id="cb25-199"><a href="#cb25-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-200"><a href="#cb25-200" aria-hidden="true" tabindex="-1"></a><span class="fu">## Four Core Elements of Statistical Power</span></span>
<span id="cb25-201"><a href="#cb25-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-202"><a href="#cb25-202" aria-hidden="true" tabindex="-1"></a>Four primary factors shape an experiment’s power:</span>
<span id="cb25-203"><a href="#cb25-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-204"><a href="#cb25-204" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>**The test itself and the statistical significance criterion** The type of statistical test used—and the threshold set for statistical significance—directly influences power. Some tests are inherently more sensitive than others, depending on the data and research design. In addition, the choice of $\alpha$ (commonly set at 0.05) defines the strictness of evidence required to reject the null hypothesis. A lower $\alpha$ (e.g., 0.01) reduces the chance of false positives but also makes it harder to detect true effects, thereby reducing power. Conversely, increasing $\alpha$ boosts power but raises the risk of false positives.</span>
<span id="cb25-205"><a href="#cb25-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-206"><a href="#cb25-206" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>**Strength of Treatment**\</span>
<span id="cb25-207"><a href="#cb25-207" aria-hidden="true" tabindex="-1"></a>    Stronger treatments are easier to detect and therefore increase statistical power. For example, giving each participant a large sum of money is more likely to produce a measurable effect than giving only a small sum. However, in practice, researchers often face constraints—whether due to limited resources or limited control over the intervention—especially when evaluating existing programs or policies.</span>
<span id="cb25-208"><a href="#cb25-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-209"><a href="#cb25-209" aria-hidden="true" tabindex="-1"></a><span class="ss">3.  </span>**Background Noise (Variability**)\</span>
<span id="cb25-210"><a href="#cb25-210" aria-hidden="true" tabindex="-1"></a>    The more variability there is in outcomes, the harder it is to detect a true effect. Selecting outcome measures with lower variability can help improve power. In many cases, however, variability is inherent and difficult to reduce—especially when measuring complex behaviors like income or attitudes. This is precisely one of the reasons researchers turn to lab experiments: to create controlled environments that minimize noise. By standardizing conditions across participants, lab settings help keep variability low, making it easier to isolate and detect the effect of interest.</span>
<span id="cb25-211"><a href="#cb25-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-212"><a href="#cb25-212" aria-hidden="true" tabindex="-1"></a><span class="ss">4.  </span>**Experimental Design**\</span>
<span id="cb25-213"><a href="#cb25-213" aria-hidden="true" tabindex="-1"></a>    This is (often) the most direct lever researchers have to influence power. Power analysis often focuses on **sample size**—larger samples reduce uncertainty and increase power. But good design goes beyond just size. Consider:</span>
<span id="cb25-214"><a href="#cb25-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-215"><a href="#cb25-215" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>How units are randomized (individually or in clusters),</span>
<span id="cb25-216"><a href="#cb25-216" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Whether key covariates are measured and controlled for,</span>
<span id="cb25-217"><a href="#cb25-217" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>How many treatment groups are included and how they’re structured.</span>
<span id="cb25-218"><a href="#cb25-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-219"><a href="#cb25-219" aria-hidden="true" tabindex="-1"></a><span class="fu">### Time To Play (and Learn!)</span></span>
<span id="cb25-220"><a href="#cb25-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-221"><a href="#cb25-221" aria-hidden="true" tabindex="-1"></a>In the interactive graph below, you can explore how the key parameters of hypothesis testing—significance criterion $\alpha$, difference in mean $\mu_1$, and standard deviation $\sigma$—interact to shape the probabilities of different outcomes.<span class="ot">[^2]</span> By adjusting the sliders, observe how the rates of **Type I errors** (false positives) and **Type II errors** (false negatives) change.</span>
<span id="cb25-222"><a href="#cb25-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-223"><a href="#cb25-223" aria-hidden="true" tabindex="-1"></a><span class="ot">[^2]: </span>In this interactive graph, $\sigma$ does not only represent standard deviation in the classical sense, but can also serve as a proxy for sample size. Increasing the sample size reduces uncertainty around the estimated mean, effectively shrinking the observed standard deviation due to the law of large numbers. In that sense, decreasing $\sigma$ here mimics the effect of increasing the number of observations.</span>
<span id="cb25-224"><a href="#cb25-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-225"><a href="#cb25-225" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The **blue shaded areas** represent **Type I errors**: regions where we incorrectly reject the null hypothesis ($H_0$ is true, but we reject it).</span>
<span id="cb25-226"><a href="#cb25-226" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The **red shaded area** represents a **Type II error**: failing to reject the null hypothesis when the alternative is actually true.</span>
<span id="cb25-227"><a href="#cb25-227" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The remaining areas under the curves represent **correct decisions**: either correctly retaining the null or correctly detecting a true effect.</span>
<span id="cb25-228"><a href="#cb25-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-229"><a href="#cb25-229" aria-hidden="true" tabindex="-1"></a>In an ideal scenario, we aim to minimize both the blue and red areas—reducing the likelihood of false discoveries *and* missed effects. Try adjusting the parameters to see how you can shrink both error regions simultaneously!</span>
<span id="cb25-230"><a href="#cb25-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-231"><a href="#cb25-231" aria-hidden="true" tabindex="-1"></a><span class="in">```{=html}</span></span>
<span id="cb25-232"><a href="#cb25-232" aria-hidden="true" tabindex="-1"></a><span class="in">&lt;script src="https://cdn.plot.ly/plotly-3.0.1.min.js" charset="utf-8"&gt;&lt;/script&gt;</span></span>
<span id="cb25-233"><a href="#cb25-233" aria-hidden="true" tabindex="-1"></a><span class="in">&lt;script src="js/alpha_beta.js" charset="utf-8"&gt;&lt;/script&gt;</span></span>
<span id="cb25-234"><a href="#cb25-234" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-235"><a href="#cb25-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-236"><a href="#cb25-236" aria-hidden="true" tabindex="-1"></a>:::::: simulation</span>
<span id="cb25-237"><a href="#cb25-237" aria-hidden="true" tabindex="-1"></a>:::: results</span>
<span id="cb25-238"><a href="#cb25-238" aria-hidden="true" tabindex="-1"></a>::: {#power-plot style="width:100%;height:500px;"}</span>
<span id="cb25-239"><a href="#cb25-239" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb25-240"><a href="#cb25-240" aria-hidden="true" tabindex="-1"></a>::::</span>
<span id="cb25-241"><a href="#cb25-241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-242"><a href="#cb25-242" aria-hidden="true" tabindex="-1"></a>::: settings</span>
<span id="cb25-243"><a href="#cb25-243" aria-hidden="true" tabindex="-1"></a>&lt;p&gt;&lt;strong&gt;Significance criterion $\alpha$:&lt;/strong&gt; &lt;label for="a_value_v" id="a_value_label"&gt;&lt;/label&gt;&lt;br&gt; &lt;input type="range" id="a_value" min="0.01" max="0.2" value="0.05" step="0.01"&gt;&lt;/p&gt;</span>
<span id="cb25-244"><a href="#cb25-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-245"><a href="#cb25-245" aria-hidden="true" tabindex="-1"></a>&lt;p&gt;&lt;strong&gt;Difference in mean $\mu_1$:&lt;/strong&gt; &lt;label for="d_value_v" id="d_value_label"&gt;&lt;/label&gt;&lt;br&gt; &lt;input type="range" id="d_value" min="0.1" max="3" value="2" step="0.1"&gt;&lt;/p&gt;</span>
<span id="cb25-246"><a href="#cb25-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-247"><a href="#cb25-247" aria-hidden="true" tabindex="-1"></a>&lt;p&gt;&lt;strong&gt;Standard Deviation $\sigma$:&lt;/strong&gt; &lt;label for="sd_value_v" id="sd_value_label"&gt;&lt;/label&gt;&lt;br&gt; &lt;input type="range" id="sd_value" min="0.1" max="3" value="1" step="0.1"&gt;&lt;/p&gt;</span>
<span id="cb25-248"><a href="#cb25-248" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb25-249"><a href="#cb25-249" aria-hidden="true" tabindex="-1"></a>::::::</span>
<span id="cb25-250"><a href="#cb25-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-251"><a href="#cb25-251" aria-hidden="true" tabindex="-1"></a>As you will notice, all three parameters—significance criterion $\alpha$, difference in mean $\mu_1$, and standard deviation $\sigma$—impact the probability of a Type II error ($\beta$). However, they are not equally advisable to manipulate from a scientific perspective.</span>
<span id="cb25-252"><a href="#cb25-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-253"><a href="#cb25-253" aria-hidden="true" tabindex="-1"></a>While increasing the significance criterion $\alpha$ can improve power by reducing $\beta$, doing so comes at the cost of raising the false positive rate. This compromises the integrity of your results and increases the risk of contributing to irreproducible findings. Good scientific practice discourages simply relaxing $\alpha$ to gain statistical significance.</span>
<span id="cb25-254"><a href="#cb25-254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-255"><a href="#cb25-255" aria-hidden="true" tabindex="-1"></a>Instead, maintaining a conventional threshold (e.g., $\alpha = 0.05$) ensures that evidence required to reject the null hypothesis remains stringent. This protects the credibility of statistical inference and helps prevent the overstatement of weak or spurious effects—one of the central concerns in the current replication crisis across many disciplines.</span>
<span id="cb25-256"><a href="#cb25-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-257"><a href="#cb25-257" aria-hidden="true" tabindex="-1"></a>Therefore, we should seek to influence $\beta$ by adjusting parameters that improve our experimental design **without compromising statistical integrity**—namely, increasing effect size (e.g., through better treatment design), reducing variability (e.g., by improving measurement precision), or increasing sample size (e.g., adding more participants or simulation runs).</span>
<span id="cb25-258"><a href="#cb25-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-259"><a href="#cb25-259" aria-hidden="true" tabindex="-1"></a><span class="fu"># Conducting a Power Analysis</span></span>
<span id="cb25-260"><a href="#cb25-260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-261"><a href="#cb25-261" aria-hidden="true" tabindex="-1"></a>In the previous section, we explored several key design choices—such as sample size, randomization strategy, and control of covariates—that can greatly influence an experiment’s statistical power. To make informed design decisions, however, we must first understand how to **quantify** power. This is where power analysis comes in.</span>
<span id="cb25-262"><a href="#cb25-262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-263"><a href="#cb25-263" aria-hidden="true" tabindex="-1"></a>There are two primary approaches to conducting a power analysis:</span>
<span id="cb25-264"><a href="#cb25-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-265"><a href="#cb25-265" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>**Analytical methods**, which use mathematical formulas derived from statistical theory to estimate power.</span>
<span id="cb25-266"><a href="#cb25-266" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>**Simulation-based methods**, which involve generating synthetic datasets under specified assumptions and repeatedly testing them to observe how often a statistically significant result occurs.</span>
<span id="cb25-267"><a href="#cb25-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-268"><a href="#cb25-268" aria-hidden="true" tabindex="-1"></a>Each approach has its advantages. Analytical formulas are fast, interpretable, and useful for standard designs—but they depend on idealized assumptions (e.g., normality, equal variances). Simulation, by contrast, is computationally more intensive but highly flexible, making it better suited for complex or customized scenarios.</span>
<span id="cb25-269"><a href="#cb25-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-270"><a href="#cb25-270" aria-hidden="true" tabindex="-1"></a>In the sections that follow, we will explore both methods in detail and discuss how to apply them to real experimental planning.</span>
<span id="cb25-271"><a href="#cb25-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-272"><a href="#cb25-272" aria-hidden="true" tabindex="-1"></a><span class="fu">## The Analytical Way</span></span>
<span id="cb25-273"><a href="#cb25-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-274"><a href="#cb25-274" aria-hidden="true" tabindex="-1"></a>There are many formulas for calculating statistical power, each tailored to a specific type of test (e.g., t-tests, ANOVA, regression). To keep things simple, we’ll focus on the classical two-sample, two-sided t-test, which compares the means of two independent groups.</span>
<span id="cb25-275"><a href="#cb25-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-276"><a href="#cb25-276" aria-hidden="true" tabindex="-1"></a>For this case, the power ($1 - \beta$) can be approximated using the following formula:</span>
<span id="cb25-277"><a href="#cb25-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-278"><a href="#cb25-278" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-279"><a href="#cb25-279" aria-hidden="true" tabindex="-1"></a> 1-\beta \approx 1 - \Phi\left( \Phi^{-1} \left(1-\frac{\alpha}{2}\right) - \frac{|\mu_t-\mu_c|\sqrt{N}}{2\sigma} \right)</span>
<span id="cb25-280"><a href="#cb25-280" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-281"><a href="#cb25-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-282"><a href="#cb25-282" aria-hidden="true" tabindex="-1"></a>Here’s what these symbols mean:</span>
<span id="cb25-283"><a href="#cb25-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-284"><a href="#cb25-284" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$\beta$: Probability of making a Type II error.</span>
<span id="cb25-285"><a href="#cb25-285" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$\Phi$: Cumulative distribution function (CDF) for the normal distribution.</span>
<span id="cb25-286"><a href="#cb25-286" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$\Phi^{-1}$: The inverse normal distribution function.</span>
<span id="cb25-287"><a href="#cb25-287" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$\mu_t$: Mean outcome of the treatment group.</span>
<span id="cb25-288"><a href="#cb25-288" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$\mu_c$: Mean outcome of the control group.</span>
<span id="cb25-289"><a href="#cb25-289" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$\sigma$: Standard deviation (noise) of outcomes, assumed equal across groups.</span>
<span id="cb25-290"><a href="#cb25-290" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$\alpha$: Significance level (commonly set at 0.05).</span>
<span id="cb25-291"><a href="#cb25-291" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$N$: Total sample size.</span>
<span id="cb25-292"><a href="#cb25-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-293"><a href="#cb25-293" aria-hidden="true" tabindex="-1"></a>Note that this approximation becomes more accurate as $N$ increases, because under the alternative hypothesis ($H_1$), the Student’s t-distribution converges to the standard normal distribution. </span>
<span id="cb25-294"><a href="#cb25-294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-295"><a href="#cb25-295" aria-hidden="true" tabindex="-1"></a>Let’s apply this formula to estimate the power of our experiment with $N = 4$ (2 simulated worlds per condition):</span>
<span id="cb25-296"><a href="#cb25-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-299"><a href="#cb25-299" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-300"><a href="#cb25-300" aria-hidden="true" tabindex="-1"></a>power_calculator <span class="ot">&lt;-</span> <span class="cf">function</span>(mu_t, mu_c, sigma, <span class="at">alpha=</span><span class="fl">0.05</span>, N, <span class="at">two.sided =</span> <span class="cn">TRUE</span>){ </span>
<span id="cb25-301"><a href="#cb25-301" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (<span class="sc">!</span>two.sided) alpha <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">*</span> alpha</span>
<span id="cb25-302"><a href="#cb25-302" aria-hidden="true" tabindex="-1"></a>  inside <span class="ot">&lt;-</span> <span class="fu">qnorm</span>(<span class="dv">1</span> <span class="sc">-</span> alpha<span class="sc">/</span><span class="dv">2</span>) <span class="sc">-</span> <span class="fu">abs</span>(mu_t <span class="sc">-</span> mu_c) <span class="sc">*</span> <span class="fu">sqrt</span>(N) <span class="sc">/</span> (<span class="dv">2</span> <span class="sc">*</span> sigma)</span>
<span id="cb25-303"><a href="#cb25-303" aria-hidden="true" tabindex="-1"></a>  <span class="dv">1</span> <span class="sc">-</span> <span class="fu">pnorm</span>(inside)</span>
<span id="cb25-304"><a href="#cb25-304" aria-hidden="true" tabindex="-1"></a>} </span>
<span id="cb25-305"><a href="#cb25-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-306"><a href="#cb25-306" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate the sd's for our two experimental conditions</span></span>
<span id="cb25-307"><a href="#cb25-307" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> df_polarization <span class="sc">|&gt;</span></span>
<span id="cb25-308"><a href="#cb25-308" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(network <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">"neutral"</span>, <span class="st">"antipartisan"</span>)) <span class="sc">|&gt;</span></span>
<span id="cb25-309"><a href="#cb25-309" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pull</span>(abs_diff_opinion_1) <span class="sc">|&gt;</span> </span>
<span id="cb25-310"><a href="#cb25-310" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sd</span>()</span>
<span id="cb25-311"><a href="#cb25-311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-312"><a href="#cb25-312" aria-hidden="true" tabindex="-1"></a><span class="co"># in diffs[1,2] and diffs[3,2] the values for neutral and antipartisan are stored! </span></span>
<span id="cb25-313"><a href="#cb25-313" aria-hidden="true" tabindex="-1"></a><span class="fu">power_calculator</span>(</span>
<span id="cb25-314"><a href="#cb25-314" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu_t  =</span> diffs[<span class="dv">1</span>,<span class="dv">2</span>] <span class="sc">|&gt;</span> <span class="fu">pull</span>(),</span>
<span id="cb25-315"><a href="#cb25-315" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu_c  =</span> diffs[<span class="dv">3</span>,<span class="dv">2</span>] <span class="sc">|&gt;</span> <span class="fu">pull</span>(),</span>
<span id="cb25-316"><a href="#cb25-316" aria-hidden="true" tabindex="-1"></a>  <span class="at">sigma =</span> sigma,</span>
<span id="cb25-317"><a href="#cb25-317" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="fl">0.05</span>,</span>
<span id="cb25-318"><a href="#cb25-318" aria-hidden="true" tabindex="-1"></a>  <span class="at">N =</span> <span class="dv">4</span></span>
<span id="cb25-319"><a href="#cb25-319" aria-hidden="true" tabindex="-1"></a>) </span>
<span id="cb25-320"><a href="#cb25-320" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-321"><a href="#cb25-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-322"><a href="#cb25-322" aria-hidden="true" tabindex="-1"></a>We see that with $N = 4$, we can only expect about 13.7% power—meaning that in roughly 86% of similar experiments, we would fail to detect a real effect, despite a substantial difference between groups.</span>
<span id="cb25-323"><a href="#cb25-323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-324"><a href="#cb25-324" aria-hidden="true" tabindex="-1"></a>How many observations do we need? For a quick approximation, we can use Lehr’s rule of thumb <span class="co">[</span><span class="ot">-@lehr1992</span><span class="co">]</span>, which estimates sample size for an 80% powered, two-sided t-test at $\alpha = 0.05$ as:</span>
<span id="cb25-325"><a href="#cb25-325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-326"><a href="#cb25-326" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-327"><a href="#cb25-327" aria-hidden="true" tabindex="-1"></a>n \approx 16 \cdot \frac{\sigma^2}{(\mu_c-\mu_t)^2}</span>
<span id="cb25-328"><a href="#cb25-328" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-329"><a href="#cb25-329" aria-hidden="true" tabindex="-1"></a>In this formula, $n$ represents the required sample size **per group**. Since we are comparing two groups, the total sample size is $N = 2 \cdot n$. Let’s apply this rule in R:</span>
<span id="cb25-330"><a href="#cb25-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-333"><a href="#cb25-333" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-334"><a href="#cb25-334" aria-hidden="true" tabindex="-1"></a>approx_n <span class="ot">&lt;-</span> <span class="cf">function</span>(</span>
<span id="cb25-335"><a href="#cb25-335" aria-hidden="true" tabindex="-1"></a>    mu_t,</span>
<span id="cb25-336"><a href="#cb25-336" aria-hidden="true" tabindex="-1"></a>    mu_c, </span>
<span id="cb25-337"><a href="#cb25-337" aria-hidden="true" tabindex="-1"></a>    sigma</span>
<span id="cb25-338"><a href="#cb25-338" aria-hidden="true" tabindex="-1"></a>){ </span>
<span id="cb25-339"><a href="#cb25-339" aria-hidden="true" tabindex="-1"></a> <span class="dv">16</span> <span class="sc">*</span> (sigma<span class="sc">^</span><span class="dv">2</span> <span class="sc">/</span> (mu_t <span class="sc">-</span> mu_c)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb25-340"><a href="#cb25-340" aria-hidden="true" tabindex="-1"></a>} </span>
<span id="cb25-341"><a href="#cb25-341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-342"><a href="#cb25-342" aria-hidden="true" tabindex="-1"></a><span class="fu">approx_n</span>(</span>
<span id="cb25-343"><a href="#cb25-343" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu_t =</span> <span class="fl">0.1681238</span>,</span>
<span id="cb25-344"><a href="#cb25-344" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu_c =</span> <span class="fl">0.0869696</span>,</span>
<span id="cb25-345"><a href="#cb25-345" aria-hidden="true" tabindex="-1"></a>  <span class="at">sigma =</span> sigma</span>
<span id="cb25-346"><a href="#cb25-346" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb25-347"><a href="#cb25-347" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-348"><a href="#cb25-348" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-349"><a href="#cb25-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-350"><a href="#cb25-350" aria-hidden="true" tabindex="-1"></a>This yields an estimated $n \geq 22$ to achieve 80% power. This means in the end we must sample 44 worlds at least. </span>
<span id="cb25-351"><a href="#cb25-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-352"><a href="#cb25-352" aria-hidden="true" tabindex="-1"></a>While this is helpful for a rough estimate, it’s not advisable to rely solely on such approximations. To improve accuracy, we can use the <span class="in">`WebPower`</span> package, which offers more precise calculations and supports a range of designs, including unequal group sizes, paired samples, and more.</span>
<span id="cb25-353"><a href="#cb25-353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-354"><a href="#cb25-354" aria-hidden="true" tabindex="-1"></a>Let’s use <span class="in">`WebPower`</span> to plot how power increases with $N$, using the previously calculated effect size as an anchor.</span>
<span id="cb25-355"><a href="#cb25-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-358"><a href="#cb25-358" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-359"><a href="#cb25-359" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-N-power</span></span>
<span id="cb25-360"><a href="#cb25-360" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: The power in our experiment depending on n. The total N is twice this size.</span></span>
<span id="cb25-361"><a href="#cb25-361" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-align: center</span></span>
<span id="cb25-362"><a href="#cb25-362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-363"><a href="#cb25-363" aria-hidden="true" tabindex="-1"></a><span class="co">#install.packages("WebPower")</span></span>
<span id="cb25-364"><a href="#cb25-364" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(WebPower)</span>
<span id="cb25-365"><a href="#cb25-365" aria-hidden="true" tabindex="-1"></a><span class="co"># we calculated the d earlyer with cohens.d</span></span>
<span id="cb25-366"><a href="#cb25-366" aria-hidden="true" tabindex="-1"></a>res <span class="ot">&lt;-</span> <span class="fu">wp.t</span>(<span class="at">n1=</span><span class="fu">seq</span>(<span class="dv">20</span>, <span class="dv">30</span>, <span class="at">by=</span><span class="dv">1</span>), <span class="at">d=</span>d<span class="sc">$</span>estimate, <span class="at">type=</span><span class="st">"two.sample"</span>, <span class="at">alternative=</span><span class="st">"two.sided"</span>)</span>
<span id="cb25-367"><a href="#cb25-367" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(res)</span>
<span id="cb25-368"><a href="#cb25-368" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> <span class="fl">0.8</span>, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">"red"</span>)</span>
<span id="cb25-369"><a href="#cb25-369" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-370"><a href="#cb25-370" aria-hidden="true" tabindex="-1"></a>We observe that while Lehr’s rule suggests $n = 22$, a more precise estimate shows we would actually need at least $n = 25$ to achieve 80% power in our experiment.</span>
<span id="cb25-371"><a href="#cb25-371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-372"><a href="#cb25-372" aria-hidden="true" tabindex="-1"></a><span class="fu">### Trusting Your Power Analysis</span></span>
<span id="cb25-373"><a href="#cb25-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-374"><a href="#cb25-374" aria-hidden="true" tabindex="-1"></a>Power analyses inherently rely on uncertain assumptions. Critics might point out this circular reasoning: you use guesses about effect size and variability to determine how likely you are to detect effects.</span>
<span id="cb25-375"><a href="#cb25-375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-376"><a href="#cb25-376" aria-hidden="true" tabindex="-1"></a>However, power analysis is a powerful tool precisely because it reveals sensitivity to these assumptions. You can easily explore how your conclusions change with variations in assumed effect size, sample size, and noise.</span>
<span id="cb25-377"><a href="#cb25-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-378"><a href="#cb25-378" aria-hidden="true" tabindex="-1"></a>For instance, vary the sample size ($N$) to observe how power changes:</span>
<span id="cb25-379"><a href="#cb25-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-380"><a href="#cb25-380" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Larger samples increase power.</span>
<span id="cb25-381"><a href="#cb25-381" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Smaller effect sizes or higher variability reduce power.</span>
<span id="cb25-382"><a href="#cb25-382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-383"><a href="#cb25-383" aria-hidden="true" tabindex="-1"></a>Conducting sensitivity analyses this way helps you make informed, transparent decisions about experimental design.</span>
<span id="cb25-384"><a href="#cb25-384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-385"><a href="#cb25-385" aria-hidden="true" tabindex="-1"></a>It’s also worth noting that our current estimates rely on just a few simulations (e.g., $N = 4$ total worlds for comparing *neutral* vs. *antipartisan* conditions). This low number limits the reliability of our estimates. To obtain more trustworthy results, we should next turn to simulation-based power estimation—directly measuring how often our experiment would succeed, given our current assumptions.</span>
<span id="cb25-386"><a href="#cb25-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-387"><a href="#cb25-387" aria-hidden="true" tabindex="-1"></a><span class="fu">## Simulation: A Practical Alternative to Formula-Based Power Analysis</span></span>
<span id="cb25-388"><a href="#cb25-388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-389"><a href="#cb25-389" aria-hidden="true" tabindex="-1"></a>Traditional formulas offer quick insights, but modern computational methods—such as simulations—can provide richer, more flexible analysis.</span>
<span id="cb25-390"><a href="#cb25-390" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-391"><a href="#cb25-391" aria-hidden="true" tabindex="-1"></a>Simulation involves:</span>
<span id="cb25-392"><a href="#cb25-392" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-393"><a href="#cb25-393" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Repeatedly generating hypothetical datasets based on your assumptions.</span>
<span id="cb25-394"><a href="#cb25-394" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Conducting statistical tests on these simulated datasets.</span>
<span id="cb25-395"><a href="#cb25-395" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Calculating the proportion of simulated experiments detecting significant effects.</span>
<span id="cb25-396"><a href="#cb25-396" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-397"><a href="#cb25-397" aria-hidden="true" tabindex="-1"></a>This approach makes fewer assumptions and lets you explore complex scenarios realistically, especially useful for advanced or novel experimental designs.</span>
<span id="cb25-398"><a href="#cb25-398" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-399"><a href="#cb25-399" aria-hidden="true" tabindex="-1"></a>Simulations thus enhance your understanding of an experiment’s robustness and strengthen the validity of your experimental findings.</span>
<span id="cb25-400"><a href="#cb25-400" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-401"><a href="#cb25-401" aria-hidden="true" tabindex="-1"></a><span class="fu">## Implementation in R</span></span>
<span id="cb25-402"><a href="#cb25-402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-403"><a href="#cb25-403" aria-hidden="true" tabindex="-1"></a>Under normal circumstances—when we're interested in individual-level outcomes—our <span class="in">`run_simulation()`</span> function would suffice for estimating the required $N$. We could vary $N$ directly in <span class="in">`tbl_parameter`</span> and track when the treatment becomes significant in more than 80% of the replications.</span>
<span id="cb25-404"><a href="#cb25-404" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-405"><a href="#cb25-405" aria-hidden="true" tabindex="-1"></a>However, in our case, we're interested in a **property of the world** itself (i.e., polarization), not in individual behavior. In this context, the `replications` used in `run_simulation()` actually correspond to the number of **independent worlds** (or experimental sessions) we simulate per treatment. </span>
<span id="cb25-406"><a href="#cb25-406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-407"><a href="#cb25-407" aria-hidden="true" tabindex="-1"></a>A clean and robust solution would be to write a <span class="in">`run_meta_simulation()`</span> function that wraps around <span class="in">`run_simulation()`</span> and handles repeated simulation for each sample size, collecting p-values across runs. However, such an implementation is complex. Instead, we'll take a shortcut and slightly modify how we use our existing <span class="in">`run_simulation()`</span>:</span>
<span id="cb25-408"><a href="#cb25-408" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-411"><a href="#cb25-411" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-412"><a href="#cb25-412" aria-hidden="true" tabindex="-1"></a>replications <span class="ot">=</span> <span class="dv">100</span></span>
<span id="cb25-413"><a href="#cb25-413" aria-hidden="true" tabindex="-1"></a>worlds_per_treatment_max <span class="ot">=</span> <span class="dv">40</span></span>
<span id="cb25-414"><a href="#cb25-414" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb25-415"><a href="#cb25-415" aria-hidden="true" tabindex="-1"></a>simulation  <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb25-416"><a href="#cb25-416" aria-hidden="true" tabindex="-1"></a>  <span class="at">model =</span> <span class="st">"calibrated_model"</span>,</span>
<span id="cb25-417"><a href="#cb25-417" aria-hidden="true" tabindex="-1"></a>  <span class="at">replications =</span> worlds_per_treatment_max <span class="sc">*</span> replications,</span>
<span id="cb25-418"><a href="#cb25-418" aria-hidden="true" tabindex="-1"></a>  <span class="at">tbl_parameter =</span> <span class="fu">expand.grid</span>(</span>
<span id="cb25-419"><a href="#cb25-419" aria-hidden="true" tabindex="-1"></a>    <span class="at">network =</span> <span class="fu">c</span>(<span class="st">"neutral"</span>, <span class="st">"antipartisan"</span>)</span>
<span id="cb25-420"><a href="#cb25-420" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb25-421"><a href="#cb25-421" aria-hidden="true" tabindex="-1"></a>  <span class="at">master_seed  =</span> <span class="dv">42</span></span>
<span id="cb25-422"><a href="#cb25-422" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb25-423"><a href="#cb25-423" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-424"><a href="#cb25-424" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-425"><a href="#cb25-425" aria-hidden="true" tabindex="-1"></a>Here we define <span class="in">`r replications`</span> replications and <span class="in">`r worlds_per_treatment_max`</span> as the maximum number of worlds per treatment we want to simulate.</span>
<span id="cb25-426"><a href="#cb25-426" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-427"><a href="#cb25-427" aria-hidden="true" tabindex="-1"></a>Now we run this simulation:</span>
<span id="cb25-428"><a href="#cb25-428" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-431"><a href="#cb25-431" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-432"><a href="#cb25-432" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb25-433"><a href="#cb25-433" aria-hidden="true" tabindex="-1"></a>meta_results <span class="ot">&lt;-</span> <span class="fu">read_rds</span>(<span class="st">"../data/abm-opinion3/week12_meta_results.rds"</span>)</span>
<span id="cb25-434"><a href="#cb25-434" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-435"><a href="#cb25-435" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-438"><a href="#cb25-438" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-439"><a href="#cb25-439" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb25-440"><a href="#cb25-440" aria-hidden="true" tabindex="-1"></a>meta_results <span class="ot">&lt;-</span> <span class="fu">run_simulation</span>(simulation)</span>
<span id="cb25-441"><a href="#cb25-441" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-442"><a href="#cb25-442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-443"><a href="#cb25-443" aria-hidden="true" tabindex="-1"></a>The idea is as follows: replication 1 to <span class="in">`r replications`</span> corresponds to the first world, <span class="in">`r replications + 1`</span> to <span class="in">`r 2 * replications`</span> to the second world, and so on. If we want to compare, for example, 10 *neutral* worlds with 5 *antipartisan* worlds, we can take replications 1, `r replications + 1`, `r 2*replications + 1`, ..., `r 9* replications + 1` and compare those to the corresponding replications for the other condition.</span>
<span id="cb25-444"><a href="#cb25-444" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-445"><a href="#cb25-445" aria-hidden="true" tabindex="-1"></a>To automate this, we write a function that calculates power by looping over replications, collecting p-values, and computing the share of tests that fall below our $\alpha$ threshold:</span>
<span id="cb25-446"><a href="#cb25-446" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-449"><a href="#cb25-449" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-450"><a href="#cb25-450" aria-hidden="true" tabindex="-1"></a>get_power_from_simulation <span class="ot">&lt;-</span> <span class="cf">function</span>(</span>
<span id="cb25-451"><a href="#cb25-451" aria-hidden="true" tabindex="-1"></a>  df,</span>
<span id="cb25-452"><a href="#cb25-452" aria-hidden="true" tabindex="-1"></a>  n_1, </span>
<span id="cb25-453"><a href="#cb25-453" aria-hidden="true" tabindex="-1"></a>  n_2, </span>
<span id="cb25-454"><a href="#cb25-454" aria-hidden="true" tabindex="-1"></a>  by_var,    <span class="co"># unquoted column name, e.g. network</span></span>
<span id="cb25-455"><a href="#cb25-455" aria-hidden="true" tabindex="-1"></a>  by_val1,   <span class="co"># value of by_var for group 1, e.g. "neutral"</span></span>
<span id="cb25-456"><a href="#cb25-456" aria-hidden="true" tabindex="-1"></a>  by_val2,   <span class="co"># value of by_var for group 2, e.g. "antipartisan"</span></span>
<span id="cb25-457"><a href="#cb25-457" aria-hidden="true" tabindex="-1"></a>  replications</span>
<span id="cb25-458"><a href="#cb25-458" aria-hidden="true" tabindex="-1"></a>){</span>
<span id="cb25-459"><a href="#cb25-459" aria-hidden="true" tabindex="-1"></a>  by_var <span class="ot">&lt;-</span> <span class="fu">enquo</span>(by_var)</span>
<span id="cb25-460"><a href="#cb25-460" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb25-461"><a href="#cb25-461" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Pre‐filter the two condition sets once:</span></span>
<span id="cb25-462"><a href="#cb25-462" aria-hidden="true" tabindex="-1"></a>  df_by <span class="ot">&lt;-</span> df <span class="sc">|&gt;</span> <span class="fu">filter</span>((<span class="sc">!!</span>by_var) <span class="sc">==</span> by_val1 <span class="sc">|</span>(<span class="sc">!!</span>by_var) <span class="sc">==</span> by_val2)</span>
<span id="cb25-463"><a href="#cb25-463" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb25-464"><a href="#cb25-464" aria-hidden="true" tabindex="-1"></a>  rejections <span class="ot">&lt;-</span> <span class="fu">vapply</span>( <span class="fu">seq_len</span>(replications),  <span class="at">FUN.VALUE =</span> <span class="fu">logical</span>(<span class="dv">1</span>), <span class="cf">function</span>(i) </span>
<span id="cb25-465"><a href="#cb25-465" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb25-466"><a href="#cb25-466" aria-hidden="true" tabindex="-1"></a>      idx1 <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> i, <span class="at">by =</span> replications, <span class="at">length.out =</span> n_1)</span>
<span id="cb25-467"><a href="#cb25-467" aria-hidden="true" tabindex="-1"></a>      idx2 <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> i, <span class="at">by =</span> replications, <span class="at">length.out =</span> n_2)</span>
<span id="cb25-468"><a href="#cb25-468" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-469"><a href="#cb25-469" aria-hidden="true" tabindex="-1"></a>      df_sel <span class="ot">&lt;-</span> df_by <span class="sc">|&gt;</span> </span>
<span id="cb25-470"><a href="#cb25-470" aria-hidden="true" tabindex="-1"></a>        <span class="fu">filter</span>(</span>
<span id="cb25-471"><a href="#cb25-471" aria-hidden="true" tabindex="-1"></a>          ((<span class="sc">!!</span>by_var) <span class="sc">==</span> by_val1 <span class="sc">|</span> rep <span class="sc">%in%</span> idx1) <span class="sc">&amp;</span></span>
<span id="cb25-472"><a href="#cb25-472" aria-hidden="true" tabindex="-1"></a>          ((<span class="sc">!!</span>by_var) <span class="sc">==</span> by_val2 <span class="sc">|</span> rep <span class="sc">%in%</span> idx2)</span>
<span id="cb25-473"><a href="#cb25-473" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb25-474"><a href="#cb25-474" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb25-475"><a href="#cb25-475" aria-hidden="true" tabindex="-1"></a>      <span class="fu">run_test</span>(df_sel)</span>
<span id="cb25-476"><a href="#cb25-476" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb25-477"><a href="#cb25-477" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb25-478"><a href="#cb25-478" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb25-479"><a href="#cb25-479" aria-hidden="true" tabindex="-1"></a>  <span class="co"># proportion of rejections = estimated power</span></span>
<span id="cb25-480"><a href="#cb25-480" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mean</span>(rejections)</span>
<span id="cb25-481"><a href="#cb25-481" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb25-482"><a href="#cb25-482" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-483"><a href="#cb25-483" aria-hidden="true" tabindex="-1"></a>run_test <span class="ot">&lt;-</span> <span class="cf">function</span>(df){</span>
<span id="cb25-484"><a href="#cb25-484" aria-hidden="true" tabindex="-1"></a>  <span class="fu">t.test</span>(abs_diff_opinion_1 <span class="sc">~</span> network, <span class="at">data =</span> df, <span class="at">alternative =</span> <span class="st">"two.sided"</span>)<span class="sc">$</span>p.value <span class="sc">&lt;</span> <span class="fl">0.05</span></span>
<span id="cb25-485"><a href="#cb25-485" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb25-486"><a href="#cb25-486" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-487"><a href="#cb25-487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-488"><a href="#cb25-488" aria-hidden="true" tabindex="-1"></a>Note that we defined a small helper function, <span class="in">`run_test()`</span>, which performs a $t$-test. By isolating the test logic in its own function, we make it easy to later substitute alternative statistical tests—simply by modifying this subfunction—without needing to change the surrounding analysis pipeline.</span>
<span id="cb25-489"><a href="#cb25-489" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-490"><a href="#cb25-490" aria-hidden="true" tabindex="-1"></a>We can now apply this function to estimate power for 10 *neutral* and 5 *antipartisan* worlds:</span>
<span id="cb25-491"><a href="#cb25-491" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-494"><a href="#cb25-494" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-495"><a href="#cb25-495" aria-hidden="true" tabindex="-1"></a>df_polarization <span class="ot">&lt;-</span> <span class="fu">calc_polarization</span>(meta_results)</span>
<span id="cb25-496"><a href="#cb25-496" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-497"><a href="#cb25-497" aria-hidden="true" tabindex="-1"></a><span class="fu">get_power_from_simulation</span>(</span>
<span id="cb25-498"><a href="#cb25-498" aria-hidden="true" tabindex="-1"></a>  <span class="at">df         =</span> df_polarization,</span>
<span id="cb25-499"><a href="#cb25-499" aria-hidden="true" tabindex="-1"></a>  <span class="at">n_1        =</span> <span class="dv">10</span>,</span>
<span id="cb25-500"><a href="#cb25-500" aria-hidden="true" tabindex="-1"></a>  <span class="at">n_2        =</span> <span class="dv">5</span>,</span>
<span id="cb25-501"><a href="#cb25-501" aria-hidden="true" tabindex="-1"></a>  <span class="at">by_var     =</span> network,</span>
<span id="cb25-502"><a href="#cb25-502" aria-hidden="true" tabindex="-1"></a>  <span class="at">by_val1    =</span> <span class="st">"neutral"</span>,</span>
<span id="cb25-503"><a href="#cb25-503" aria-hidden="true" tabindex="-1"></a>  <span class="at">by_val2    =</span> <span class="st">"antipartisan"</span>,</span>
<span id="cb25-504"><a href="#cb25-504" aria-hidden="true" tabindex="-1"></a>  <span class="at">replications =</span> <span class="dv">100</span></span>
<span id="cb25-505"><a href="#cb25-505" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb25-506"><a href="#cb25-506" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-507"><a href="#cb25-507" aria-hidden="true" tabindex="-1"></a>Not surprisingly, power is still low—around 23%. But now, let's systematically explore how power increases as we raise the number of worlds per treatment:</span>
<span id="cb25-508"><a href="#cb25-508" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-511"><a href="#cb25-511" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-512"><a href="#cb25-512" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-N-power2</span></span>
<span id="cb25-513"><a href="#cb25-513" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: The power in our experiment depending on n (simulation results). </span></span>
<span id="cb25-514"><a href="#cb25-514" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-align: center</span></span>
<span id="cb25-515"><a href="#cb25-515" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb25-516"><a href="#cb25-516" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: Show R Code (Power plot)</span></span>
<span id="cb25-517"><a href="#cb25-517" aria-hidden="true" tabindex="-1"></a>sample_size <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">10</span>, <span class="dv">30</span>, <span class="at">by =</span> <span class="dv">1</span>)</span>
<span id="cb25-518"><a href="#cb25-518" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-519"><a href="#cb25-519" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">sample_size =</span> sample_size) <span class="sc">|&gt;</span></span>
<span id="cb25-520"><a href="#cb25-520" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb25-521"><a href="#cb25-521" aria-hidden="true" tabindex="-1"></a>    <span class="at">power =</span> <span class="fu">map_dbl</span>(sample_size, <span class="sc">~</span> </span>
<span id="cb25-522"><a href="#cb25-522" aria-hidden="true" tabindex="-1"></a>      <span class="fu">get_power_from_simulation</span>(</span>
<span id="cb25-523"><a href="#cb25-523" aria-hidden="true" tabindex="-1"></a>        <span class="at">df           =</span> df_polarization,</span>
<span id="cb25-524"><a href="#cb25-524" aria-hidden="true" tabindex="-1"></a>        <span class="at">n_1          =</span> .x,</span>
<span id="cb25-525"><a href="#cb25-525" aria-hidden="true" tabindex="-1"></a>        <span class="at">n_2          =</span> .x,</span>
<span id="cb25-526"><a href="#cb25-526" aria-hidden="true" tabindex="-1"></a>        <span class="at">by_var       =</span> network,</span>
<span id="cb25-527"><a href="#cb25-527" aria-hidden="true" tabindex="-1"></a>        <span class="at">by_val1      =</span> <span class="st">"neutral"</span>,</span>
<span id="cb25-528"><a href="#cb25-528" aria-hidden="true" tabindex="-1"></a>        <span class="at">by_val2      =</span> <span class="st">"antipartisan"</span>,</span>
<span id="cb25-529"><a href="#cb25-529" aria-hidden="true" tabindex="-1"></a>        <span class="at">replications =</span> <span class="dv">100</span></span>
<span id="cb25-530"><a href="#cb25-530" aria-hidden="true" tabindex="-1"></a>      )</span>
<span id="cb25-531"><a href="#cb25-531" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb25-532"><a href="#cb25-532" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb25-533"><a href="#cb25-533" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-534"><a href="#cb25-534" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(plotly)</span>
<span id="cb25-535"><a href="#cb25-535" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-536"><a href="#cb25-536" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_ly</span>(df, </span>
<span id="cb25-537"><a href="#cb25-537" aria-hidden="true" tabindex="-1"></a>        <span class="at">x =</span> <span class="sc">~</span>sample_size, </span>
<span id="cb25-538"><a href="#cb25-538" aria-hidden="true" tabindex="-1"></a>        <span class="at">y =</span> <span class="sc">~</span>power, </span>
<span id="cb25-539"><a href="#cb25-539" aria-hidden="true" tabindex="-1"></a>        <span class="at">type =</span> <span class="st">'scatter'</span>, </span>
<span id="cb25-540"><a href="#cb25-540" aria-hidden="true" tabindex="-1"></a>        <span class="at">name =</span> <span class="st">'Power by n'</span>,</span>
<span id="cb25-541"><a href="#cb25-541" aria-hidden="true" tabindex="-1"></a>        <span class="at">mode =</span> <span class="st">'lines+markers'</span>,</span>
<span id="cb25-542"><a href="#cb25-542" aria-hidden="true" tabindex="-1"></a>        <span class="at">hoverinfo =</span> <span class="st">'text'</span>,</span>
<span id="cb25-543"><a href="#cb25-543" aria-hidden="true" tabindex="-1"></a>        <span class="at">text =</span> <span class="sc">~</span><span class="fu">paste0</span>(<span class="st">'N = '</span>, sample_size, <span class="st">'&lt;br&gt;Power = '</span>, <span class="fu">round</span>(power, <span class="dv">2</span>))</span>
<span id="cb25-544"><a href="#cb25-544" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb25-545"><a href="#cb25-545" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_lines</span>(<span class="at">x =</span> <span class="sc">~</span>sample_size, </span>
<span id="cb25-546"><a href="#cb25-546" aria-hidden="true" tabindex="-1"></a>            <span class="at">y =</span> <span class="fu">rep</span>(<span class="fl">0.8</span>, <span class="fu">nrow</span>(df)), </span>
<span id="cb25-547"><a href="#cb25-547" aria-hidden="true" tabindex="-1"></a>            <span class="at">line =</span> <span class="fu">list</span>(<span class="at">dash =</span> <span class="st">'dash'</span>, <span class="at">color =</span> <span class="st">'red'</span>),</span>
<span id="cb25-548"><a href="#cb25-548" aria-hidden="true" tabindex="-1"></a>            <span class="at">name =</span> <span class="st">'80% Power'</span>) <span class="sc">%&gt;%</span></span>
<span id="cb25-549"><a href="#cb25-549" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layout</span>(</span>
<span id="cb25-550"><a href="#cb25-550" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">'Power vs. Sample Size'</span>,</span>
<span id="cb25-551"><a href="#cb25-551" aria-hidden="true" tabindex="-1"></a>    <span class="at">xaxis =</span> <span class="fu">list</span>(<span class="at">title =</span> <span class="st">'Sample Size (N)'</span>),</span>
<span id="cb25-552"><a href="#cb25-552" aria-hidden="true" tabindex="-1"></a>    <span class="at">yaxis =</span> <span class="fu">list</span>(<span class="at">title =</span> <span class="st">'Power'</span>),</span>
<span id="cb25-553"><a href="#cb25-553" aria-hidden="true" tabindex="-1"></a>    <span class="at">showlegend =</span> <span class="cn">TRUE</span></span>
<span id="cb25-554"><a href="#cb25-554" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb25-555"><a href="#cb25-555" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-556"><a href="#cb25-556" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-557"><a href="#cb25-557" aria-hidden="true" tabindex="-1"></a>We observe that even with a symmetric sample size of 19 worlds per condition or an $N=38$, we achieve over 80% power. This is a bit lower than our earlier approximation using analytical methods—likely because our original estimate was based on only 4 observations to calculate $\sigma$, introducing higher variability.</span>
<span id="cb25-558"><a href="#cb25-558" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-559"><a href="#cb25-559" aria-hidden="true" tabindex="-1"></a>We can inspect the effect size again for the the complete run (all 8000 worlds):</span>
<span id="cb25-560"><a href="#cb25-560" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-563"><a href="#cb25-563" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-564"><a href="#cb25-564" aria-hidden="true" tabindex="-1"></a><span class="fu">cohen.d</span>(</span>
<span id="cb25-565"><a href="#cb25-565" aria-hidden="true" tabindex="-1"></a>  <span class="at">formula =</span> abs_diff_opinion_1 <span class="sc">~</span> network,</span>
<span id="cb25-566"><a href="#cb25-566" aria-hidden="true" tabindex="-1"></a>  <span class="at">data    =</span> df_polarization <span class="sc">|&gt;</span> <span class="fu">filter</span>(network <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">"neutral"</span>, <span class="st">"antipartisan"</span>)) <span class="sc">|&gt;</span> </span>
<span id="cb25-567"><a href="#cb25-567" aria-hidden="true" tabindex="-1"></a>    <span class="fu">droplevels</span>(),</span>
<span id="cb25-568"><a href="#cb25-568" aria-hidden="true" tabindex="-1"></a>  <span class="at">pooled  =</span> <span class="cn">TRUE</span>,</span>
<span id="cb25-569"><a href="#cb25-569" aria-hidden="true" tabindex="-1"></a>  <span class="at">hedges.correction =</span> <span class="cn">FALSE</span></span>
<span id="cb25-570"><a href="#cb25-570" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb25-571"><a href="#cb25-571" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-572"><a href="#cb25-572" aria-hidden="true" tabindex="-1"></a>We see that this is not far off what we initially estimated. </span>
<span id="cb25-573"><a href="#cb25-573" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-574"><a href="#cb25-574" aria-hidden="true" tabindex="-1"></a>This simulation-based approach gives us a robust, assumption-light estimate of the power under realistic experimental conditions. It’s particularly valuable when classical formulas are too simplistic for the design at hand.</span>
<span id="cb25-575"><a href="#cb25-575" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-576"><a href="#cb25-576" aria-hidden="true" tabindex="-1"></a><span class="fu">## Why Use Unequal Sample Sizes?</span></span>
<span id="cb25-577"><a href="#cb25-577" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-578"><a href="#cb25-578" aria-hidden="true" tabindex="-1"></a>Throughout this chapter, we have primarily assumed equal sample sizes for treatment and control groups (i.e., $n_0 = n_1$). This design is indeed statistically optimal: comparing 10 vs. 10 yields more power than, for example, 19 vs. 1. In general, power is maximized when group sizes are balanced, assuming all else is equal.</span>
<span id="cb25-579"><a href="#cb25-579" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-580"><a href="#cb25-580" aria-hidden="true" tabindex="-1"></a>However, there are several situations in which using **unequal sample sizes** is not only acceptable, but actually advisable.</span>
<span id="cb25-581"><a href="#cb25-581" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-582"><a href="#cb25-582" aria-hidden="true" tabindex="-1"></a><span class="fu">### 1. Cost Constraints</span></span>
<span id="cb25-583"><a href="#cb25-583" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-584"><a href="#cb25-584" aria-hidden="true" tabindex="-1"></a>In some experiments, one treatment group may be significantly more expensive to implement than the other. For example, if administering the treatment requires costly resources—say, specialist time, hardware, or financial incentives—while the control group involves only basic measurement, then a balanced design may be impractical.</span>
<span id="cb25-585"><a href="#cb25-585" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-586"><a href="#cb25-586" aria-hidden="true" tabindex="-1"></a>Instead of running a 10 vs. 10 trial, you might run 15 vs. 8. Although this introduces some statistical inefficiency, it may still be preferable if it leads to lower overall cost. The trade-off here is between statistical power and budget efficiency: slightly reduced power may be acceptable if it enables more feasible execution.</span>
<span id="cb25-587"><a href="#cb25-587" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-588"><a href="#cb25-588" aria-hidden="true" tabindex="-1"></a><span class="fu">### 2. Logistical or External Constraints</span></span>
<span id="cb25-589"><a href="#cb25-589" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-590"><a href="#cb25-590" aria-hidden="true" tabindex="-1"></a>Sometimes, sample sizes in one group are fixed by circumstances beyond the researcher’s control. For example:</span>
<span id="cb25-591"><a href="#cb25-591" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-592"><a href="#cb25-592" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>You may only have access to a limited number of treated units (e.g., policy participants, rare populations, or invited experts).</span>
<span id="cb25-593"><a href="#cb25-593" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The treatment group could be capped due to institutional or ethical limits.</span>
<span id="cb25-594"><a href="#cb25-594" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Recruitment channels might produce uneven inflows into treatment and control.</span>
<span id="cb25-595"><a href="#cb25-595" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-596"><a href="#cb25-596" aria-hidden="true" tabindex="-1"></a>In such cases, the sample size for one group is fixed, and the researcher must calculate the **required sample size for the other group** to achieve the desired power.</span>
<span id="cb25-597"><a href="#cb25-597" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-598"><a href="#cb25-598" aria-hidden="true" tabindex="-1"></a><span class="fu">### 3. Adaptive Designs and Reweighting</span></span>
<span id="cb25-599"><a href="#cb25-599" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-600"><a href="#cb25-600" aria-hidden="true" tabindex="-1"></a>Unequal sample sizes may also emerge as a result of **adaptive experimental designs**, where assignment probabilities shift over time (e.g., in multi-armed bandits). Or, they may reflect **intentional oversampling** of one group to ensure adequate representation or variance for subgroup analysis.</span>
<span id="cb25-601"><a href="#cb25-601" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-602"><a href="#cb25-602" aria-hidden="true" tabindex="-1"></a>Statistical techniques such as weighted regression or generalized estimating equations can help correct for imbalances, especially in observational or quasi-experimental contexts.</span>
<span id="cb25-603"><a href="#cb25-603" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-604"><a href="#cb25-604" aria-hidden="true" tabindex="-1"></a>In summary, while equal sample sizes provide maximum statistical efficiency, real-world considerations—such as cost, availability, and ethics—can justify unequal designs. In such cases, power analysis becomes especially important to determine how best to allocate limited resources while still preserving the ability to detect meaningful effects.</span>
<span id="cb25-605"><a href="#cb25-605" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-606"><a href="#cb25-606" aria-hidden="true" tabindex="-1"></a><span class="fu"># Increasing Power Further</span></span>
<span id="cb25-607"><a href="#cb25-607" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-608"><a href="#cb25-608" aria-hidden="true" tabindex="-1"></a>Until now, we have primarily focused on increasing power by adjusting **sample size**—arguably the most straightforward and commonly used approach. However, as previously discussed, sample size is not the only lever available to researchers. Another highly effective strategy is to use the **most efficient test statistic** for the research question and data structure at hand. </span>
<span id="cb25-609"><a href="#cb25-609" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-610"><a href="#cb25-610" aria-hidden="true" tabindex="-1"></a>But what exactly does that mean? To understand this, let’s reconsider the structure of our experiment:</span>
<span id="cb25-611"><a href="#cb25-611" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-612"><a href="#cb25-612" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-613"><a href="#cb25-613" aria-hidden="true" tabindex="-1"></a>R \longrightarrow T_0 \longrightarrow Y_0 \newline</span>
<span id="cb25-614"><a href="#cb25-614" aria-hidden="true" tabindex="-1"></a>R \longrightarrow T_1 \longrightarrow Y_1</span>
<span id="cb25-615"><a href="#cb25-615" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-616"><a href="#cb25-616" aria-hidden="true" tabindex="-1"></a>In this setup, participants are randomized ($R$) into either a control group ($T_0$, *neutral*) or a treatment group ($T_1$, *antipartisan*), and we then measure the outcome—average partisan difference in opinions—after the treatment.</span>
<span id="cb25-617"><a href="#cb25-617" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-618"><a href="#cb25-618" aria-hidden="true" tabindex="-1"></a>However, our actual experimental design contains more information:</span>
<span id="cb25-619"><a href="#cb25-619" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-620"><a href="#cb25-620" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-621"><a href="#cb25-621" aria-hidden="true" tabindex="-1"></a>R \longrightarrow Y_0^{t_0} \longrightarrow T_0 \longrightarrow Y_0^{t_1} \newline</span>
<span id="cb25-622"><a href="#cb25-622" aria-hidden="true" tabindex="-1"></a>R \longrightarrow Y_1^{t_0} \longrightarrow T_1 \longrightarrow Y_1^{t_1}</span>
<span id="cb25-623"><a href="#cb25-623" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-624"><a href="#cb25-624" aria-hidden="true" tabindex="-1"></a>That is, we also collect an initial measurement of opinions **before** treatment assignment, allowing us to observe polarization at baseline ($Y^{t_0}$), in addition to the post-treatment outcome ($Y^{t_1}$).</span>
<span id="cb25-625"><a href="#cb25-625" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-626"><a href="#cb25-626" aria-hidden="true" tabindex="-1"></a>This pre-treatment measurement allows for a more precise analysis. Instead of relying solely on a simple $t$-test comparing post-treatment outcomes, we can now use a regression model that adjusts for baseline polarization. This approach not only increases statistical power but also helps account for initial differences between groups.</span>
<span id="cb25-627"><a href="#cb25-627" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-628"><a href="#cb25-628" aria-hidden="true" tabindex="-1"></a>Fortunately, our <span class="in">`calc_polarization()`</span> function supports this by allowing us to extract both final and initial polarization measures:</span>
<span id="cb25-629"><a href="#cb25-629" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-632"><a href="#cb25-632" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-633"><a href="#cb25-633" aria-hidden="true" tabindex="-1"></a>df_polarization <span class="ot">&lt;-</span> <span class="fu">calc_polarization</span>(meta_results) <span class="sc">|&gt;</span> <span class="co"># get final polarization</span></span>
<span id="cb25-634"><a href="#cb25-634" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_cols</span>(</span>
<span id="cb25-635"><a href="#cb25-635" aria-hidden="true" tabindex="-1"></a>    <span class="fu">calc_polarization</span>(meta_results, <span class="at">table =</span> <span class="st">"init"</span>) <span class="sc">|&gt;</span> <span class="co"># get inital polarization</span></span>
<span id="cb25-636"><a href="#cb25-636" aria-hidden="true" tabindex="-1"></a>      <span class="fu">rename</span>(<span class="at">abs_diff_opinion_1_init =</span> abs_diff_opinion_1) <span class="sc">|&gt;</span> </span>
<span id="cb25-637"><a href="#cb25-637" aria-hidden="true" tabindex="-1"></a>      dplyr<span class="sc">::</span><span class="fu">select</span>(abs_diff_opinion_1_init)</span>
<span id="cb25-638"><a href="#cb25-638" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb25-639"><a href="#cb25-639" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-640"><a href="#cb25-640" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-641"><a href="#cb25-641" aria-hidden="true" tabindex="-1"></a>Next, we redefine our <span class="in">`run_test()`</span> function to include <span class="in">`abs_diff_opinion_1_init`</span> as a covariate in the regression:</span>
<span id="cb25-642"><a href="#cb25-642" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-645"><a href="#cb25-645" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-646"><a href="#cb25-646" aria-hidden="true" tabindex="-1"></a>run_test <span class="ot">&lt;-</span> <span class="cf">function</span>(df){</span>
<span id="cb25-647"><a href="#cb25-647" aria-hidden="true" tabindex="-1"></a>    fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(abs_diff_opinion_1  <span class="sc">~</span> network <span class="sc">+</span> abs_diff_opinion_1_init,</span>
<span id="cb25-648"><a href="#cb25-648" aria-hidden="true" tabindex="-1"></a>              <span class="at">data =</span> df</span>
<span id="cb25-649"><a href="#cb25-649" aria-hidden="true" tabindex="-1"></a>              )</span>
<span id="cb25-650"><a href="#cb25-650" aria-hidden="true" tabindex="-1"></a>    coefs <span class="ot">&lt;-</span> <span class="fu">summary</span>(fit)<span class="sc">$</span>coefficients</span>
<span id="cb25-651"><a href="#cb25-651" aria-hidden="true" tabindex="-1"></a>    <span class="co"># coefficient name for group effect</span></span>
<span id="cb25-652"><a href="#cb25-652" aria-hidden="true" tabindex="-1"></a>    coef_name <span class="ot">&lt;-</span> <span class="st">"networkantipartisan"</span></span>
<span id="cb25-653"><a href="#cb25-653" aria-hidden="true" tabindex="-1"></a>    p_val <span class="ot">&lt;-</span> coefs[coef_name, <span class="st">"Pr(&gt;|t|)"</span>]</span>
<span id="cb25-654"><a href="#cb25-654" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-655"><a href="#cb25-655" aria-hidden="true" tabindex="-1"></a>    p_val <span class="sc">&lt;</span> <span class="fl">0.05</span> <span class="co"># alpha</span></span>
<span id="cb25-656"><a href="#cb25-656" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb25-657"><a href="#cb25-657" aria-hidden="true" tabindex="-1"></a><span class="in">```</span> </span>
<span id="cb25-658"><a href="#cb25-658" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-659"><a href="#cb25-659" aria-hidden="true" tabindex="-1"></a>With this updated model in place, we can now rerun our power analysis using regression instead of a $t$-test:</span>
<span id="cb25-660"><a href="#cb25-660" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-663"><a href="#cb25-663" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-664"><a href="#cb25-664" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-N-power3</span></span>
<span id="cb25-665"><a href="#cb25-665" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: The power in our experiment depending on n (simulation results). </span></span>
<span id="cb25-666"><a href="#cb25-666" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-align: center</span></span>
<span id="cb25-667"><a href="#cb25-667" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb25-668"><a href="#cb25-668" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: Show R Code (Power plot)</span></span>
<span id="cb25-669"><a href="#cb25-669" aria-hidden="true" tabindex="-1"></a>sample_size <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">2</span>, <span class="dv">15</span>, <span class="at">by =</span> <span class="dv">1</span>)</span>
<span id="cb25-670"><a href="#cb25-670" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-671"><a href="#cb25-671" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-672"><a href="#cb25-672" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">sample_size =</span> sample_size) <span class="sc">|&gt;</span></span>
<span id="cb25-673"><a href="#cb25-673" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb25-674"><a href="#cb25-674" aria-hidden="true" tabindex="-1"></a>    <span class="at">power =</span> <span class="fu">map_dbl</span>(sample_size, <span class="sc">~</span> </span>
<span id="cb25-675"><a href="#cb25-675" aria-hidden="true" tabindex="-1"></a>      <span class="fu">get_power_from_simulation</span>(</span>
<span id="cb25-676"><a href="#cb25-676" aria-hidden="true" tabindex="-1"></a>        <span class="at">df           =</span> df_polarization,</span>
<span id="cb25-677"><a href="#cb25-677" aria-hidden="true" tabindex="-1"></a>        <span class="at">n_1          =</span> .x,</span>
<span id="cb25-678"><a href="#cb25-678" aria-hidden="true" tabindex="-1"></a>        <span class="at">n_2          =</span> .x,</span>
<span id="cb25-679"><a href="#cb25-679" aria-hidden="true" tabindex="-1"></a>        <span class="at">by_var       =</span> network,</span>
<span id="cb25-680"><a href="#cb25-680" aria-hidden="true" tabindex="-1"></a>        <span class="at">by_val1      =</span> <span class="st">"neutral"</span>,</span>
<span id="cb25-681"><a href="#cb25-681" aria-hidden="true" tabindex="-1"></a>        <span class="at">by_val2      =</span> <span class="st">"antipartisan"</span>,</span>
<span id="cb25-682"><a href="#cb25-682" aria-hidden="true" tabindex="-1"></a>        <span class="at">replications =</span> <span class="dv">100</span></span>
<span id="cb25-683"><a href="#cb25-683" aria-hidden="true" tabindex="-1"></a>      )</span>
<span id="cb25-684"><a href="#cb25-684" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb25-685"><a href="#cb25-685" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb25-686"><a href="#cb25-686" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-687"><a href="#cb25-687" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(plotly)</span>
<span id="cb25-688"><a href="#cb25-688" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-689"><a href="#cb25-689" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_ly</span>(df, </span>
<span id="cb25-690"><a href="#cb25-690" aria-hidden="true" tabindex="-1"></a>        <span class="at">x =</span> <span class="sc">~</span>sample_size, </span>
<span id="cb25-691"><a href="#cb25-691" aria-hidden="true" tabindex="-1"></a>        <span class="at">y =</span> <span class="sc">~</span>power, </span>
<span id="cb25-692"><a href="#cb25-692" aria-hidden="true" tabindex="-1"></a>        <span class="at">type =</span> <span class="st">'scatter'</span>, </span>
<span id="cb25-693"><a href="#cb25-693" aria-hidden="true" tabindex="-1"></a>        <span class="at">name =</span> <span class="st">'Power by n'</span>,</span>
<span id="cb25-694"><a href="#cb25-694" aria-hidden="true" tabindex="-1"></a>        <span class="at">mode =</span> <span class="st">'lines+markers'</span>,</span>
<span id="cb25-695"><a href="#cb25-695" aria-hidden="true" tabindex="-1"></a>        <span class="at">hoverinfo =</span> <span class="st">'text'</span>,</span>
<span id="cb25-696"><a href="#cb25-696" aria-hidden="true" tabindex="-1"></a>        <span class="at">text =</span> <span class="sc">~</span><span class="fu">paste0</span>(<span class="st">'N = '</span>, sample_size, <span class="st">'&lt;br&gt;Power = '</span>, <span class="fu">round</span>(power, <span class="dv">2</span>))</span>
<span id="cb25-697"><a href="#cb25-697" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb25-698"><a href="#cb25-698" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_lines</span>(<span class="at">x =</span> <span class="sc">~</span>sample_size, </span>
<span id="cb25-699"><a href="#cb25-699" aria-hidden="true" tabindex="-1"></a>            <span class="at">y =</span> <span class="fu">rep</span>(<span class="fl">0.8</span>, <span class="fu">nrow</span>(df)), </span>
<span id="cb25-700"><a href="#cb25-700" aria-hidden="true" tabindex="-1"></a>            <span class="at">line =</span> <span class="fu">list</span>(<span class="at">dash =</span> <span class="st">'dash'</span>, <span class="at">color =</span> <span class="st">'red'</span>),</span>
<span id="cb25-701"><a href="#cb25-701" aria-hidden="true" tabindex="-1"></a>            <span class="at">name =</span> <span class="st">'80% Power'</span>) <span class="sc">%&gt;%</span></span>
<span id="cb25-702"><a href="#cb25-702" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layout</span>(</span>
<span id="cb25-703"><a href="#cb25-703" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">'Power vs. Sample Size'</span>,</span>
<span id="cb25-704"><a href="#cb25-704" aria-hidden="true" tabindex="-1"></a>    <span class="at">xaxis =</span> <span class="fu">list</span>(<span class="at">title =</span> <span class="st">'Sample Size (N)'</span>),</span>
<span id="cb25-705"><a href="#cb25-705" aria-hidden="true" tabindex="-1"></a>    <span class="at">yaxis =</span> <span class="fu">list</span>(<span class="at">title =</span> <span class="st">'Power'</span>),</span>
<span id="cb25-706"><a href="#cb25-706" aria-hidden="true" tabindex="-1"></a>    <span class="at">showlegend =</span> <span class="cn">TRUE</span></span>
<span id="cb25-707"><a href="#cb25-707" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb25-708"><a href="#cb25-708" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-709"><a href="#cb25-709" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-710"><a href="#cb25-710" aria-hidden="true" tabindex="-1"></a>As shown in the plot, adjusting for baseline polarization dramatically improves the power of our experiment. With this more sophisticated approach, a sample size of just $n = 4$ per group is already sufficient to surpass 80% power. At $n = 5$, power approaches nearly 100%.</span>
<span id="cb25-711"><a href="#cb25-711" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-712"><a href="#cb25-712" aria-hidden="true" tabindex="-1"></a>This is a **significant improvement** over our initial $t$-test-only approach—and one that could save considerable time and resources. It underscores the value of leveraging all available data and using appropriate statistical models to maximize efficiency in experimental design.</span>
<span id="cb25-713"><a href="#cb25-713" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-714"><a href="#cb25-714" aria-hidden="true" tabindex="-1"></a><span class="fu"># 🧩 Conclusion</span></span>
<span id="cb25-715"><a href="#cb25-715" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-716"><a href="#cb25-716" aria-hidden="true" tabindex="-1"></a>In this chapter, we explored how power analysis serves as a critical tool for designing effective and efficient experiments. We began by revisiting the statistical foundations—clarifying the trade-off between **power** ($1 - \beta$) and **specificity** ($1 - \alpha$)—and showed how low-powered studies can lead to ambiguous or misleading conclusions.</span>
<span id="cb25-717"><a href="#cb25-717" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-718"><a href="#cb25-718" aria-hidden="true" tabindex="-1"></a>We then examined both **analytical** and **simulation-based** methods for calculating statistical power. While analytical formulas offer quick approximations, simulation-based approaches provide the flexibility needed for more complex or realistic experimental designs—especially in agent-based modeling contexts.</span>
<span id="cb25-719"><a href="#cb25-719" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-720"><a href="#cb25-720" aria-hidden="true" tabindex="-1"></a>Using our own calibrated opinion dynamics model, we demonstrated how simulation can help estimate the number of "worlds" required to detect meaningful treatment effects. We also showed how controlling for pre-treatment measurements—such as initial polarization—can significantly increase statistical power, allowing us to draw stronger conclusions with fewer resources.</span>
<span id="cb25-721"><a href="#cb25-721" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-722"><a href="#cb25-722" aria-hidden="true" tabindex="-1"></a>In practice, power analysis supports better planning, more transparent preregistration, and stronger scientific claims. Whether you're preparing a grant proposal, designing a pilot, or running a full-scale experiment, power analysis ensures that your study is not only feasible but also meaningful.</span>
<span id="cb25-723"><a href="#cb25-723" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-724"><a href="#cb25-724" aria-hidden="true" tabindex="-1"></a>Ultimately, power analysis is not just a technical requirement—it’s a safeguard for scientific integrity and a cornerstone of responsible research design.</span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":true,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>