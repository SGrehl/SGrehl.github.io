[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Experimental Sociology and Computational Social Sciences",
    "section": "",
    "text": "Note\n\n\n\nSome of the material (due to copyright issues) can be found at moodle. The password is provided in the sessions of the first week."
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "Experimental Sociology and Computational Social Sciences",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nA good tip from someone who‚Äôs spent hours raging over broken code: The problem is 99.99999% of the time sitting in front of the screen. You probably made a silly mistake and just aren‚Äôt spotting it right now. Keep calm, drink some tea and relax. In this respect, ChatGPT changed my life ‚Äî just ask it where the error is, and it will usually confront you with your obvious mistake.‚Ü©Ô∏é"
  },
  {
    "objectID": "general-information/exam.html",
    "href": "general-information/exam.html",
    "title": "Course Assessment",
    "section": "",
    "text": "Every two weeks, in one of the courses, we will assign you a problem set (√úbungsblatt). You will typically have at least one week to complete and submit your solutions. You can hand in your solutions either as a Markdown or a Quarto Skript.\n\n\n\n\n\n\n\n\nWeek\nCourse\nTopics\n\n\n\n\n2\nCSS\ntba\n\n\n4\nCSS\ntba\n\n\n6\nES\ntba\n\n\n8\nCSS\ntba\n\n\n10\nES\ntba\n\n\n12\nES\ntba"
  },
  {
    "objectID": "general-information/exam.html#general-information",
    "href": "general-information/exam.html#general-information",
    "title": "Course Assessment",
    "section": "General Information",
    "text": "General Information\n\nLength: 4,500 words (¬± 10%, approximately 15 pages, excluding the title page, references, and tables)\nFormatting:\n\n12 pt font size\n1.5 line spacing\nJustified text alignment\n\nLanguage: German or English (American or British)\nStructure: Write it like a scientific paper. Include an abstract, but no table of contents. Ensure that your figures are informative and that tables are compact and free from redundancies.\nTone: Use precise and professional scientific language. Clearly motivate your work and place it within the context of existing literature.\nDeadline: TBA"
  },
  {
    "objectID": "general-information/exam.html#topic",
    "href": "general-information/exam.html#topic",
    "title": "Course Assessment",
    "section": "Topic",
    "text": "Topic\nYou are essentially free to choose any topic that connects to one of our courses. However, keep in mind that different types of projects will naturally require different levels of effort for different parts of the term paper.\n\nThe more complex your data acquisition is, the less complex your data analysis can be. In theory, there could even be extreme cases where a very complex data acquisition process means that no data analysis is required (e.g., if the script runs for months scraping data that cannot be used before the end of the semester).\nOn the other hand, if you use an existing dataset (where data preparation is straightforward), we will expect a more in-depth and sophisticated statistical analysis.\n\nIn general: talk to us ‚Äî we will help you determine whether your project is too ambitious or too simple, where to focus your effort, and how to balance the workload. Also, keep in mind that your term paper can be the foundation for a larger, more complex project (e.g., your master‚Äôs thesis).\n\n\n\n\n\n\n\nField\nPossible topics\n\n\n\n\nES in general\n\nWrite a detailed pre-registration plan for an experiment.\n\n\n\nAgent-based models\n\nWrite a new, simple ABM.\nReproduce and modify an existing ABM.\nExamine an existing ABM in depth (e.g.¬†sensitivity analysis)\n\n\n\nCSS in general\n\nAnalyse existing data.\nScrape or combine new datasets (and analyze them).\n\n\n\nNetworks\n\nUse existing network data and apply it to a new problem.\nGenerate a new network dataset.\n\n\n\nSpatial data\n\nUse existing spatial data and apply it to a new problem.\nGenerate a new spatial dataset."
  },
  {
    "objectID": "general-information/anti_dis.html",
    "href": "general-information/anti_dis.html",
    "title": "Anti-Discrimination Policy",
    "section": "",
    "text": "Guidelines"
  },
  {
    "objectID": "experimental-sociology/week02.html",
    "href": "experimental-sociology/week02.html",
    "title": "Experimental Sociology - Week 2",
    "section": "",
    "text": "This week is about"
  },
  {
    "objectID": "experimental-sociology/week02.html#learning-goals",
    "href": "experimental-sociology/week02.html#learning-goals",
    "title": "Experimental Sociology - Week 2",
    "section": "üéØ Learning Goals",
    "text": "üéØ Learning Goals\nBy the end of this week, you should:\n\nKnow the difference between hypotheses and propositions.\nUnderstand why analytical solutions are valuable in the social sciences.\nRecognize the limitations of analytical solutions when applied to complex social situations.\nBe able to model a simple social interaction using Game Theory.\nUnderstand how introducing bounded rationality increases complexity."
  },
  {
    "objectID": "experimental-sociology/week02.html#section",
    "href": "experimental-sociology/week02.html#section",
    "title": "Experimental Sociology - Week 2",
    "section": "",
    "text": "üß† Why Analytical Solutions Matter\nAnalytical solutions (often expressed as equations) are the gold standard in science because:\n\nThey provide precise answers.\nThey allow for clear causal interpretation.\nThey have a high objectivity, transparency and reproducibility.\nThey are often computationally fast.\n\n\n\nüöß Shortcomings of Analytical Solutions\nHowever, in the social sciences, analytical solutions can become difficult because:\nReality too complex to be captured analytically in its entirety Theories (and the respective equations) can capture only partial aspects of reality. Yet, Sometimes we want a complex, multifaceted analysis Combination of theories not necessarily analytically compatible or manageable\n\nModels of social behavior often become too complex to solve analytically.\nHuman behavior introduces noise and irrationality.\n\nTherefore we will look in two weeks at another approach, namly numerical solutions (e.g.¬†simulations)."
  },
  {
    "objectID": "experimental-sociology/week02.html#game-theory",
    "href": "experimental-sociology/week02.html#game-theory",
    "title": "Experimental Sociology - Week 2",
    "section": "Game Theory",
    "text": "Game Theory\nGame theory offers a structured approach to modeling social situations:\n\nPlayers ‚Äì Agents making decisions.\nStrategies ‚Äì Options available to the players.\nPayoffs ‚Äì Outcomes based on strategy combinations.\n\nüëâ Example: The Prisoner‚Äôs Dilemma ‚Äì A simple two-player game that reveals the challenge of cooperation and competition."
  },
  {
    "objectID": "experimental-sociology/week02.html#bounded-rationality",
    "href": "experimental-sociology/week02.html#bounded-rationality",
    "title": "Experimental Sociology - Week 2",
    "section": "üîé Bounded Rationality",
    "text": "üîé Bounded Rationality\n\nClassical game theory assumes perfectly rational actors.\nIn reality, humans often make decisions based on incomplete information and cognitive limitations (bounded rationality).\nIntroducing bounded rationality increases complexity ‚Äî solutions become harder to compute."
  },
  {
    "objectID": "experimental-sociology/es_overview.html",
    "href": "experimental-sociology/es_overview.html",
    "title": "Course Overview",
    "section": "",
    "text": "üåç Overview\nWelcome to the Experimental Sociology (ES) seminar!\nIn this course, we will explore how analytical and computational tools can be used to derive experimental research questions, optimize experimental design, and plan necessary observations more effectively. Together, we‚Äôll bridge the gap between theory and practice, using simulations and agent-based models (ABMs) to enhance the quality and efficiency of sociological research.\n\nGeneral Information\n\n\n\nWednesday, weekly\n11:15 - 12:45\n\n\nGWZ, H2 1.15\nStart: 2025-04-09\n\n\n\n\n\n\nüîç Focus\nOur focus will be twofold:\n\nHypothesis derivation: How can analytical tools and agent-based models (ABMs) help us derive meaningful hypotheses and design better experiments?\nPlanning an experiment: How can ABMs help us improve the statistical power of our experiments, save time and money, and make smarter design decisions (e.g., number of participants, treatment structure)?\n\n\n\nüéØ Course Goals\nBy the end of this course, you should be able to:\n\nModel a social problem so that it can be tackled analytically or via an ABM.\nProgram a simple ABM (either from scratch or with the help of an LLM).\nUse ABMs to design experiments ‚Äî including determining the number of participants needed to detect a given effect size and setting up meaningful treatments.\nUnderstand how to fine-tune experimental design to increase statistical power.\nReflect on the broader implications of experimental sociology and agent-based modeling in real-world research.\n\n\n\nüìñ Weekly Readings\nCourse materials will be provided weekly. Read at your own pace, and bring questions or ideas to the seminar! If some of the literature is not\n\n\nüóìÔ∏è Syllabus\n\n\n\nDate\nWeek\nSubject\nContent\nLiterature and Materials\n\n\n\n\n2025-04-09\n1\nKick-Off\n\nIntroduction\nCourse setup and structure\nWhat is the merit of an analytical solution?\nWhat are ABMs?\n\nReadings:\n\n\n2025-04-16\n2\nAnalytical Methods: Game Theory\n\nWhy analytical solutions?\nGame Theory\n\nReadings:\n\n\n2025-04-23\n3\nAnalytical Methods: Ecological Models & Evolutionary Game Theory\n\nDifferential Equations\nThe 3 ingredients of an evolutionary process\n\nReadings:\n\n\n2025-04-30\n4\nABMs: Basics\n\nBasic design principles of AMBs in R\nODD-Protocol\nA simple ABM with ChatGPT\n\nReadings:\n\n(Grimm et al. 2020)\n\n\n\n2025-05-07\n5\nEvolutionary ABMs: Basics\n\nLearning\nMutation\n\nReadings:\n\n\n2025-05-14\n6\nEvolutionary ABMs: Complex Simulations\n\nErrors & noise\nStrategy space\nRC vs.¬†Bounded Rationality\n\nReadings:\n\n\n2025-05-21\n7\nDiffusion: Basics\n\nSimple & complex contagion\nSIS/SIR/SIRD\nNetwork structures\n\nReadings:\n\n\n2025-05-28\n8\nDiffusion: Dispersion,Robustness & Sensitivity Analysis\n\nHow to deal with randomness\nDiscussions\nTerm Paper ideas\n\nReadings:\n\n\n2025-06-04\n9\nDiffusion: Calibration\n\nInput, model & output realism\nHow to do calibrate a model\n\nReadings:\n\n\n2025-06-11\n10\nMachine Learning: Basics\n\nSet up a simple machine learning (ML)\nPrecision & recall\nCross-validation\n\nReadings:\n\n\n2025-06-18\n11\nOpen Lab Session\n\nQ&A\nDiscussions\nTerm Paper ideas\n\nReadings:\n\n\n2025-06-25\n12\nStatistical Power, Randomization, Running an Experiment\n\nStatistical power via formula and simulation\nHow to increase statistical power?\nProblems, challenges, and more problems\n\nReadings:\nAdditional material:\n\nhttps://egap.org/resource/10-things-to-know-about-statistical-power/\nhttps://egap.org/resource/10-things-to-know-about-randomization/\n\n\n\n2025-07-02\n13\nSummary & Term Paper Presentation I\n\n\n\n\n2025-07-09\n14\nTerm Paper Presentation II\n\n\n\n\n\n\n\n\n\n\n\n\nReferences\n\nGrimm, Volker, Steven F. Railsback, Christian E. Vincenot, Uta Berger, Cara Gallagher, Donald L. DeAngelis, Bruce Edmonds, et al. 2020. ‚ÄúThe ODD Protocol for Describing Agent-Based and Other Simulation Models: A Second Update to Improve Clarity, Replication, and Structural Realism.‚Äù Journal of Artificial Societies and Social Simulation 23 (2): 7. https://doi.org/10.18564/jasss.4259."
  },
  {
    "objectID": "computational-social-sciences/week13.html",
    "href": "computational-social-sciences/week13.html",
    "title": "Week 13",
    "section": "",
    "text": "CopyrightCopyright Leonie Steinbrinker, 2025. All Rights Reserved"
  },
  {
    "objectID": "computational-social-sciences/week11.html",
    "href": "computational-social-sciences/week11.html",
    "title": "Week 11",
    "section": "",
    "text": "CopyrightCopyright Leonie Steinbrinker, 2025. All Rights Reserved"
  },
  {
    "objectID": "computational-social-sciences/week09.html",
    "href": "computational-social-sciences/week09.html",
    "title": "Week 09",
    "section": "",
    "text": "CopyrightCopyright Leonie Steinbrinker, 2025. All Rights Reserved"
  },
  {
    "objectID": "computational-social-sciences/week07.html",
    "href": "computational-social-sciences/week07.html",
    "title": "Week 07",
    "section": "",
    "text": "CopyrightCopyright Leonie Steinbrinker, 2025. All Rights Reserved"
  },
  {
    "objectID": "computational-social-sciences/week05.html",
    "href": "computational-social-sciences/week05.html",
    "title": "Week 05",
    "section": "",
    "text": "CopyrightCopyright Leonie Steinbrinker, 2025. All Rights Reserved"
  },
  {
    "objectID": "computational-social-sciences/week03.html",
    "href": "computational-social-sciences/week03.html",
    "title": "Week 03",
    "section": "",
    "text": "Network concepts\nComplete networks\nCliques\nPath\nDyads\n\n\n\n\n\n\nCopyrightCopyright Leonie Steinbrinker, 2025. All Rights Reserved"
  },
  {
    "objectID": "computational-social-sciences/week01.html",
    "href": "computational-social-sciences/week01.html",
    "title": "Week 01 - Kick-Off",
    "section": "",
    "text": "Welcome to the first session of Computational Social Sciences!\nToday, we will go over the plan for the semester, including:\nLooking forward to a great semester with you all!"
  },
  {
    "objectID": "computational-social-sciences/week01.html#getting-started",
    "href": "computational-social-sciences/week01.html#getting-started",
    "title": "Week 01 - Kick-Off",
    "section": "Getting started",
    "text": "Getting started\n\nInstallation\nIn case you haven`t installed R and RStudio\n\nInstall R\nInstall RStudio\n\n\n\n\nR-Meme (PsyTeachR)\n\n\nThis is the easiest way, you are of course allowed to use other source code editors (like VSCode, Eclipse, PyCharm, Vim, Emacs or any other preference you might have). I will show the examples in class using RStudio though.\n\n\nStart a new file\nCreate a new R Script, R Notebook, or Quarto document:\n\nGo to the menu bar and click on File.\nSelect New File.\nChoose the type of file you want to create (R Script, R Notebook, or Quarto document).\n\nWorking directory\n\n\nCode\n# Find the current workind directory (where inputs are found and output are send)\ngetwd()\n\n# Change the current working directory\nsetwd(\"C://your/file/path\")\n\n\nWhen we analyze data in R usually we also depend on functions, other users and developers have written, which are usually stored in so called packages. Packages can be installed and called like this:\n\n\nCode\ninstall.packages(\"igraph\")\n\nlibrary(igraph)\n\n\n\nAccessing help files\n\n\nCode\n# Get help of a particular function\nhelp(rnorm)\n# or\n?rnorm\n\n# Search te help files for a word or a phrase (if you don't know the name of the function)\nhelp.search(\"weighted mean\")\n# or\n??\"weighted mean\"\n\n# Find help for a package\nhelp(package=igraph)\n\n\n\n\n\nAtomic classes in R\nAtomic in this case means the data is of size = 1.\n\n\n\nName\nDescription\nExample\n\n\n\n\ninteger\nWhole numbers\n5\n\n\nnumeric\nDecimal numbers\n4.2\n\n\nlogic\nBoolean values\nTRUE, FALSE\n\n\ncharacter\nText or string values\n\"Hello\"\n\n\nNA\nMissing value indicator\nNA\n\n\nNULL\nMissing object indicator\nNULL\n\n\nNaN\nNot a number (e.g.¬†0/0)\nNaN\n\n\nInf\nPositive or negative infinity\nInf, -Inf\n\n\n\nChecking types\n\n\nCode\nint &lt;- 5L #capital L forces integer-storage\nnum &lt;- 42.1\nlog &lt;- TRUE\nchar &lt;- \"Hello\"\n\nclass(int)\nclass(num)\nclass(log)\nclass(char)\n\n\n\n\nBasic Operations\n\nStorage of values\nValues can be stored in Variables. The name of a variable starts with a letter and may consist of any sequence of letters, numbers, dot or underline characters.\n\n\nCode\n# assigning values to variables\na &lt;- 15.7\na\na + 10\na / 10\nround(a)\n\n# storing results in new variables\nb &lt;- round(a)\n\n\n\n\nArithmetic operations\n\n\nCode\n# Addition\n2 + 7\n\n# Substraction\n4 - 2\n\n# Multiplication\n5 * 2\n\n# Division\n8 / 2\n\n# Natural log\nlog(2)\n\n# Exponentation\n2^3\n\n# Exponential\nexp(7)\n\n# Round to nearest integer\nfloor(4.8)\nceiling(4.8)\n\n# Round\nround(7.5)\n\n\n\n\nLogical operations\n\n\nCode\n# is equal?\nb == a\n\n# is unequal?\nb != a\n\n# is greater?\nb &gt; a\n\n# is smaller?\nb &lt; a\n\n# is greater or equal?\nb &gt;= a\n\n# is smaller or equal?\nb &lt;= a\n\n\n# Further logical operations\n(3 &gt; 2) & (4 &gt; 1)   # AND\n(3 &gt; 5) | (1 &gt; 4)   # OR\n!TRUE  # NOT"
  },
  {
    "objectID": "computational-social-sciences/week01.html#classes-of-data-in-r",
    "href": "computational-social-sciences/week01.html#classes-of-data-in-r",
    "title": "Week 01 - Kick-Off",
    "section": "Classes of Data in R",
    "text": "Classes of Data in R\nR has several classes that define how data is structured and handled. Just to name a few:\n\n\n\n\n\n\n\n\nClass\nDescription\nExample\n\n\n\n\nvector\nBasic 1D array of elements of one type\nc(1, 2, 3)\n\n\nfactor\nCategorical data with levels\nfactor(c(\"low\", \"high\"))\n\n\nmatrix\n2D array with elements of one type\nmatrix(1:9, nrow = 3)\n\n\narray\nMulti-dimensional generalization of matrix\narray(1:12, dim = c(2,3,2))\n\n\nlist\nCollection of different types of objects\nlist(name=\"Alice\", age=25)\n\n\ndata.frame\nTabular data, columns can have different types\ndata.frame(a=1:3, b=c(\"x\",\"y\",\"z\"))\n\n\ntibble\nEnhanced version of a data frame\ntibble::tibble(a=1:3, b=c(\"x\",\"y\",\"z\"))\n\n\n\n\nVectors\nA vector is a simple data structure, that can store multiple elements of the same type. You can create a vector using the c() function.\n\n\n\n\n\n\nNote\n\n\n\nTo ensure, that all elements in a vector are of the same type, R will coerce the elements to the most general type. For example, if you combine a numeric and a character, the numeric will be coerced to a character.\n\n\n\n\nCode\nages &lt;- c(25, 30, 35, 40)\nnames &lt;- c(\"Albert\", \"Berta\", \"Charlie\", \"Dora\")\nsociologists &lt;- c(TRUE, FALSE, TRUE, FALSE)\n\n\n\nIndexication\nR indices start counting at 1, not at 0 like in many other programming languages. You can access elements of a vector, matrix, or data frame by using square brackets [].\n\n\nCode\n# Accessing elements of a vector\nages[1]\nnames[2]\nsociologists[3]\nages[c(1,4)] # First and fourth element\nnames[-1] #  All but the first element\nnames[names == \"Tom\"] #  All elements with the name \"Tom\"\nages[names == \"Tom\"] # Age of the person with the name \"Tom\"\n\n\n\nShort Exercise:\n\nWhat are the names of the sociologists?\nWhat are the ages of the non-sociologists?\nAre Berta and Charlie sociologists?\n\n\n\n\n\nMatrices\nMatrices are two-dimensional arrays with elements of the same type. You can create a matrix using the matrix() function.\n\n\nCode\nM &lt;- matrix(c(11, 0, 3, 3, 5, 1, 7, 1, 0),\n      nrow = 3)\nM\n\nN &lt;- matrix(1:9,\n      nrow = 3)\nN\n\n\n\nIndexication\n\n\nCode\nM[1, 2] # First row, second column\nM[1, ]   # First row\nM[, 2]   # Second column\n\n# name the row of a matrix\nrownames(M) &lt;- c(\"A\", \"B\", \"C\")\n\n# name the column of a matrix\ncolnames(M) &lt;- c(\"A\", \"B\", \"C\")\n\n\n\n\n\nData frames\nData frames are one of the most common data structures in R. They are two-dimensional objects, with rows and columns. Each column can have a different type. You can create a data frame using the data.frame() function.\n\n\nCode\ndf_friends &lt;- data.frame(name = names, \n                         religious = religious, \n                         age = ages)\ndf_friends\n\n\n\nIndexication\n\n\nCode\ndf_friends[3,]   # Dritte Zeile\n\ndf_friends[,2]   # Zweite Spalte\n\ndf_friends[3,2]  # Drittes Element in der zweiten Spalte\n\ndf_friends$name  # Zugriff auf eine Spalte per Namen\n\n\n\n\nAdd variables\n\n\nCode\nyear_of_birth &lt;- 2025 - df_friends$age\ndf_friends$birth_year &lt;- year_of_birth\n\ndf_friends$city &lt;- c(\"Leipzig\", \"Leipzig\", \"Berlin\", \"Leipzig\")\ndf_friends\n\n\n\n\n\nLists\nLists are collections of different types of objects. You can create a list using the list() function.\n\n\nCode\nfriends_list &lt;- list(\n  name = df_friends$name,\n  age = df_friends$age,\n  city = df_friends$city,\n  birth_year = df_friends$birth_year,\n  sociologists = df_friends$sociologists\n)\n\nfriends_list\n\n\n\nIndexication\n\n\nCode\nfriends_list$name # Index via name\nfriends_list[[1]] # Index via position\n\n\n# Further indexing\n\nlist_of_list &lt;- list(\n  l1 = friends_list,\n  l2 = list(\"something else\",\n            c(1:1000))\n)\n\nlist_of_lists$l1$name \nlist_of_lists[[1]][[1]] \nlist_of_lists[[2]]\n\n\n\n\n\nUnlist-meme (R-Memes for Statistical Friendss - Facebook 2017)"
  },
  {
    "objectID": "computational-social-sciences/week01.html#operations",
    "href": "computational-social-sciences/week01.html#operations",
    "title": "Week 01 - Kick-Off",
    "section": "Operations",
    "text": "Operations\nWe can perform several operations on different classes of vectors or variables. If we want to call variables we use the name of the object followed by the $ sign and the name of the variable.\n\n\nCode\n# give mimum value\nmin(vec)\n\n# give maximum value\nmax(vec)\n\n# give mean value\nmean(vec)\n\n# give median value\nmedian(vec)\n\n# give standard deviation\nsd(vec)\n\n# give sum of all values\nsum(vec)\n\n# give length of vector\nlength(vec)\n\n# give range of vector\nrange(vec)\n\n# give quantile of vector\nquantile(vec)\n\n# give unique values of vector\nunique(vec)\n\n# give number of unique values\nlength(unique(vec))\n\n# give frequency of values\ntable(vec)\n\n# This works also with variables. \nmean(my_data$score)"
  },
  {
    "objectID": "computational-social-sciences/week01.html#control-structures",
    "href": "computational-social-sciences/week01.html#control-structures",
    "title": "Week 01 - Kick-Off",
    "section": "Control structures",
    "text": "Control structures\nControl structures are used to control the flow of a program. They include loops and conditional statements.\n\n\n\n\n\n\nTip\n\n\n\nThere are two tips, that will make your programming game a whole lot easier: 1. Don`t repeat yourself: If you find yourself writing the same code over and over again, you should consider automating your task. 2. Divide and conquer: If you have a complex task, break it down into smaller, more manageable parts.\n\n\n\nIf-loops\nA if-loop is useful to discern between different cases. The syntax is as follows\nIf (condition) {\n# do something\n} else {\n# do something else\n}\nIf the condition (logical value) is true, the code in the first block will be executed. Otherwise, the code in the second block will be executed.\n\n\nCode\nx &lt;- 10\n\nif (x &gt; 0) {\n  print(TRUE)\n} else {\n  print(FALSE)\n}\n\n\nFor simple vector-based operations, you can use the ifelse() function. It has the following structure: ifelse(condition, value if true, value if false).\n\n\nCode\nbirthyear &lt;- c(1991, 1984, 1969, 2004, 1988, 2007, 1996)\n\nifelse(birthyear &lt; 1996, \"other\", \"Generation Z\")\n\n\n\n\nLoops\nThere are two main types of loops in R: for and while loops. 1. for (i in I) {code execution}: The for loop is used to iterate over a sequence of values in a set. 2. while (condition) {code execution}: The while loop is used to execute a block of code as long as a condition is true.\nExample: Compute how long a person still has to work until retirement (for-loop)\n\n\nCode\nages &lt;- c(21, 29, 61, 72, 12)\n\nfor (i in ages) {\n  if (i &gt;= 67) {\n    print(\"retired\")\n  }\n  if (i &lt; 18) {\n    print(\"in education\")\n  }\n  if (i &gt; 18 & i &lt; 67) {\n    rest &lt;- 67 - i\n    print(rest)\n  }\n}\n\n\nExample: Compute how long a person can drink, staying below a certain alcohol level and not spending more than a certain amount of money (while-loop)\n\n\nCode\nmoney &lt;- 25\nalcohol &lt;- 0\n\nwhile (money &gt;= 3 & alcohol &lt; 1.2) {\n    \n    money &lt;- money - 3\n    alcohol &lt;- alcohol + 0.3\n    \n    print(paste0(\"Money spent: \", money))\n    print(paste0(\"Alcohol in blood: \", alcohol))\n       \n}\n\n\n\n\nFunctions\nSometimes, we want to repeat a certain task multiple times. In this case, we can write a function. Functions are blocks of code that perform a specific task. They can take arguments as input and return a value as output. The syntax follows: function_name &lt;- function(argument) {function body}\nWhen doing this, the function is loaded as an object to the global environment.\n\n\nCode\n# Creating and using functions\nmy_function &lt;- function(x) {\n  \n  y &lt;- x^2 + 3\n\n  return(y)\n}\n\nmy_function(5)  # Example usage\n\n\nApply functions The family of apply functions is used to apply a function to the rows or columns of a matrix or data frame. The most common functions are apply(), lapply(), sapply(), and tapply(). In principle, they are a more efficient variant of for-loops running a function FUN over a vector or list X. Most often, we use lapply() which returns a list of outputs (one entry per part in X).\n\n\nCode\nnums &lt;- c(1:10)\nnew_nums &lt;- lapply(X = nums, # run over nums\n                   FUN = my_function) # run my_function\n                   \n\nnew_nums"
  },
  {
    "objectID": "computational-social-sciences/week01.html#global-environment",
    "href": "computational-social-sciences/week01.html#global-environment",
    "title": "Week 01 - Kick-Off",
    "section": "Global environment",
    "text": "Global environment\nThe global environment is the workspace of R. It contains all objects that you have created during your session. You can see all objects in the global environment in the upper right corner of RStudio. You can also list all objects in the global environment using the ls() function.\n\n\nCode\nls()\n\n# delete specific object\nrm(df_friends)\n\n# delete global environment\nrm(list = ls())\n\n# Save objects in global environment\n# Save data\nsave(df_friends, file = \"files/df_friends.RData\")\n\n# Load data\nload(\"files/df_friends.RData\")\n\n\nThat is about it. If you have any questions during the semester, feel free to ask! You can also always come back to this document to refresh your memory.\n\nHomework Next to the reading of the upcoming week, please\nPlease install the packages igraph, ggplot2, ggraph, intergraph, sand, devtools, and UserNetR in your R environment. You can do this by running the following code:\n\n\nCode\ninstall.packages(\"igraph\")\ninstall.packages(\"igraphdata\")\ninstall.packages(\"ggplot2\")\n\ninstall.packages(\"sand\")\ninstall.packages(\"devtools\")\nlibrary(devtools)\ninstall_github(\"DougLuke/UserNetR\")\ninstall.packages(\"intergraph\")"
  },
  {
    "objectID": "computational-social-sciences/css_overview.html",
    "href": "computational-social-sciences/css_overview.html",
    "title": "Course Overview",
    "section": "",
    "text": "Welcome to the Computational Social Science (CSS) seminar! This hands-on course explores how social network analysis and geo/spatial data can enhance our understanding of society. Using R, we will learn techniques for visualizing, analyzing, and integrating these data types with existing datasets ‚Äî such as survey or experimental data ‚Äî to gain deeper insights into social phenomena.\n\nGeneral Information\n\n\n\nMonday, weekly\n15:15 - 16:45\n\n\nGWZ, H2 1.15\nStart: 4/7/25\n\n\n\n\n\nüîé Focus\nOur focus will be twofold:\n\nSocial Network Analysis: Understanding relationships and structures in network data, applying visualization techniques, and conducting empirical analyses.\nGeo/Spatial Data Analysis: Examining spatial patterns and dependencies, and leveraging location-based data for social science research.\n\n\n\nüèÅ Goals\nBy combining these data sources with traditional and emerging approaches‚Äîincluding text data (next Semester with Felix) and simulated data (this semester with Sascha) ‚Äîwe will explore innovative ways to study societal dynamics. Throughout the seminar, we will engage with inspiring case studies and hands-on applications to develop our own research perspectives.\nThis course provides both conceptual and technical foundations for working with computational methods in the social sciences, empowering participants to extend existing datasets and refine their analytical toolkit.\nBy the end of this semester, you will be able to understand, analyze, and visualize network and spatial data types. You will gain the skills to effectively apply these methods to your own research questions, enabling you to generate insightful and impactful results. This course provides hands-on knowledge that you can use both in academic research and beyond.\n\n\nüìÜ Syllabus\n\n\n\n\n\n\n\n\n\n\nWeek\nDate\nSubject\nContent\nReadings\n\n\n\n\n1\n07.04.\nKick-Off\n\nIntroduction\nCourse setup and structure\nRefresher\n\n\n\n\n2\n14.04.\nNetworkanalysis in R\n\nIntroduction to SNA (in R)\nKey metrics\nData quality\n\n\n\n\n3\n21.04.\nno lecture (Ostermontag)\n\n\n\n\n4\n28.04.\nTheoretical Insight\n\nCentrality and Assortavity\nHomophily\nHierarchy\n\nBurt, Ronald S. 2009. Structural Holes: The Social Structure of Competition. Harvard University Press. (Chapter: The Social Structure of Competition)\nGranovetter, Mark S. 1973. The Strength of Weak Ties. American Journal of Sociology 78: 1360‚Äì1380.\nMcPherson, Miller, Lynn Smith-Lovin, und James M. Cook. 2001. Birds of a Feather: Homophily in Social Networks. Annual Review of Sociology 27: 415‚Äì444.\n\n\n5\n05.05.\nNetwork Visualisation\n\nVisualisation basics\nInteractive visualisation\n\n\n\n\n6\n12.05.\nCommunity Detection & Structural Comparison\n\n\n\n\n7\n19.05.\nStatistical Models & Case Studies\n\nERGMs\n\nBodaghi, Amirhosein, und Jonice Oliveira. 2022. The theater of fake news spreading, who plays which role? A study on real graphs of spreading on Twitter. Expert Systems with Applications 189: 116110.\n\n\n8\n26.05.\nOpen Lab Session\n\nQ&A\nTerm Paper ideas\n\n\n\n\n9\n02.06.\nGeo-Data Analysis\n\nIntroduction to spatial data\nBasics in R\n\nLogan, John R. 2012. Making a Place for Space: Spatial Thinking in Social Science. Annual Review of Sociology 38: 507‚Äì524.\n\n\n10\n09.06.\nno lecture (Pfingstmontag)\n\n\n\n\n11\n16.06.\nSpatial data visualisation in R\n\nVisualisation\nSpatial inference\n\n\n\n\n12\n23.06.\nCase Studies in Geodata Analysis\n\nBail, Christopher A., Friedolin Merhout, und Peng Ding. 2018. Using Internet search data to examine the relationship between anti-Muslim and pro-ISIS sentiment in U.S. counties. Science Advances 4: eaao5948.\nBalarezo, Maria Laura Guerrero, Martin Tr√©panier, Jonathan Jalbert, und Genevi√®ve Boisjoly. 2024. Going the distance: Gender differences in travel in Montr√©al, Canada. Journal of Transport Geography 118: 103935.\n\n\n13\n30.06.\nOpen Science and CSS\n\n\nTools\nChallenges\nBest Practices\n\n\n\n\n14\n07.07.\nPresentations and term paper discussion\n\n\n\n\n\n\n\nüóÇÔ∏è Course Materials and Structure\nAll materials required for the completion of this course can be found on this website. Literature references (when openly available) are linked directly; otherwise, the PDFs will be uploaded to our Moodle course.\nThe Pre-examination requirements will be available under the ‚ÄúCourse Assessment‚Äù tab, while the lecture content for each week will be uploaded in the ‚ÄúComputational Social Science‚Äù folder.\nDuring the lectures, you may encounter the following block:\n\nThis usually indicates some additional information included for your reference.\n\nIf you see this block:\n\nThis marks an in-class discussion and/or reflection exercise.\n\n\n\nüíê Acknowledgements\nWhile creating this course, I have drawn inspiration from several courses taught by Felix Lennert, Till Hovestadt, Johannes Zschache, Omar Lizardo. Below is a table listing the courses, institutions, and links for further reference (if available). If you are interested in diving deeper into the topics, I encourage you to explore these resources and courses.\n\n\n\nCourse Name\nInstitution\nInstructor\nCourse Link (if available)\n\n\n\n\nSocial Networks\nUCLA\nOmar Lizardo /& Isaac Jilbert\nhttps://olizardo.github.io/networks-textbook/\n\n\nToolbox CSS\nUniversit√§t Leipzig\nFelix Lennert\nhttps://fellennert.github.io/toolbox_css/\n\n\nEmpirische Netzwerkanalyse\nUniversit√§t Leipzig\nJohannes Zschache\n\n\n\nSNA mit R\nUniversit√§t Leipzig\nTill Hovestadt\n\n\n\n\nAdditionally, parts of the content for this course were created with the assistance of GitHub Copilot, ChatGPT, and ChatAI. Please note that while these tools have contributed to the development of the course materials, the final content and structure have been carefully curated and tailored for this course.\n\n\nüíæ Data Inspiration\nIf you find cool datasets during this course (or at any point tbh) I‚Äôd be happy if you share it with the course!\n(‚û°Ô∏èGeneral Information ‚û°Ô∏èData)\n\n\n\n\n\n\nCopyrightCopyright Leonie Steinbrinker, 2025. All Rights Reserved"
  },
  {
    "objectID": "computational-social-sciences/week02.html",
    "href": "computational-social-sciences/week02.html",
    "title": "Week 02 - Social Network Analysis",
    "section": "",
    "text": "Welcome to the second session of the seminar Computational Social Sciences"
  },
  {
    "objectID": "computational-social-sciences/week02.html#exercise",
    "href": "computational-social-sciences/week02.html#exercise",
    "title": "Week 02 - Social Network Analysis",
    "section": "Exercise",
    "text": "Exercise\nReflect briefly on the occasions, where in the past you have been confronted with social networks theories. In what theoretical concepts of sociology is the embedding of actors of central importance?"
  },
  {
    "objectID": "computational-social-sciences/week02.html#from-ties-to-graphs",
    "href": "computational-social-sciences/week02.html#from-ties-to-graphs",
    "title": "Week 02 - Social Network Analysis",
    "section": "From ties to graphs",
    "text": "From ties to graphs\nImagine you where to plot all relationships of all people in the world. Of course, this is just not possible, as the measurement but also the representation would be too complex. Thus we need some kind of (theoretical) bounds, that make the analysis of networks possible.\nIn social network analysis, we use graphs to represent social networks. We borrow graphs from the mathematical graph theory which also provides us with a definition (Joshi 2017).\nA graph \\(G\\) consists of a vertex set \\(V\\) and an edge set \\(E\\):\n\\[\nG = \\{V, E\\}\n\\]\nwhere \\(V\\) is a set of nodes \\(V=\\{v_1,v_2,v_3\\}\\) and \\(E\\) being a set of edges \\(E = \\{\\{v_1,v_2\\},\\{v_2,v_3\\}\\}\\).\nBy using set theory, we can rigorously define different types of graphs, operations on graphs, and concepts like subgraphs, neighbourhoods, or connectivity.\n\nShort Digression: Set Theory\nSets are collections of distinct elements. The order and repitition of elements in a set does not matter.\n\n\n\n\n\n\n\n\nSymbol\nUsage\nInterpretation in Graphs\n\n\n\n\n\\(\\emptyset\\)\n\\(\\{\\}\\)\nEmpty set (e.g., a graph with no edges)\n\n\n\\(\\cup\\)\n\\(A \\cup B\\)\nUnion of sets (e.g., merging vertex or edge sets)\n\n\n\\(\\cap\\)\n\\(A \\cap B\\)\nIntersection of sets (e.g., common neighbors)\n\n\n\\(\\setminus\\)\n\\(A \\setminus B\\)\nSet difference (e.g., removing edges or vertices)\n\n\n\\(\\times\\)\n\\(A \\times B\\)\nCartesian product (e.g., possible edge pairs in a complete graph)\n\n\n\\(\\mathfrak{P}()\\)\n\\(\\mathfrak{P}(A)\\)\nPower set (e.g., all possible subsets of vertices or edges)\n\n\n\\(\\subset\\)\n\\(A \\subset B\\)\nSubset (e.g., a subgraph is a subset of a larger graph)\n\n\n\\(\\in\\)\n\\(x \\in A\\)\nElement in a set (e.g., a vertex in a vertex set)\n\n\n\\(\\notin\\)\n\\(x \\notin A\\)\nElement not in a set (e.g., a missing edge in a sparse graph)"
  },
  {
    "objectID": "computational-social-sciences/week02.html#types-of-graphs",
    "href": "computational-social-sciences/week02.html#types-of-graphs",
    "title": "Week 02 - Social Network Analysis",
    "section": "Types of graphs",
    "text": "Types of graphs\nIn social network analysis, we distinguish between directed and undirected networks. In most real-world cases, directed networks are more realistic because relationships are often asymmetric. However, undirected networks are easier to analyze mathematically and computationally.\n\nDirected Networks\nDirected networks represent relationships where the connection has a defined direction. These relationships do not necessarily have to be reciprocal.\n\\[\n\\forall A,B \\in V:(A \\to B) \\not\\Rightarrow (B \\to A)\n\\]\nExamples:\n- Social media interactions: On Twitter or Instagram, one user can follow another without being followed back.\n- Communication networks: E-Mails, phone calls or other forms of communication, can be sent out or received, thus defining a direction.\nNote: In a directed graph, the edges are ordered, meaning the edge ( (a, b) ) is not the same as ( (b, a) ). The direction of the edge matters, and there is a one-way connection from ( a ) to ( b ) (but not necessarily the other way around).\n\nEdges in directed graphs are representations of ordered pairs (tuples), where the order of the vertices does matter. We can write these as \\(E = \\{(a,b), (b, c), (c, d), (d, a)\\}\\).\n\n\n\nUndirected Networks\nUndirected networks assume that if a connection exists, it is inherently mutual. These networks are simpler to analyze since they do not require considering directionality.\n\\[\n\\forall A, B \\in V: (A \\leftrightarrow B) \\Rightarrow (B \\leftrightarrow A)\n\\]\nExamples:\n- Mutual friendships: In many studies, friendship networks are assumed to be undirected, meaning if A considers B a friend, B also considers A a friend (although this is not always the case in reality).\n- Co-authorship networks: If two researchers have co-authored a paper together, the connection exists for both equally.\n- Collaboration networks: In corporate or scientific collaborations, individuals or institutions work together on projects, making the relationship inherently bidirectional. - Classmates\n\nNote: In an undirected graph, the edges are unordered, meaning the edge ( {a, b} ) is the same as ( {b, a} ). The connection between ( a ) and ( b ) has no direction, and this is reflected by the use of unordered pairs in the edge set.\nA graph \\(E\\) where there are no multiple edges and where each edge is an unordered pair \\({a,b}\\) with \\(a /neq b\\) is also called a simple graph$\n\nIn practice, the choice between directed and undirected networks depends on the research question. If directionality is crucial (e.g., influence, hierarchy, or information flow), a directed network is necessary. However, if the goal is to analyze overall connectivity, undirected networks provide a simpler approach.\n\n\nCode\nlibrary(patchwork)  # For arranging plots\n\n\n# Generate a random graph with 30 nodes and 50 edges\ng2 &lt;- erdos.renyi.game(n = 60, p.or.m = 70, type = \"gnm\", directed = TRUE)\n\n# Assign random colors to nodes\nV(g2)$color &lt;- sample(c(\"blue\", \"green\"), vcount(g2), replace = TRUE)\n\n# Assign random sizes to nodes\nV(g2)$size &lt;- sample(5:12, vcount(g2), replace = TRUE)\n\n  # Plot the network using ggraph\np1 &lt;- ggraph(g, layout = \"fr\") + \n      geom_edge_link(color = \"lightgray\", alpha = 0.5) +\n      geom_node_point(aes(size = size, color = color), alpha = 0.8) +\n      scale_color_manual(values = c(\"blue\" = \"#967bb6\", \"green\" = \"#e8bff7\")) +\n      theme_void() +\n      theme(legend.position = \"none\") +\n      ggtitle(\"Undirected Network\")\n\n# Create the directed network plot\np2 &lt;- ggraph(g2, layout = \"fr\") + \n  geom_edge_link(arrow = arrow(length = unit(1.5, \"mm\"), type = \"closed\"), color = \"lightgray\", alpha = 0.5) +\n  geom_node_point(aes(size = size, color = color), alpha = 0.8) +\n  scale_color_manual(values = c(\"blue\" = \"#967bb6\", \"green\" = \"#e8bff7\")) +\n  theme_void() +\n  theme(legend.position = \"none\") +\n  ggtitle(\"Directed Network\")\n\n# Arrange the two plots side by side\np1 + p2"
  },
  {
    "objectID": "computational-social-sciences/week02.html#network-representations",
    "href": "computational-social-sciences/week02.html#network-representations",
    "title": "Week 02 - Social Network Analysis",
    "section": "Network representations",
    "text": "Network representations\nIn academic research, networks are often represented as graphs. For small datasets, this visualization is quite intuitive. A quick glance at such a diagram can give us a good sense of the network‚Äôs structure.\nHowever, as networks grow larger, this representation quickly reaches its limits. With hundreds, thousands, or even millions of nodes and edges, we end up with what network analysts call a ‚Äúhairball‚Äù‚Äîa dense, tangled structure from which little insight can be gained.\nThis is why, alongside graphical representations, there are other, mathematically more powerful approaches. While they may seem less intuitive, they allows for precise calculations and the analysis of large networks. While graphs help us visually grasp networks, matrices or edge lists serve as the essential tools for conducting complex computations in network analysis.\n\nAdjacency matrices\nAdjacency: We say that two vertices v and w of a graph G are adjacent if there is an edge joining them, and the vertices v and w are then incident with such an edge. Similarly, two distinct edges e and f are adjacent if they have a vertex in common.(Wilson 2009)\n\n\n\nAdjacency\n\n\nTo analyze large networks effectively, we often use adjacency matrices. An adjacency matrix \\(A\\) is a square matrix used to represent a finite graph. Each row and column correspond to a node in a network. The entries of the matrix indicate whether a connection exists between two nodes.\nIn the simplest form, the matrix contains binary values:\n\\[\nA = (A_{ij})_{i,j \\in V},\\text{ where }\nA_{ij} =\n\\begin{cases}\n1, & \\text{if there is an edge between node } i \\text{ and node } j \\\\\n0, & \\text{otherwise}\n\\end{cases}\n\\]\nFor an undirected graph, the adjacency matrix is symmetric, meaning \\(A_{ij} = A_{ji}\\). In contrast, for a directed graph, the matrix is generally asymmetric, where \\(A_{ij} = 1\\) indicates a directed edge from node \\(i\\) to node \\(j\\), but not necessarily vice versa.\n\n\n\nRepresentation as adjacency matrices\n\n\n\nBy using different values than 0 and 1 in \\(A\\) , we can also represent a weight of a connection (e.g strength of a friendship, the frequency of interaction or any other meaningful measure of connection intensity).\n\n\n\nAdjacency lists\nSimiliarly to the adjacency matrix a adjacency list stores the information if one node in a graph is connected to another, while being a lot more space efficient.\nAn adjacency list is a collection of lists, where each node has a list of its neighbours.\nWe can convert from an adjacency matrix to a adjacency list in the way that we iterate over the matrix \\(A\\) and for each entry \\(A_{ij} = 1\\), we add node \\(j\\) to the adjacency list of node \\(i\\).\n\n\n\n\ndirected\nundirected\n\n\n\n\n1\n(4,7)\n(4,6,7)\n\n\n2\n(3,7)\n(3,5,7)\n\n\n3\n(2,6)\n(2,4,6)\n\n\n4\n(1,3)\n(1,3,5)\n\n\n5\n(2,4,7)\n(2,4,6,7)\n\n\n6\n(1,3,5)\n(1,3,5,7)\n\n\n7\n()\n(1,2,5,6)\n\n\n\n\n\nEdge lists\nWith even bigger networks it might be useful to even store networks in an edge list, where each edge is represented as a pair (or triplet in weighted graphs) indicating a connection between two nodes.\n\n\n\n\n\n\n\n\n\ndirected\nundirected\n\n\n\n\nV\n1, 2, 3, 4, 5, 6, 7\n1, 2, 3, 4, 5, 6, 7\n\n\nE\n(1,4), (1,7), (2,3), (2,7), (3,6), (5,7), (4,1), (6,1), (3,2), (5,2), (4,3), (6,3), (5,4), (6,5)\n(1,4), (1,6), (1,7), (2,3), (2,5), (2,7), (3,2), (3,4), (3,6), (4,1), (4,3), (4,5), (5,2), (5,4), (5,6), (5,7), (6,1), (6,3), (6,5), (6,7), (7,1), (7,2), (7,5), (7,6)\n\n\n\n\nTip:\n\nUse an adjacency matrix if you need fast edge lookups.\nUse an adjacency list for efficient traversal in sparse graphs.\nUse an edge list when edges are dynamic or when importing/exporting graph data."
  },
  {
    "objectID": "computational-social-sciences/week02.html#creating-igraph-objects",
    "href": "computational-social-sciences/week02.html#creating-igraph-objects",
    "title": "Week 02 - Social Network Analysis",
    "section": "Creating igraph objects",
    "text": "Creating igraph objects\nIn igraph (Cs√°rdi et al. 2025), a network object is an instance of the class igraph. There are multiple ways to create such an object, depending on the available data format:\n\ngraph.formula\ngraph.adjlist\ngraph.edgelist\ngraph.adjacency\nread.graph (can also read formats GraphML, Pajek, etc.)\ngraph.data.frame\n\n\nCreating a graph from an adjacency matrix\nDirected graph:\n\nM &lt;- matrix(c( 0, 1, 0, 0, 0,\n               0, 0, 1, 0, 0,\n               1, 1, 0, 0, 1,\n               0, 1, 0, 0, 0,\n               0, 1, 1, 0, 0), nrow = 5, byrow=TRUE)\n\ng &lt;- graph.adjacency(M, mode = \"directed\")\n\n# Graph descriptives\nsummary(g)\n\nV(g)  # List nodes\nE(g)  # List edges\n\nget.edgelist(g)  # Convert to edge list\nget.adjacency(g) # Get adjacency matrix\nget.adjlist(g, mode = \"out\") # Get adjacency list\n\nvcount(g)  # Count vertices\necount(g)  # Count edges\n\n# Plot the graph\nplot(g)\n\nUndirected graph:\n\nug &lt;- graph.adjacency(M, mode = \"undirected\")\nug\nsummary(ug)\n\nV(ug)\nE(ug)\n\nget.edgelist(ug)\nget.adjacency(ug)\nget.adjlist(ug, mode = \"out\")\n\nvcount(ug)\necount(ug)\n\nplot(ug)\n\nAccessing the Adjacency matrix\n\nget.adjacency(g)  # Retrieve adjacency matrix\ng[]  # Print entire adjacency matrix\ng[2,1]  # Check if an edge exists from node 2 to 1\ng[1,2]  # Check edge from node 1 to 2\ng[2,]   # Get all edges originating from node 2\nsum(g[2,])  # Count outgoing connections from node 2\n\n\n\nCreating a graph from an edge list\n\nedgelist &lt;- rbind(c(1,2), c(1,3), c(2,3), c(2,4), c(3,2), c(5,3))\nh &lt;- graph.edgelist(edgelist)\n\nplot(h)\n\n\n\nCreating a graph from formula\n\ng &lt;- graph_from_literal(1--2, 2--3, 3--5, 4--2, 1--3, 2--5)\n\nplot(g)"
  },
  {
    "objectID": "computational-social-sciences/week02.html#adding-node-and-edge-attributes",
    "href": "computational-social-sciences/week02.html#adding-node-and-edge-attributes",
    "title": "Week 02 - Social Network Analysis",
    "section": "Adding node and edge attributes",
    "text": "Adding node and edge attributes\nJust the network itself does not hold a lot of information to analyze. In order to sensefully do so on a micro-level, we can add more data to our nodes and edges.\n\n\n\nCategory\nExample Values\n\n\n\n\nNodes\n(1,2,3,4)\n\n\nEdges\n{(1,2), (2,3), (2,4)}\n\n\nNode attributes\nGender, Age, Income, Status\n\n\nEdge attributes\nStrength, Valence (positive, negative), Frequency\n\n\nMetadata\nDirected, loops, etc.\n\n\n\n\n# Assign names to nodes\nV(g)$name &lt;- c(\"A\", \"B\", \"C\", \"D\", \"E\")\n\nplot(g)\n\n\nE(g)$weight &lt;- c(1.2, 2.3, 1.8, 3.0, 2.1, 1.5)\n\nplot(g, edge.width = E(g)$weight)  # Visualizing edge weights"
  },
  {
    "objectID": "computational-social-sciences/week04.html",
    "href": "computational-social-sciences/week04.html",
    "title": "Week 04",
    "section": "",
    "text": "CopyrightCopyright Leonie Steinbrinker, 2025. All Rights Reserved"
  },
  {
    "objectID": "computational-social-sciences/week06.html",
    "href": "computational-social-sciences/week06.html",
    "title": "Week 06",
    "section": "",
    "text": "CopyrightCopyright Leonie Steinbrinker, 2025. All Rights Reserved"
  },
  {
    "objectID": "computational-social-sciences/week08.html",
    "href": "computational-social-sciences/week08.html",
    "title": "Week 08",
    "section": "",
    "text": "CopyrightCopyright Leonie Steinbrinker, 2025. All Rights Reserved"
  },
  {
    "objectID": "computational-social-sciences/week10.html",
    "href": "computational-social-sciences/week10.html",
    "title": "Week 10",
    "section": "",
    "text": "CopyrightCopyright Leonie Steinbrinker, 2025. All Rights Reserved"
  },
  {
    "objectID": "computational-social-sciences/week12.html",
    "href": "computational-social-sciences/week12.html",
    "title": "Week 12",
    "section": "",
    "text": "CopyrightCopyright Leonie Steinbrinker, 2025. All Rights Reserved"
  },
  {
    "objectID": "computational-social-sciences/week14.html",
    "href": "computational-social-sciences/week14.html",
    "title": "Week 14",
    "section": "",
    "text": "CopyrightCopyright Leonie Steinbrinker, 2025. All Rights Reserved"
  },
  {
    "objectID": "experimental-sociology/week01.html",
    "href": "experimental-sociology/week01.html",
    "title": "Experimental Sociology - Week 1",
    "section": "",
    "text": "In short: it‚Äôs about understanding social behavior through controlled experiments. We‚Äôll also integrate analytical thinking and computational methods‚Äîsuch as game-theoretical equilibrium and agent-based modeling (ABM)‚Äîto help you formulate better research questions, optimize experimental design, and effectively utilize available resources. Essentially, computational methods serve as tools to enhance and refine your experimental designs, maximizing the quality and efficiency of your research.\n\n\n\nWe‚Äôll follow a flipped classroom approach: - Before class: You‚Äôll read materials and familiarize yourself with key concepts. - In class: Engage actively in discussions, solve problems, and apply concepts practically.\n\n\n\n\nAnalytical thinking and hypothesis generation\nAgent-based models (ABM): creating, modifying, and calibrating simulations\nExperimental design: optimizing experiments, improving statistical power, and addressing real-world research challenges\nMachine learning basics: practical implementation\n\n\n\n\nCourse materials will be provided weekly. Read at your own pace, and bring questions or ideas to the seminar!\n\n\n\nBy the end of this course, you‚Äôll: - Understand how to model social processes analytically and computationally. - Design, program, and utilize agent-based models (ABMs). - Improve experimental design efficiency using computational methods.\n\n\n\n\nSociological curiosity\nBasic R programming knowledge\nLaptop with R and RStudio installed\nA good sense of humor\n\n\n\n\nGot questions or ideas? Talk to us anytime‚Äîwe‚Äôre your collaborators, not just instructors.\nLet‚Äôs enjoy this journey and make some discoveries together!"
  },
  {
    "objectID": "experimental-sociology/week01.html#what-is-experimental-sociology",
    "href": "experimental-sociology/week01.html#what-is-experimental-sociology",
    "title": "Experimental Sociology - Week 1",
    "section": "",
    "text": "In short: it‚Äôs about understanding social behavior through controlled experiments. We‚Äôll also integrate analytical thinking and computational methods‚Äîsuch as game-theoretical equilibrium and agent-based modeling (ABM)‚Äîto help you formulate better research questions, optimize experimental design, and effectively utilize available resources. Essentially, computational methods serve as tools to enhance and refine your experimental designs, maximizing the quality and efficiency of your research."
  },
  {
    "objectID": "experimental-sociology/week01.html#course-structure",
    "href": "experimental-sociology/week01.html#course-structure",
    "title": "Experimental Sociology - Week 1",
    "section": "",
    "text": "We‚Äôll follow a flipped classroom approach: - Before class: You‚Äôll read materials and familiarize yourself with key concepts. - In class: Engage actively in discussions, solve problems, and apply concepts practically."
  },
  {
    "objectID": "experimental-sociology/week01.html#main-topics",
    "href": "experimental-sociology/week01.html#main-topics",
    "title": "Experimental Sociology - Week 1",
    "section": "",
    "text": "Analytical thinking and hypothesis generation\nAgent-based models (ABM): creating, modifying, and calibrating simulations\nExperimental design: optimizing experiments, improving statistical power, and addressing real-world research challenges\nMachine learning basics: practical implementation"
  },
  {
    "objectID": "experimental-sociology/week01.html#weekly-readings",
    "href": "experimental-sociology/week01.html#weekly-readings",
    "title": "Experimental Sociology - Week 1",
    "section": "",
    "text": "Course materials will be provided weekly. Read at your own pace, and bring questions or ideas to the seminar!"
  },
  {
    "objectID": "experimental-sociology/week01.html#goals",
    "href": "experimental-sociology/week01.html#goals",
    "title": "Experimental Sociology - Week 1",
    "section": "",
    "text": "By the end of this course, you‚Äôll: - Understand how to model social processes analytically and computationally. - Design, program, and utilize agent-based models (ABMs). - Improve experimental design efficiency using computational methods."
  },
  {
    "objectID": "experimental-sociology/week01.html#requirements",
    "href": "experimental-sociology/week01.html#requirements",
    "title": "Experimental Sociology - Week 1",
    "section": "",
    "text": "Sociological curiosity\nBasic R programming knowledge\nLaptop with R and RStudio installed\nA good sense of humor"
  },
  {
    "objectID": "experimental-sociology/week01.html#communication",
    "href": "experimental-sociology/week01.html#communication",
    "title": "Experimental Sociology - Week 1",
    "section": "",
    "text": "Got questions or ideas? Talk to us anytime‚Äîwe‚Äôre your collaborators, not just instructors.\nLet‚Äôs enjoy this journey and make some discoveries together!"
  },
  {
    "objectID": "experimental-sociology/week01.html#experiments-in-the-social-sciences",
    "href": "experimental-sociology/week01.html#experiments-in-the-social-sciences",
    "title": "Experimental Sociology - Week 1",
    "section": "Experiments in the Social Sciences",
    "text": "Experiments in the Social Sciences\nIn the ideal world we have:\n\nWe have a hypothesis regarding the effect of a independent treatment on a dependent variable.\nWe plan an experiment to test this hypothesis\n\nThe experiment has at least one treatment and a control group.\nOnly independent treatment is changed while everything else is kept similar.\nAssignment to TG or CG is randomly.\nWe measure the dependent variable after the different treatment occured.\n\nWe decide whether the reject the hypothesis or keep it.\n\nYet, often it is not that easy."
  },
  {
    "objectID": "experimental-sociology/week01.html#problems-of-experiments-in-the-social-sciences",
    "href": "experimental-sociology/week01.html#problems-of-experiments-in-the-social-sciences",
    "title": "Experimental Sociology - Week 1",
    "section": "Problems of Experiments in the Social Sciences",
    "text": "Problems of Experiments in the Social Sciences\nIn this course we will look at some of the problems (some you already have tackled in your former studies (Experiments not possible), others you will tackle in the ‚ÄúKausalanalyse‚Äù. So we will focus on a very specific part.\n\nHow to derive hypothesis\nHow to plan a good and efficienct experiment.\n\nHow to make the expected effects strong?\nHow to know what to test?\nHow to do with limited money more?\nHow to save the researches time?\nHow to save the subjects time?"
  },
  {
    "objectID": "experimental-sociology/week01.html#basic-process",
    "href": "experimental-sociology/week01.html#basic-process",
    "title": "Experimental Sociology - Week 1",
    "section": "Basic Process",
    "text": "Basic Process\nAn ABM is"
  },
  {
    "objectID": "experimental-sociology/week01.html#basic-steps-for-a-agent-based-model.example-of-an-interaction-at-time-ùë°",
    "href": "experimental-sociology/week01.html#basic-steps-for-a-agent-based-model.example-of-an-interaction-at-time-ùë°",
    "title": "Experimental Sociology - Week 1",
    "section": "Example of an Interaction at Time ùë°",
    "text": "Example of an Interaction at Time ùë°"
  },
  {
    "objectID": "experimental-sociology/week01.html#advantages-of-abms",
    "href": "experimental-sociology/week01.html#advantages-of-abms",
    "title": "Experimental Sociology - Week 1",
    "section": "Advantages of ABMs",
    "text": "Advantages of ABMs\n\nAdvantages for Modeling\nSee also Manzo (2022)\nGranularity - No level of detail specified a priori - Heterogeneity easy to implement\nGeneralizability - Can contain multiple approaches and formalisms simultaneously\nFlexibility - Open for all theoretical ideas / approaches - Approaches can be added / removed individually ### Advatages in Contrast to Empirical Studies\nDisadvantages of studies with real actors (= people) - Costly - Difficult to collect/implement - Unethical\nABMs as an alternative - Hypotheses can be tested as proof-of-concept - Crucial factors can be identified (cf.¬†sensitivity analysis) - Irrelevant factors can be identified\nHowever, does not replace empirical confirmation!\nUse insights of ABM to develop tailored studies\n\n\nOther Advantages\nAutomated - Effects of changed parameters/other formalisms, do not have to be calculated, but can be implemented automatically\nEducational aspects - Visualizations are more memorable and help convey information faster - Learners can do hands-on learning for themselves by ‚Äúplaying around‚Äù"
  },
  {
    "objectID": "general-information/ai_usage.html",
    "href": "general-information/ai_usage.html",
    "title": "Guidelines on AI-Usage",
    "section": "",
    "text": "Of course, you are allowed to use tools like ChatGPT, Elicit, Copilot, or Canva to facilitate your tasks, to have content explained again, or to receive suggestions and inspiration, just as we do.\nHowever, in order to ensure that our work adheres to the principles of good scientific practice and to clarify our expectations regarding the use of these tools, we have compiled a few points below that should be considered.\n\n\nEverything you submit, send, or publish under your name is your responsibility. This means that you are fully accountable for the content. Specifically, this entails:\n\nYou have to at least have a basic understanding of how AI models function (what happens in the background) in order to properly evaluate and interpret the output you receive.\nBe aware of potential biases that may affect the answers due to training datasets or algorithms.\n\n\n\n\nExample for bias resulting from training data\n\n\n\nOnly outsource tasks where you can take responsibility for the content, fact-check everything, and have sufficient prior knowledge of the topic"
  },
  {
    "objectID": "general-information/ai_usage.html#responsibility-for-content",
    "href": "general-information/ai_usage.html#responsibility-for-content",
    "title": "Guidelines on AI-Usage",
    "section": "",
    "text": "Everything you submit, send, or publish under your name is your responsibility. This means that you are fully accountable for the content. Specifically, this entails:\n\nYou have to at least have a basic understanding of how AI models function (what happens in the background) in order to properly evaluate and interpret the output you receive.\nBe aware of potential biases that may affect the answers due to training datasets or algorithms.\n\n\n\n\nExample for bias resulting from training data\n\n\n\nOnly outsource tasks where you can take responsibility for the content, fact-check everything, and have sufficient prior knowledge of the topic"
  },
  {
    "objectID": "general-information/ai_usage.html#potential-reproduction-of-biases",
    "href": "general-information/ai_usage.html#potential-reproduction-of-biases",
    "title": "Guidelines on AI-Usage",
    "section": "Potential Reproduction of Biases",
    "text": "Potential Reproduction of Biases\nThis issue arises from the way data and algorithms are used to train AI models. If the data used to train these models is biased or reflects social inequalities, the resulting AI model will also show these biases. This can lead to AI models reinforcing and perpetuating existing prejudices and discriminatory practices without being noticed.\n\n\n\n\n\n\n\n\n\nModel prompt: Scientist\n\n\n\n\n\n\n\nModel prompt: Scientist\n\n\n\n\n\n\n\nModel prompt: Social Scientist\n\n\n\n\n\n\n\n\n\nModel prompt: Social Scientist\n\n\n\n\n\n\n\nModel prompt: Computational Social Scientist\n\n\n\n\n\n\n\nModel prompt: Computational Social Scientist"
  },
  {
    "objectID": "general-information/ai_usage.html#environmental-impacts",
    "href": "general-information/ai_usage.html#environmental-impacts",
    "title": "Guidelines on AI-Usage",
    "section": "Environmental Impacts",
    "text": "Environmental Impacts\nLarge-scale AI deploymens are hosted in data centers, which have a significant toll on the planet [@AIHasEnvironmental2024].\n\n\n\nThe Chemetall Foot Lithium Operation in Clayton Valley, Nevada (Image by PDTillman, Wikipedia Commons)\n\n\nFor example:\n\nProducing a 2 kg computer requires about 800 kg of raw materials.\nMicrochips that power AI require rare earth elements, which are often mined in environmentally destructive ways and frequently come from regions affected by civil-wars.\nThe production of electronics involves materials like lead and mercury, which are harmful to the environment.\nData centers use water during construction and in operation to cool electronic components. Globally, AI-related infrastructure consumes about six times more water than Denmark, which is a problem, considering a quarter of humanity already lacks access to clean water and sanitation.\nThe use of fossil fuels contributes to the production of greenhouse gases.\nA request made through ChatGPT consumes about 10-times the electricity of a Google search."
  },
  {
    "objectID": "general-information/ai_usage.html#reflection",
    "href": "general-information/ai_usage.html#reflection",
    "title": "Guidelines on AI-Usage",
    "section": "Reflection",
    "text": "Reflection\n\nWhat is your attitude on the usage of generative AI in class? What are further issues we encounter, when we are tolerating (or not tolerating) AI in class?\nWhat can we do together to ensure an appropriate behavior with AI in class?"
  },
  {
    "objectID": "general-information/data.html",
    "href": "general-information/data.html",
    "title": "Data & More",
    "section": "",
    "text": "Data is truly the bread and butter of Computational Social Sciences‚Äîwithout it, we‚Äôd be cooking up theories with empty pans! To keep your research kitchen well-stocked, we‚Äôve curated a list of data sources to fuel your computational explorations. We encourage you to adding your own favorite data sources. After all, science thrives best when everyone brings something to the table.\nYou can find (and contribute to!) the complete list in the following Google Doc:"
  },
  {
    "objectID": "general-information/sc.html",
    "href": "general-information/sc.html",
    "title": "Scientific Computing",
    "section": "",
    "text": "Note\n\n\n\nThis document is an updated and extended version of original work by Felix Lennert, who has kindly granted us permission to adapt and share it with you."
  },
  {
    "objectID": "general-information/sc.html#why-should-i-use-scientific-computing",
    "href": "general-information/sc.html#why-should-i-use-scientific-computing",
    "title": "Scientific Computing",
    "section": "Why Should I Use Scientific Computing?",
    "text": "Why Should I Use Scientific Computing?\nUsing the computational cluster provides numerous advantages, especially when your programs can run independently without supervision and aren‚Äôt feasible to execute on your local machine. Typical scenarios include:\n\nYour script requires a significant amount of time to finish (several hours or even days).\nYour task demands more RAM than your local computer can provide.\nYour computation generates a large volume of temporary data that exceeds your local storage capabilities.\nYou need to repeatedly execute the same code across multiple datasets or parameter combinations‚Äîespecially when the number of runs is very large.\nYou prefer to let your calculations run smoothly in the background, allowing you to enjoy downtime at the park while maintaining the satisfying feeling of productivity!"
  },
  {
    "objectID": "general-information/sc.html#request-sc-infrastructure-access",
    "href": "general-information/sc.html#request-sc-infrastructure-access",
    "title": "Scientific Computing",
    "section": "Request SC Infrastructure Access:",
    "text": "Request SC Infrastructure Access:\nTo use the SC cluster, first request access:\n\nVisit the Scientific Computing Knowledge Base.\nGo to Request SC infrastructure.\nComplete the form with your university credentials.. A good start is to ask for paula, clara, paul, jupyter, rstudio\n\nApproval typically takes a few hours to days."
  },
  {
    "objectID": "general-information/sc.html#accessing-the-cluster",
    "href": "general-information/sc.html#accessing-the-cluster",
    "title": "Scientific Computing",
    "section": "Accessing the Cluster:",
    "text": "Accessing the Cluster:\nWhen accessing the cluster, make sure that you are connected to the university‚Äôs internal network (i.e., you are physically in a university building and connected to the local wifi network) or use a VPN (instructions).\nIf this is the case, you can access the services through your web browser:\n\nJupyterLab: lab.sc.uni-leipzig.de\nRStudio: rstudio01, rstudio02\n\nFor submitting jobs, you need to connect to the cluster from your terminal. To do this, the most convenient way is to authenticate via SSH. SSH gives you the possibility to connect safely to another computer (the server, in our case). Then, once connected, you can control the remote machine via terminal commands. This is good for submitting jobs. Everything else (i.e., interactive coding, code testing, etc.) should be done using the web interface in JupyterLab or RStudio.\nBefore you can authenticate using SSH, you need to create a key pair on your own machine and upload the public key to the cluster. You can find an extensive tutorial online.\nOnce you have access, you can connect using your terminal with your SC username.\nssh &lt;your_sc_username&gt;@login01.sc.uni-leipzig.de"
  },
  {
    "objectID": "general-information/sc.html#python",
    "href": "general-information/sc.html#python",
    "title": "Scientific Computing",
    "section": "Python",
    "text": "Python\nOnce you have access, you can set up your Python environment and workflows.\nWhen you access JupyterLab, you first need to choose your server and the resources you need. paul has CPUs only, while clara and paula also have GPUs available.\n\n\n\n\n\n\nFigure¬†1: lab.sc.uni-leipzig.de landing page\n\n\n\nOnce you have launched the server, you reach the ‚ÄúLauncher.‚Äù While you can do most of these things in the JupyterLab GUI, we recommend using terminal commands since it‚Äôs fast and ‚Äì once you‚Äôve got the hang of it ‚Äì easier. In the Launcher, you can open a Terminal window by clicking ‚ÄúOther &gt; Terminal‚Äù (see screenshot below).\n\n\n\n\n\n\nFigure¬†2: Launcher\n\n\n\n\nBasic Terminal Commands\nFamiliarity with basic terminal commands is essential for navigating and managing files on the cluster. Here are some common commands:\n\nls: List directory contents.\ncd: Change the current directory, e.g., cd my_folder\npwd: Display the current directory path.\nmkdir: Create a new directory (make sure you have navigated to the right folder first).\nrm: Remove files or directories, e.g., rm my_file\n\nFor a comprehensive list, consult the Linux Command Reference.\n\n\nModule Selection\nThe cluster uses environment modules to manage software. To see available modules, type:\nmodule avail\nThen you have to choose one first thing. I usually go for Python/3.10.8-GCCcore-12.2.0. You can activate this module using module load Python/3.10.8-GCCcore-12.2.0. The module essentially provides the environment needed to run your code.\n\n\nCreating a Project-specific Virtual Environment\nThen you will want to create a virtual environment for your dedicated project. The virtual environment allows you to install the relevant Python packages that you will need, keeping your Python distribution clean and ensuring that you will not run into compatibility issues between packages.\nFor creating a virtual environment, you can use the terminal. First, navigate to your project‚Äôs folder (make sure to create it first), then create the environment using venv, and finally activate it.\nmkdir project_folder \ncd project_folder \npython -m venvmy_project_env \nsource my_project_env/bin/activate\nOnce it is activated, you can start installing the packages you require using pip (e.g., pip install pandas).\n\n\nSetting up Kernels\nTo make your life easier in the JupyterLab, you should set up a dedicated kernel in your JupyterLab. The kernel runs in the background of your notebook, takes your code, processes it, and finally returns the results. Each notebook is connected to one kernel and the kernel defines the language and environment the notebook runs in.\nYou can set up a dedicated kernel as follows: first, activate your environment, second, install ipykernel, third, create the Jupyter kernel containing your environment, you can change the name in the final argument after display-name.\nsource my_project_env/bin/activate \npip install ipykernel \npython -m ipykernel install --user --name=my_project_env --display-name \"Python 3.9 (my_project_env)\"\nOnce this is done, in the future, you will have to choose your module first ‚Äì matching the Python version of your kernel (e.g., load a Python 3.9 module if your kernel uses Python 3.9). Then you can click one of the buttons (see screenshot) ‚Äì depending on the environment you want to work with ‚Äì and start coding.\n\n\n\n\n\n\nFigure¬†3: Laucher with loaded modules\n\n\n\nFind more information here."
  },
  {
    "objectID": "general-information/sc.html#slurm",
    "href": "general-information/sc.html#slurm",
    "title": "Scientific Computing",
    "section": "Slurm",
    "text": "Slurm\nSlurm (Simple Linux Utility for Resource Management) is a powerful job scheduling system used on HPC (High-Performance Computing) clusters to manage and allocate resources among users. Job here means that if you have a script that needs to run for longer, e.g., classifying large amounts of text or comparable things, you can set this up as a job. This allows the server to manage its resources better by distributing the different jobs all over the cluster.\nHere‚Äôs a quick guide on the basic Slurm commands to help you submit, monitor, and manage jobs.\nThe Script\nA Slurm job script is a shell script with Slurm-specific options defined at the beginning. Here‚Äôs an example template:\n#!/bin/bash eval=FALSE \n#SBATCH --time=02:30:00                       # allocated time (check max. time limit!)\n#SBATCH --mem=128G                            # required memory \n#SBATCH --ntasks=1                            # number of tasks \n#SBATCH --job-name=myJob                      # job name \n#SBATCH --partition=clara                     # the server partition you want to work on \n#SBATCH --gpus=v100:1                         # the gpu you need, \":1\" stands for one gpu required \n#SBATCH --mail-type=END                       # sending you an email once it's done \n#SBATCH --mail-user=[username]@uni-leipzig.de # your email \n#SBATCH --output=$HOME/jobfiles/log/%x.out-%j # where you want your log file\n\n# load modules \nmodule purge \nmodule load Python/3.11.5-GCCcore-13.2.0 \nmodule load CUDA/12.1.1 \n\n# Activate the virtual environment \nsource /home/sc.uni-leipzig.de/[username]/venv/bertopic_env/bin/activate \n\n# Confirm the Python version and environment being used \npython --version \nwhich python \n\n# Run the Python \nscript python /home/sc.uni-leipzig.de/[username]/bertopic_scripts/script_1.py \n\nBasic Slurm Commands\nTo submit a job, first connect to the server via ssh. Then you can use the following commands:\n\nSubmitting a Job: To submit a job, use the sbatch command.\nbatch job_script.sh\nThis command sends the job script to Slurm, which then schedules the job to run on available resources.\nChecking Job Status: To check the status of your submitted jobs, use:\nsqueue -u [your_username]\nReplace [your_username] with your actual username. This will display all jobs you have running or queued on the cluster.\nCancelling a Job: To cancel a job, use:\nscancel [job_id]\nReplace [job_id] with the actual ID of the job that you defined in the script. You can also find the job ID using squeue .\nMonitoring Resource Usage: You can monitor resource usage and efficiency with commands like:\nsacct -j [job_id]\nThis command provides detailed information about your job, including CPU and memory usage. Replace [job_id] with your job‚Äôs ID.\n\nSo, in practice:\nFirst, write your Python script and test it with a small sample of your data in ‚Äúinteractive coding mode‚Äù in the JupyterLab. This will also give you an idea of how much time your job will require. Then, refine the script so that it takes the full data and build the Slurm script in your text editor (needs to be an .sh file)\nOnce you‚Äôve created your Slurm job script, you can log in via SSH and submit the script using:\nsbatch job_script.sh\nAfter submitting, you can use squeue to check its status or scancel if you need to stop it. Monitoring with sacct will help you optimize resource requests for future jobs, making your submissions more efficient and improving queue times.\nHappy coding."
  },
  {
    "objectID": "general-information/sc.html#parallelization",
    "href": "general-information/sc.html#parallelization",
    "title": "Scientific Computing",
    "section": "Parallelization",
    "text": "Parallelization\nA major advantage of using the scientific cluster instead of your local machine is its powerful hardware resources. Tasks that might take hours or even days on your computer can often be greatly accelerated through parallelization. Parallelization typically involves two main strategies:\n\nUsing multiple CPU cores: Splitting computations across several cores to perform tasks simultaneously.\nUsing multiple nodes: Each node is essentially a separate virtual computer. If your task can be divided into completely independent parts (e.g., running the same script multiple times with different parameters), distributing the tasks across multiple nodes can significantly enhance efficiency.\n\nKeep in mind, however, that the SC cluster‚Äôs resources (cores, nodes, RAM, and execution time) are limited. Always check current resource constraints before running large-scale parallel tasks.\n\nUsing Multiple Cores in R\nBasically there are two ways how to distribute your work on several cores:\n\nMulticore:\n\nUses the Unix fork() system call to create child processes.\nChild processes share the same memory space initially (copy-on-write), which can make it more memory‚Äëefficient and slightly lower in overhead.\nIt‚Äôs very fast for CPU-bound tasks that are fork‚Äêsafe.\nHowever, not all packages or code are fork‚Äësafe (side effects or open connections may be problematic).\nNot available on Windows.\n\n\n\n\nMultisession:\n\nStarts separate R sessions as workers (via PSOCK clusters).\nEach session is completely independent (does not share memory with the main session), so data must be copied to each worker.\nThis can incur a bit more overhead compared to multicore, but it tends to be more robust with packages that aren‚Äôt fork‚Äësafe.\nIt works consistently across platforms (including Windows).\n\n\nIn the following we take a look at both approaches.\n\nThe parallel Package\n\n\n\n\n\n\nWarning\n\n\n\nThese functions rely on forking, which is not supported on Windows. However, if you‚Äôd like to use them, the web-based R system runs on Linux, where forking is fully supported.\n\n\nThe simplest method for parallelization in R is the parallel library that comes with base R, specifically the function mclapply, which automatically distributes tasks across multiple cores:\nlibrary(parallel)\n\n# generate 32 tasks \ntasks = 1:32\n\n# assinge a maximum of 16 cores\ncores_max = 16\n\n# mclapply generates a list. \nresults &lt;- mclapply(1:length(tasks), function(i) {\n  tasks[i]^2\n}, mc.cores = cores_max)\nmclapply returns a sorted list with each task‚Äôs result. If there are more tasks than cores, it automatically assigns new tasks to cores as they become available.\nWhen using parallel processing, variables created or modified inside the parallel function are independent copies. For example:\nlibrary(parallel)  \n\n# generate 32 tasks  \ntasks  = 1:32 \nnumber = 2\n\n# assinge a maximum of 16 cores \ncores_max = 16  \n# mclapply generates a list.  \nresults &lt;- mclapply(1:length(tasks), function(i) {\n  number &lt;- number * 2\n  number\n}, mc.cores = cores_max)\n\nnumber\ntable(unlist(results))\nIn this case, the original number remains unchanged because, when you call number &lt;- number * 2, a local copy of number is created. Keep this in mind if your calculations involve a large dataset.\nFor example, if you have a 5 GB dataset, everything is fine as long as you don‚Äôt modify it. However, the moment a process running on a core makes changes, it will create its own copy of the data, which can significantly increase memory usage.\n\n\nThe future.apply Package\nAnother simple method for parallelization in R without the Windows restriction is the future.apply library that must be installed manually.\nlibrary(future.apply)\n\n# generate 32 tasks  \ntasks  = 1:32 \nnumber = 2\n\n# assinge a maximum of 16 cores \ncores_max = 16  \n# mclapply generates a list.  \n\n# Set up parallel plan\nplan(multisession, workers = cores_max)  # Use \"multicore\" for Unix/macOS\n\nresults &lt;- future_lapply(1:length(tasks), function(i) {\n  number &lt;- number * 2\n  number\n})\n\nnumber\ntable(unlist(results))\n\n\n\nReproducibility\nReproducibility is crucial in computational social science. When using parallel processing, managing random seeds properly ensures consistent and reproducible results. The example below demonstrates how different seed-setting approaches affect the reproducibility of parallel computations using the parallel package in R.\nlibrary(parallel)\n\n# Define seed and tasks\nseed  = 1234\ntasks = 1:32\n\n# Assign a maximum of 16 cores\ncores_max = 16\n\n# Case 1: Setting seed before `mclapply` with `mc.set.seed = TRUE` (default)\n# A new seed is generated for each core, resulting in different outputs across runs\nset.seed(seed)\nresults1 &lt;- mclapply(1:length(tasks), function(i) {\n  rpois(1, lambda = 5) # Poisson-distributed random integer\n}, mc.cores = cores_max, mc.set.seed = TRUE)\n\n# Case 2: Setting seed before `mclapply` with `mc.set.seed = FALSE`\n# The seed from the current R session is used for each core, leading to consistent but non-identical results\nset.seed(seed)\nresults2 &lt;- mclapply(1:length(tasks), function(i) {\n  rpois(1, lambda = 5) # Poisson-distributed random integer\n}, mc.cores = cores_max, mc.set.seed = FALSE)\n\n# Case 3: Setting the seed within `mclapply`\n# Ensures consistent and reproducible results across runs\nresults3 &lt;- mclapply(1:length(tasks), function(i) {\n  set.seed(seed)\n  rpois(1, lambda = 5) # Poisson-distributed random integer\n}, mc.cores = cores_max)\n\n# Show the results\ntable(unlist(results1))\ntable(unlist(results2))\ntable(unlist(results3))\nIf we run this code some times we can make the following observations:\nResults 1:\n\nThe random values in results1 differ not only from each other but also between runs.\nThis is because mc.set.seed = TRUE generates a new seed for each core at runtime, leading to non-reproducible outcomes.\n\nResults 2:\n\nThe random values in results2 are stable within a session but vary between tasks.\nThis happens because the initial session seed is used, but since there are more tasks than cores, each core generates different values across runs.\nIn more complex simulations, this could lead to inconsistencies.\n\nResults 3:\n\nThe values in results3 are identical across tasks and consistent between runs.\nSetting the seed explicitly within mclapply ensures full reproducibility.\n\nTo guarantee reproducible results, set the seed explicitly within the mclapply function (as in results3). This approach ensures that each core uses the same seed consistently across runs, leading to stable and reliable outputs. If you want reproducible results but also variation, you can do something like set.seed(seed+1).\n\n\nUsing Multiple Nodes\nParallelization across multiple nodes involves specialized setups, typically managed by Slurm. Below is an example of how to perform parallel computations across multiple nodes using an R script and Slurm. For detailed guidance, refer to the Slurm documentation.\nFirst, create an R script (script_run_sim.R) that can handle task-specific input arguments:\nargs     &lt;- commandArgs(trailingOnly = TRUE)\ntask_id  &lt;- as.numeric(args[1]) \n\nmy_calculation_function(task_id)\nNext, set up your Slurm job script (run_script.job) to manage parallel tasks efficiently:\n#!/bin/bash\n\n#SBATCH --output=logs/%x_%A_%a.out   # Standard output (includes job name and ID)\n#SBATCH --error=logs/%x_%A_%a.err    # Standard error\n#SBATCH --time=24:00:00\n#SBATCH --mem=64G\n#SBATCH --ntasks=1                    \n#SBATCH --array=1-10                 # We will run 10 tasks\n#SBATCH --cpus-per-task=16           # choose here how many cpus you need\n#SBATCH --job-name=my_job\n#SBATCH --partition=paul\n\nexport OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\n\nmodule load R\n\nRscript script_run_sim.R $SLURM_ARRAY_TASK_ID\nIn the terminal we enter now\nsbatch run_script.job\n\n\nEfficient Resource Management\nEfficient management of computational resources is crucial. As of 2025-03-20, the ‚Äúpaul‚Äù server consists of 32 nodes, each equipped with 2 CPUs containing 64 cores each (128 cores per node), and a total of 512 GB RAM per node. Each core can be allocated a maximum of 8 GB of memory. Thus, you could theoretically run your script on 128 cores with 4 GB RAM each, or on 64 cores with the full 8 GB RAM. However, requesting large amounts of resources, such as an entire node, typically results in extended waiting periods, since your job would need to wait until the full node becomes available. To enhance scheduling efficiency, it is often better to request fewer resources (e.g., 16 or 24 cores), as partial nodes become available more frequently. Finding a balance between resource requests and acceptable wait times is essential for optimizing the efficiency of your computations."
  },
  {
    "objectID": "general-information/sc.html#github",
    "href": "general-information/sc.html#github",
    "title": "Scientific Computing",
    "section": "GitHub",
    "text": "GitHub\nGitHub is an excellent tool for enhancing your workflow with SC. It also serves as a crucial safety net in case you accidentally overwrite or delete a file, or if the SC cluster crashes and files are permanently lost (which has happened recently!).\nHaving a secure backup for your valuable scripts (and possibly your results) is essential. We strongly expect you to store your scripts with at least one layer of redundancy ‚Äî this is not optional. Make sure your work is protected so you‚Äôre never in a position where you have to explain why it‚Äôs missing.\n\nConnect GitHub With RStudio\ncoming soon ‚Ä¶"
  },
  {
    "objectID": "general-information/sc.html#troubleshooting",
    "href": "general-information/sc.html#troubleshooting",
    "title": "Scientific Computing",
    "section": "Troubleshooting",
    "text": "Troubleshooting\nIf your code suddenly stops working even though it was running fine before, and you‚Äôre not sure why, check the status of the services or the specific nodes involved. Sometimes the issue is simply due to cluster problems."
  },
  {
    "objectID": "computational-social-sciences/week02.html#notions-for-network-description",
    "href": "computational-social-sciences/week02.html#notions-for-network-description",
    "title": "Week 02 - Social Network Analysis",
    "section": "Notions for network description",
    "text": "Notions for network description\n\nThe language of graph Theory is not Standard - all authors have their own terminology Some use the term ‚Äògraph‚Äô for what we call a simple graph, or for a graph with directed edges, or for a graph with infinitely many vertices or edges. In this case the notion is taken from (Wilson 2009).\n\n\n\nCode\nG &lt;- graph_from_literal(v--w, u--w, v--u, u--w, w--z, a --b)\n\nplot(G,\n     vertex.color=\"lavender\",\n     vertex.frame.color=\"gray\",\n     vertex.label.color=\"black\"\n     )\n\n\n\n\n\nExample of a simple graph\n\n\nConsider this simple graph \\(G\\) with: - \\(V(G) = \\{w, v, u, z, a, b\\}\\) - $E(G) = { {v,w}, {v,u}, {u,w}, {w,z}, {a,b} $\nThis graph has two components (disconnected parts)."
  },
  {
    "objectID": "computational-social-sciences/week02.html#walks-paths-and-cycles",
    "href": "computational-social-sciences/week02.html#walks-paths-and-cycles",
    "title": "Week 02 - Social Network Analysis",
    "section": "Walks, Paths, and Cycles",
    "text": "Walks, Paths, and Cycles\nA walk is a way of traveling from one vertex to another, following a sequence of edges.\n\nPath: A walk in which no vertex appears more than once.\nCycle: A walk that starts and ends at the same vertex.\n\nExample: - Walk: $ (w u v w z) $ (length = 4) - Path: $ ( v w z R )$ (length = 3) - Cycle:$ ( w u v w)$"
  },
  {
    "objectID": "computational-social-sciences/week02.html#connected-and-disconnected-graphs",
    "href": "computational-social-sciences/week02.html#connected-and-disconnected-graphs",
    "title": "Week 02 - Social Network Analysis",
    "section": "Connected and Disconnected Graphs",
    "text": "Connected and Disconnected Graphs\nA connected graph is a graph where there exists a path between any two vertices. A disconnected graph has multiple components, meaning some vertices are not reachable from others."
  },
  {
    "objectID": "computational-social-sciences/week02.html#complete-graphs",
    "href": "computational-social-sciences/week02.html#complete-graphs",
    "title": "Week 02 - Social Network Analysis",
    "section": "Complete Graphs",
    "text": "Complete Graphs\nA complete graph \\(K_n\\) is a simple graph where each pair of distinct vertices is connected by an edge. It has:\n\\[\n|E(K_n)| = \\frac{n(n-1)}{2}\n\\]\nedges.\n\nCollecting social network data\n(Rawlings et al. 2023)"
  },
  {
    "objectID": "computational-social-sciences/week02.html#data-collection-strategies",
    "href": "computational-social-sciences/week02.html#data-collection-strategies",
    "title": "Week 02 - Social Network Analysis",
    "section": "Data collection strategies",
    "text": "Data collection strategies\n\nLocal (Egocentric Networks)\n\nFocused around a particular node (ego).\nProvides insights into individual behavior and immediate social environment.\nReduces challenges of defining network boundaries.\nLimitations:\n\nDoes not capture broader network structures.\nHard to infer global properties like paths, centrality, or clustering coefficients.\n\n\n\n\nGlobal (Sociocentric Networks)\n\nCaptures all nodes and their relationships within a specific setting (e.g., a school, company, or online platform).\nAllows measurement of network-wide properties (e.g., degree distribution, network diameter, clustering).\nLimitations:\n\nData collection is expensive and often requires complete participation.\nBoundary setting is crucial to avoid biased conclusions."
  },
  {
    "objectID": "computational-social-sciences/week02.html#data-collection-approach",
    "href": "computational-social-sciences/week02.html#data-collection-approach",
    "title": "Week 02 - Social Network Analysis",
    "section": "Data collection approach",
    "text": "Data collection approach\n\nNominalist Approach:\n\nBased on observable interactions.\n\n\nExamples:\nCo-authorship networks derived from Web of Science or Scopus. - Possible Biases: - Over representation of English-language journals. - Exclusion of informal collaborations - Exclusion of fast and slow science\nFacebook-Connections - Possible Biases - Some individuals have significantly more interactions recorded due to higher usage (e.g., social media users with high posting frequency). - Group-Accounts\n\nRealist Approach:\n\nBased on self-reported relationships (e.g., surveys asking individuals to list friends).\nChallenges:\n\nMemory limitations (people forget connections).\nSubjective definitions of relationships (e.g., what constitutes a ‚Äúfriend‚Äù?)."
  },
  {
    "objectID": "computational-social-sciences/week02.html#missing-data-and-imputation",
    "href": "computational-social-sciences/week02.html#missing-data-and-imputation",
    "title": "Week 02 - Social Network Analysis",
    "section": "Missing data and imputation",
    "text": "Missing data and imputation\n\n\n\nConsequences of hidden network data\n\n\nMissing data in networks can bias results, particularly in global networks where completeness is crucial. Given the data collection choice and context, there can be different types of missing data:\n\nMissing Nodes: Some actors are absent due to nonresponse or other issues (e.g., students absent during a survey).\nMissing Edges: Some relationships are not captured (e.g., weak ties not reported).\n\n\nEvery form of data collection is prone to have some kinds of missing data, or inherent biases. Dealing with the possible consequences of the selected form of data collection and reporting possible biases and missings transparently is thus part of good scientific practice."
  }
]